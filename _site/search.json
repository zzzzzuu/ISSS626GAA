[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am a part-time student in Prof Kam’s class. This documents my learning journey in ISSS626, taught by the venerable Prof Kam."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "Getting started\nInstall and launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(sf, tidyverse)\n\nImporting the data\n\nmpsz = st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial\", \n                  layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\ncyclingpath = st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial\", \n                         layer = \"CyclingPathGazette\")\n\nReading layer `CyclingPathGazette' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 3138 features and 2 fields\nGeometry type: MULTILINESTRING\nDimension:     XY\nBounding box:  xmin: 11854.32 ymin: 28347.98 xmax: 42644.17 ymax: 48948.15\nProjected CRS: SVY21\n\npreschool = st_read(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/geospatial/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex01\\data\\geospatial\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nChecking the basic geometry and associated attribute information in the data frame\n\nst_geometry(mpsz)\n\nGeometry set for 323 features \nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\nFirst 5 geometries:\n\n\nMULTIPOLYGON (((31495.56 30140.01, 31980.96 296...\n\n\nMULTIPOLYGON (((29092.28 30021.89, 29119.64 300...\n\n\nMULTIPOLYGON (((29932.33 29879.12, 29947.32 298...\n\n\nMULTIPOLYGON (((27131.28 30059.73, 27088.33 297...\n\n\nMULTIPOLYGON (((26451.03 30396.46, 26440.47 303...\n\nglimpse(mpsz)\n\nRows: 323\nColumns: 16\n$ OBJECTID   &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, …\n$ SUBZONE_NO &lt;int&gt; 1, 1, 3, 8, 3, 7, 9, 2, 13, 7, 12, 6, 1, 5, 1, 1, 3, 2, 2, …\n$ SUBZONE_N  &lt;chr&gt; \"MARINA SOUTH\", \"PEARL'S HILL\", \"BOAT QUAY\", \"HENDERSON HIL…\n$ SUBZONE_C  &lt;chr&gt; \"MSSZ01\", \"OTSZ01\", \"SRSZ03\", \"BMSZ08\", \"BMSZ03\", \"BMSZ07\",…\n$ CA_IND     &lt;chr&gt; \"Y\", \"Y\", \"Y\", \"N\", \"N\", \"N\", \"N\", \"Y\", \"N\", \"N\", \"N\", \"N\",…\n$ PLN_AREA_N &lt;chr&gt; \"MARINA SOUTH\", \"OUTRAM\", \"SINGAPORE RIVER\", \"BUKIT MERAH\",…\n$ PLN_AREA_C &lt;chr&gt; \"MS\", \"OT\", \"SR\", \"BM\", \"BM\", \"BM\", \"BM\", \"SR\", \"QT\", \"QT\",…\n$ REGION_N   &lt;chr&gt; \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENTRAL REGION\", \"CENT…\n$ REGION_C   &lt;chr&gt; \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\", \"CR\",…\n$ INC_CRC    &lt;chr&gt; \"5ED7EB253F99252E\", \"8C7149B9EB32EEFC\", \"C35FEFF02B13E0E5\",…\n$ FMEL_UPD_D &lt;date&gt; 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05, 2014-12-05…\n$ X_ADDR     &lt;dbl&gt; 31595.84, 28679.06, 29654.96, 26782.83, 26201.96, 25358.82,…\n$ Y_ADDR     &lt;dbl&gt; 29220.19, 29782.05, 29974.66, 29933.77, 30005.70, 29991.38,…\n$ SHAPE_Leng &lt;dbl&gt; 5267.381, 3506.107, 1740.926, 3313.625, 2825.594, 4428.913,…\n$ SHAPE_Area &lt;dbl&gt; 1630379.27, 559816.25, 160807.50, 595428.89, 387429.44, 103…\n$ geometry   &lt;MULTIPOLYGON [m]&gt; MULTIPOLYGON (((31495.56 30..., MULTIPOLYGON (…\n\nhead(mpsz, n=5)  \n\nSimple feature collection with 5 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 25867.68 ymin: 28369.47 xmax: 32362.39 ymax: 30435.54\nProjected CRS: SVY21\n  OBJECTID SUBZONE_NO      SUBZONE_N SUBZONE_C CA_IND      PLN_AREA_N\n1        1          1   MARINA SOUTH    MSSZ01      Y    MARINA SOUTH\n2        2          1   PEARL'S HILL    OTSZ01      Y          OUTRAM\n3        3          3      BOAT QUAY    SRSZ03      Y SINGAPORE RIVER\n4        4          8 HENDERSON HILL    BMSZ08      N     BUKIT MERAH\n5        5          3        REDHILL    BMSZ03      N     BUKIT MERAH\n  PLN_AREA_C       REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR\n1         MS CENTRAL REGION       CR 5ED7EB253F99252E 2014-12-05 31595.84\n2         OT CENTRAL REGION       CR 8C7149B9EB32EEFC 2014-12-05 28679.06\n3         SR CENTRAL REGION       CR C35FEFF02B13E0E5 2014-12-05 29654.96\n4         BM CENTRAL REGION       CR 3775D82C5DDBEFBD 2014-12-05 26782.83\n5         BM CENTRAL REGION       CR 85D9ABEF0A40678F 2014-12-05 26201.96\n    Y_ADDR SHAPE_Leng SHAPE_Area                       geometry\n1 29220.19   5267.381  1630379.3 MULTIPOLYGON (((31495.56 30...\n2 29782.05   3506.107   559816.2 MULTIPOLYGON (((29092.28 30...\n3 29974.66   1740.926   160807.5 MULTIPOLYGON (((29932.33 29...\n4 29933.77   3313.625   595428.9 MULTIPOLYGON (((27131.28 30...\n5 30005.70   2825.594   387429.4 MULTIPOLYGON (((26451.03 30...\n\n\nPlotting the Geospatial Data\n\nplot(mpsz)\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\nplot(st_geometry(mpsz))\n\n\n\nplot(mpsz[\"PLN_AREA_N\"])\n\n\n\n\nChecking coordinate system and correcting EPSG code\n\nst_crs(mpsz)\n\nCoordinate Reference System:\n  User input: SVY21 \n  wkt:\nPROJCRS[\"SVY21\",\n    BASEGEOGCRS[\"SVY21[WGS84]\",\n        DATUM[\"World Geodetic System 1984\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ID[\"EPSG\",6326]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"Degree\",0.0174532925199433]]],\n    CONVERSION[\"unnamed\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"Degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1,\n                ID[\"EPSG\",9001]]]]\n\nmpsz3414 &lt;- st_set_crs(mpsz, 3414)\n\nWarning: st_crs&lt;- : replacing crs does not reproject data; use st_transform for\nthat\n\nst_crs(mpsz3414)\n\nCoordinate Reference System:\n  User input: EPSG:3414 \n  wkt:\nPROJCRS[\"SVY21 / Singapore TM\",\n    BASEGEOGCRS[\"SVY21\",\n        DATUM[\"SVY21\",\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4757]],\n    CONVERSION[\"Singapore Transverse Mercator\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",1.36666666666667,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",103.833333333333,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",1,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",28001.642,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",38744.572,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"northing (N)\",north,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"easting (E)\",east,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Cadastre, engineering survey, topographic mapping.\"],\n        AREA[\"Singapore - onshore and offshore.\"],\n        BBOX[1.13,103.59,1.47,104.07]],\n    ID[\"EPSG\",3414]]\n\n\nProjection transformation of pre-school locations\n\npreschool3414 &lt;- st_transform(preschool, \n                              crs = 3414)\npreschool3414\n\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 11810.03 ymin: 25596.33 xmax: 45404.24 ymax: 49300.88\nz_range:       zmin: 0 zmax: 0\nProjected CRS: SVY21 / Singapore TM\nFirst 10 features:\n     Name\n1   kml_1\n2   kml_2\n3   kml_3\n4   kml_4\n5   kml_5\n6   kml_6\n7   kml_7\n8   kml_8\n9   kml_9\n10 kml_10\n                                                                                                                                                                                                                                                                                                                                                                                                                  Description\n1                             &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S COVE PRESCHOOL PTE.LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9390&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;498CC9FE48CC94D4&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n2                                      &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S COVE PTE. LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT8675&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;22877550804213FD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n3                         &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDREN'S VINEYARD PRESCHOOL PTE. LTD&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9308&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B2FE90E44AD494E3&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n4                   &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILDTIME CARE & DEVELOPMENT CENTRE PTE.LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT9122&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;1384CDC0D14B76A1&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n5                                                 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT2070&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;FB24EAA6E73B2723&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n6                                      &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE EAST COAST&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT6550&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B53C79DF64135499&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n7                                     &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE MOUNTBATTEN&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT8637&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;B53C79DFBF7AD96F&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n8                                       &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHILTERN HOUSE TURF CLUB&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;PT5400&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;8F2BC6E9BF962BC8&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n9                              &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHINESE CHRISTIAN MISSION LIMITED&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;RC0740&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;CA317E72A442CEB6&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n10 &lt;center&gt;&lt;table&gt;&lt;tr&gt;&lt;th colspan='2' align='center'&gt;&lt;em&gt;Attributes&lt;/em&gt;&lt;/th&gt;&lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;CENTRE_NAME&lt;/th&gt; &lt;td&gt;CHOW & CHOWS CHILDCARE & EARLY LEARNING CENTRE (CCK 542) LTD.&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;CENTRE_CODE&lt;/th&gt; &lt;td&gt;RC1775&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"#E3E3F3\"&gt; &lt;th&gt;INC_CRC&lt;/th&gt; &lt;td&gt;2072C1C4F5E69A9C&lt;/td&gt; &lt;/tr&gt;&lt;tr bgcolor=\"\"&gt; &lt;th&gt;FMEL_UPD_D&lt;/th&gt; &lt;td&gt;20211201093631&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;/center&gt;\n                        geometry\n1  POINT Z (25089.46 31299.16 0)\n2  POINT Z (27189.07 32792.54 0)\n3  POINT Z (28844.56 36773.76 0)\n4  POINT Z (24821.92 46303.16 0)\n5  POINT Z (28637.82 35038.49 0)\n6  POINT Z (33248.74 32260.59 0)\n7  POINT Z (33248.74 32260.59 0)\n8   POINT Z (23591.47 35202.8 0)\n9  POINT Z (18338.28 36619.18 0)\n10 POINT Z (18148.23 41723.46 0)\n\n\nImporting the aspatial data and convert into sf\n\nlistings &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/aspatial/listings.csv\")\n\nRows: 3540 Columns: 75\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (26): listing_url, source, name, description, neighborhood_overview, pi...\ndbl  (38): id, scrape_id, host_id, host_listings_count, host_total_listings_...\nlgl   (6): host_is_superhost, host_has_profile_pic, host_identity_verified, ...\ndate  (5): last_scraped, host_since, calendar_last_scraped, first_review, la...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nlist(listings)\n\n[[1]]\n# A tibble: 3,540 × 75\n       id listing_url            scrape_id last_scraped source name  description\n    &lt;dbl&gt; &lt;chr&gt;                      &lt;dbl&gt; &lt;date&gt;       &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;      \n 1  71609 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Ensu… For 3 room…\n 2  71896 https://www.airbnb.co…   2.02e13 2024-06-29   city … B&B … &lt;NA&gt;       \n 3  71903 https://www.airbnb.co…   2.02e13 2024-06-29   city … Room… Like your …\n 4 275343 https://www.airbnb.co…   2.02e13 2024-06-29   city … 10mi… **IMPORTAN…\n 5 275344 https://www.airbnb.co…   2.02e13 2024-06-29   city … 15 m… Lovely hom…\n 6 289234 https://www.airbnb.co…   2.02e13 2024-06-29   previ… Book… This whole…\n 7 294281 https://www.airbnb.co…   2.02e13 2024-06-29   city … 5 mi… I have 3 b…\n 8 324945 https://www.airbnb.co…   2.02e13 2024-06-29   city … Comf… **IMPORTAN…\n 9 330095 https://www.airbnb.co…   2.02e13 2024-06-29   city … Rela… **IMPORTAN…\n10 344803 https://www.airbnb.co…   2.02e13 2024-06-29   city … Budg… Direct bus…\n# ℹ 3,530 more rows\n# ℹ 68 more variables: neighborhood_overview &lt;chr&gt;, picture_url &lt;chr&gt;,\n#   host_id &lt;dbl&gt;, host_url &lt;chr&gt;, host_name &lt;chr&gt;, host_since &lt;date&gt;,\n#   host_location &lt;chr&gt;, host_about &lt;chr&gt;, host_response_time &lt;chr&gt;,\n#   host_response_rate &lt;chr&gt;, host_acceptance_rate &lt;chr&gt;,\n#   host_is_superhost &lt;lgl&gt;, host_thumbnail_url &lt;chr&gt;, host_picture_url &lt;chr&gt;,\n#   host_neighbourhood &lt;chr&gt;, host_listings_count &lt;dbl&gt;, …\n\nlistings_sf &lt;- st_as_sf(listings, \n                       coords = c(\"longitude\", \"latitude\"),\n                       crs=4326) %&gt;%\n  st_transform(crs = 3414)\nglimpse(listings_sf)\n\nRows: 3,540\nColumns: 74\n$ id                                           &lt;dbl&gt; 71609, 71896, 71903, 2753…\n$ listing_url                                  &lt;chr&gt; \"https://www.airbnb.com/r…\n$ scrape_id                                    &lt;dbl&gt; 2.024063e+13, 2.024063e+1…\n$ last_scraped                                 &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ source                                       &lt;chr&gt; \"previous scrape\", \"city …\n$ name                                         &lt;chr&gt; \"Ensuite Room (Room 1 & 2…\n$ description                                  &lt;chr&gt; \"For 3 rooms.Book room 1 …\n$ neighborhood_overview                        &lt;chr&gt; NA, NA, \"Quiet and view o…\n$ picture_url                                  &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_id                                      &lt;dbl&gt; 367042, 367042, 367042, 1…\n$ host_url                                     &lt;chr&gt; \"https://www.airbnb.com/u…\n$ host_name                                    &lt;chr&gt; \"Belinda\", \"Belinda\", \"Be…\n$ host_since                                   &lt;date&gt; 2011-01-29, 2011-01-29, …\n$ host_location                                &lt;chr&gt; \"Singapore\", \"Singapore\",…\n$ host_about                                   &lt;chr&gt; \"Hi My name is Belinda -H…\n$ host_response_time                           &lt;chr&gt; \"within an hour\", \"within…\n$ host_response_rate                           &lt;chr&gt; \"100%\", \"100%\", \"100%\", \"…\n$ host_acceptance_rate                         &lt;chr&gt; \"N/A\", \"N/A\", \"N/A\", \"99%…\n$ host_is_superhost                            &lt;lgl&gt; FALSE, FALSE, FALSE, FALS…\n$ host_thumbnail_url                           &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_picture_url                             &lt;chr&gt; \"https://a0.muscache.com/…\n$ host_neighbourhood                           &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ host_listings_count                          &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ host_total_listings_count                    &lt;dbl&gt; 11, 11, 11, 73, 73, 11, 8…\n$ host_verifications                           &lt;chr&gt; \"['email', 'phone']\", \"['…\n$ host_has_profile_pic                         &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ host_identity_verified                       &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ neighbourhood                                &lt;chr&gt; NA, NA, \"Singapore, Singa…\n$ neighbourhood_cleansed                       &lt;chr&gt; \"Tampines\", \"Tampines\", \"…\n$ neighbourhood_group_cleansed                 &lt;chr&gt; \"East Region\", \"East Regi…\n$ property_type                                &lt;chr&gt; \"Private room in villa\", …\n$ room_type                                    &lt;chr&gt; \"Private room\", \"Private …\n$ accommodates                                 &lt;dbl&gt; 3, 1, 2, 1, 1, 4, 2, 1, 1…\n$ bathrooms                                    &lt;dbl&gt; NA, 0.5, 0.5, 2.0, 2.5, N…\n$ bathrooms_text                               &lt;chr&gt; \"1 private bath\", \"Shared…\n$ bedrooms                                     &lt;dbl&gt; 2, 1, 1, 1, 1, 3, 2, 1, 1…\n$ beds                                         &lt;dbl&gt; NA, 1, 2, 1, 1, NA, 1, 1,…\n$ amenities                                    &lt;chr&gt; \"[\\\"Free parking on premi…\n$ price                                        &lt;chr&gt; NA, \"$80.00\", \"$80.00\", \"…\n$ minimum_nights                               &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights                               &lt;dbl&gt; 365, 365, 365, 999, 999, …\n$ minimum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_minimum_nights                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ minimum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ maximum_maximum_nights                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ minimum_nights_avg_ntm                       &lt;dbl&gt; 92, 92, 92, 180, 180, 92,…\n$ maximum_nights_avg_ntm                       &lt;dbl&gt; 1125, 1125, 1125, 1125, 1…\n$ calendar_updated                             &lt;lgl&gt; NA, NA, NA, NA, NA, NA, N…\n$ has_availability                             &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, T…\n$ availability_30                              &lt;dbl&gt; 30, 30, 30, 28, 0, 29, 30…\n$ availability_60                              &lt;dbl&gt; 59, 53, 60, 58, 0, 58, 60…\n$ availability_90                              &lt;dbl&gt; 89, 83, 90, 62, 0, 88, 90…\n$ availability_365                             &lt;dbl&gt; 89, 148, 90, 62, 0, 88, 3…\n$ calendar_last_scraped                        &lt;date&gt; 2024-06-29, 2024-06-29, …\n$ number_of_reviews                            &lt;dbl&gt; 19, 24, 46, 20, 16, 12, 1…\n$ number_of_reviews_ltm                        &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 1, 1…\n$ number_of_reviews_l30d                       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ first_review                                 &lt;date&gt; 2011-12-19, 2011-07-30, …\n$ last_review                                  &lt;date&gt; 2020-01-17, 2019-10-13, …\n$ review_scores_rating                         &lt;dbl&gt; 4.44, 4.16, 4.41, 4.40, 4…\n$ review_scores_accuracy                       &lt;dbl&gt; 4.37, 4.22, 4.39, 4.16, 4…\n$ review_scores_cleanliness                    &lt;dbl&gt; 4.00, 4.09, 4.52, 4.26, 4…\n$ review_scores_checkin                        &lt;dbl&gt; 4.63, 4.43, 4.63, 4.47, 4…\n$ review_scores_communication                  &lt;dbl&gt; 4.78, 4.43, 4.64, 4.42, 4…\n$ review_scores_location                       &lt;dbl&gt; 4.26, 4.17, 4.50, 4.53, 4…\n$ review_scores_value                          &lt;dbl&gt; 4.32, 4.04, 4.36, 4.63, 4…\n$ license                                      &lt;chr&gt; NA, NA, NA, \"S0399\", \"S03…\n$ instant_bookable                             &lt;lgl&gt; FALSE, FALSE, FALSE, TRUE…\n$ calculated_host_listings_count               &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 7, 49…\n$ calculated_host_listings_count_entire_homes  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ calculated_host_listings_count_private_rooms &lt;dbl&gt; 6, 6, 6, 49, 49, 6, 6, 49…\n$ calculated_host_listings_count_shared_rooms  &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ reviews_per_month                            &lt;dbl&gt; 0.12, 0.15, 0.29, 0.15, 0…\n$ geometry                                     &lt;POINT [m]&gt; POINT (41972.5 3639…\n\n\nCreating buffer for cycling path\n\nbuffer_cycling &lt;- st_buffer(cyclingpath, \n                               dist=5, nQuadSegs = 30)\nbuffer_cycling$AREA &lt;- st_area(buffer_cycling)\nsum(buffer_cycling$AREA)\n\n2218855 [m^2]\n\n\nnumbers of pre-schools in each Planning Subzone\n\nmpsz3414$`PreSch Count`&lt;- lengths(st_intersects(mpsz3414, preschool3414))\nsummary(mpsz3414$`PreSch Count`)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    4.00    7.09   10.00   72.00 \n\ntop_n(mpsz3414, 1, `PreSch Count`)\n\nSimple feature collection with 1 feature and 16 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 39655.33 ymin: 35966 xmax: 42940.57 ymax: 38622.37\nProjected CRS: SVY21 / Singapore TM\n  OBJECTID SUBZONE_NO     SUBZONE_N SUBZONE_C CA_IND PLN_AREA_N PLN_AREA_C\n1      189          2 TAMPINES EAST    TMSZ02      N   TAMPINES         TM\n     REGION_N REGION_C          INC_CRC FMEL_UPD_D   X_ADDR   Y_ADDR SHAPE_Leng\n1 EAST REGION       ER 21658EAAF84F4D8D 2014-12-05 41122.55 37392.39   10180.62\n  SHAPE_Area                       geometry PreSch Count\n1    4339824 MULTIPOLYGON (((42196.76 38...           72\n\nmpsz3414$Area &lt;- mpsz3414 %&gt;%\n  st_area()\nmpsz3414 &lt;- mpsz3414 %&gt;%\n  mutate(`PreSch Density` = `PreSch Count`/Area * 1000000)\n\nEDA on density\n\nhist(mpsz3414$`PreSch Density`)\n\n\n\nggplot(data=mpsz3414, \n       aes(x= as.numeric(`PreSch Density`)))+\n  geom_histogram(bins=20, \n                 color=\"black\", \n                 fill=\"light blue\") +\n  labs(title = \"Are pre-school even distributed in Singapore?\",\n       subtitle= \"There are many planning sub-zones with a single pre-school, on the other hand, \\nthere are two planning sub-zones with at least 20 pre-schools\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Frequency\")\n\n\n\nggplot(data=mpsz3414, \n       aes(y = `PreSch Count`, \n           x= as.numeric(`PreSch Density`)))+\n  geom_point(color=\"black\", \n             fill=\"light blue\") +\n  xlim(0, 40) +\n  ylim(0, 40) +\n  labs(title = \"\",\n      x = \"Pre-school density (per km sq)\",\n      y = \"Pre-school count\")\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_point()`).\n\n\n\n\n\nLoad tmap\n\npacman::p_load(tmap)\n\nLoad population data and wrangle data\n\npopdata &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/aspatial/respopagesextod2011to2020.csv\")\n\nRows: 984656 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopdata2020 &lt;- popdata %&gt;%\n  filter(Time == 2020) %&gt;%\n  group_by(PA, SZ, AG) %&gt;%\n  summarise(`POP` = sum(`Pop`)) %&gt;%\n  ungroup()%&gt;%\n  pivot_wider(names_from=AG, \n              values_from=POP) %&gt;%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %&gt;%\nmutate(`ECONOMY ACTIVE` = rowSums(.[7:11])+\nrowSums(.[13:15]))%&gt;%\nmutate(`AGED`=rowSums(.[16:21])) %&gt;%\nmutate(`TOTAL`=rowSums(.[3:21])) %&gt;%  \nmutate(`DEPENDENCY` = (`YOUNG` + `AGED`)\n/`ECONOMY ACTIVE`) %&gt;%\n  select(`PA`, `SZ`, `YOUNG`, \n       `ECONOMY ACTIVE`, `AGED`, \n       `TOTAL`, `DEPENDENCY`)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\n\nJoining the attribute data and geospatial data\n\npopdata2020 &lt;- popdata2020 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) %&gt;%\n  filter(`ECONOMY ACTIVE` &gt; 0)\nmpsz_pop2020 &lt;- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\nwrite_rds(mpsz_pop2020, \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex01/data/rds/mpszpop2020.rds\")\n\nPlotting a choropleth map\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_polygons()\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\")\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\") +\n  tm_borders(lwd = 0.1,  alpha = 1)\n\n\n\n\nData classification methods of tmap\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"quantile\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nprepare choropleth maps by using different classification methods supported by tmap and compare their differences\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nDifferent styles produce different highlights due to the distribution of the data.\nPreparing choropleth maps by using similar classification method but with different numbers of classes (i.e. 2, 6, 10, 20). Compare the output maps, what observation can you draw?\nSee more differences in colour.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 20,\n          style = \"fisher\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nPlotting choropleth map with custome break\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.1111  0.7147  0.7866  0.8585  0.8763 19.0000      92 \n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\nWarning: Values have found that are higher than the highest break\n\n\n\n\n\nChange colour scheme and map layouts\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"Blues\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\ntmap style set to \"classic\"\n\n\nother available styles are: \"white\", \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"watercolor\" \n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\ntmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\nSmaller maps\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\ntmap style set to \"white\"\n\n\nother available styles are: \"gray\", \"natural\", \"cobalt\", \"col_blind\", \"albatross\", \"beaver\", \"bw\", \"classic\", \"watercolor\" \n\n\n\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\nWarning: The argument drop.shapes has been renamed to drop.units, and is\ntherefore deprecated\n\n\n\n\nyoungmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap &lt;- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\nWarning in pre_process_gt(x, interactive = interactive, orig_crs =\ngm$shape.orig_crs): legend.width controls the width of the legend within a map.\nPlease use legend.outside.size to control the width of the outside legend\n\n\n\n\n\nThat ends hands-on exercise 1."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nset.seed(1234)\n\n\n\n\n\nchildcare_sf &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nNote to self: the pipe function is a useful tool to avoid creating too many intermediate datasets.\n\nchildcare_sf3414 &lt;- st_transform(childcare_sf, \n                              crs = 3414)\n\n\n\n\nLet’s do some mapping!\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +   \ntm_shape(sg_sf) +\n  tm_borders() +    \ntm_shape(childcare_sf3414) +\n  tm_dots()         \n\n\n\n\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#load-the-packages",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#load-the-packages",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "pacman::p_load(sf, raster, spatstat, tmap, tidyverse)\nset.seed(1234)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#import-the-data",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#import-the-data",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "childcare_sf &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nsg_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data\", layer=\"CostalOutline\")\n\nReading layer `CostalOutline' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 60 features and 4 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 2663.926 ymin: 16357.98 xmax: 56047.79 ymax: 50244.03\nProjected CRS: SVY21\n\nmpsz_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\nNote to self: the pipe function is a useful tool to avoid creating too many intermediate datasets.\n\nchildcare_sf3414 &lt;- st_transform(childcare_sf, \n                              crs = 3414)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#mapping",
    "title": "Hands-on Exercise 02",
    "section": "",
    "text": "Let’s do some mapping!\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(mpsz_sf) +\n  tm_polygons() +   \ntm_shape(sg_sf) +\n  tm_borders() +    \ntm_shape(childcare_sf3414) +\n  tm_dots()         \n\n\n\n\nAlternatively, we can also prepare a pin map by using the code chunk below.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare_sf)+\n  tm_dots()\n\n\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-for-duplicates",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#checking-for-duplicates",
    "title": "Hands-on Exercise 02",
    "section": "Checking for duplicates",
    "text": "Checking for duplicates\nLet’s check for duplicates because it is an issue of significance.\n\nany(duplicated(childcare_ppp))\n\n[1] FALSE\n\n\nGreat! We can also check for co-indicence point.\n\nmultiplicity(childcare_ppp)\n\n   [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n  [75] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [112] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [149] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [186] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [223] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [260] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [297] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [334] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [371] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [408] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [445] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [482] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [519] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [556] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [593] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [630] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [667] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [704] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [741] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [778] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [815] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [852] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [889] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [926] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n [963] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1000] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1037] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1074] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1111] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1148] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1185] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1222] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1259] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1296] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1333] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1370] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1407] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1444] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1481] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n[1518] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n\nsum(multiplicity(childcare_ppp) &gt; 1)\n\n[1] 0\n\n\nThere are no duplications.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots(alpha=0.4, \n          size=0.05)\n\n\n\n\n\n\nDuplicated points would be those with complete overlap of dots.\nLet’s address this via jittering.\n\nchildcare_ppp_jit &lt;- rjitter(childcare_ppp, \n                             retry=TRUE, \n                             nsim=1, \n                             drop=TRUE)\n\nNow, let’s check again for duplicates.\n\nany(duplicated(childcare_ppp_jit))\n\n[1] FALSE"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#owin-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#owin-object",
    "title": "Hands-on Exercise 02",
    "section": "owin object",
    "text": "owin object\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\nsummary(sg_owin)\n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\n\nThis next step is important. It extracts the childcare events within Singapore using the simple line.\n\nchildcareSG_ppp = childcare_ppp[sg_owin]\n\nThe output can be shown below.\n\nsummary(childcareSG_ppp)\n\nMarked planar point pattern:  1545 points\nAverage intensity 2.129929e-06 points per square unit\n\nCoordinates are given to 11 decimal places\n\nmarks are of type 'character'\nSummary:\n   Length     Class      Mode \n     1545 character character \n\nWindow: polygonal boundary\n50 separate polygons (1 hole)\n                 vertices         area relative.area\npolygon 1 (hole)       30     -7081.18     -9.76e-06\npolygon 2              55     82537.90      1.14e-04\npolygon 3              90    415092.00      5.72e-04\npolygon 4              49     16698.60      2.30e-05\npolygon 5              38     24249.20      3.34e-05\npolygon 6             976  23344700.00      3.22e-02\npolygon 7             721   1927950.00      2.66e-03\npolygon 8            1992   9992170.00      1.38e-02\npolygon 9             330   1118960.00      1.54e-03\npolygon 10            175    925904.00      1.28e-03\npolygon 11            115    928394.00      1.28e-03\npolygon 12             24      6352.39      8.76e-06\npolygon 13            190    202489.00      2.79e-04\npolygon 14             37     10170.50      1.40e-05\npolygon 15             25     16622.70      2.29e-05\npolygon 16             10      2145.07      2.96e-06\npolygon 17             66     16184.10      2.23e-05\npolygon 18           5195 636837000.00      8.78e-01\npolygon 19             76    312332.00      4.31e-04\npolygon 20            627  31891300.00      4.40e-02\npolygon 21             20     32842.00      4.53e-05\npolygon 22             42     55831.70      7.70e-05\npolygon 23             67   1313540.00      1.81e-03\npolygon 24            734   4690930.00      6.47e-03\npolygon 25             16      3194.60      4.40e-06\npolygon 26             15      4872.96      6.72e-06\npolygon 27             15      4464.20      6.15e-06\npolygon 28             14      5466.74      7.54e-06\npolygon 29             37      5261.94      7.25e-06\npolygon 30            111    662927.00      9.14e-04\npolygon 31             69     56313.40      7.76e-05\npolygon 32            143    145139.00      2.00e-04\npolygon 33            397   2488210.00      3.43e-03\npolygon 34             90    115991.00      1.60e-04\npolygon 35             98     62682.90      8.64e-05\npolygon 36            165    338736.00      4.67e-04\npolygon 37            130     94046.50      1.30e-04\npolygon 38             93    430642.00      5.94e-04\npolygon 39             16      2010.46      2.77e-06\npolygon 40            415   3253840.00      4.49e-03\npolygon 41             30     10838.20      1.49e-05\npolygon 42             53     34400.30      4.74e-05\npolygon 43             26      8347.58      1.15e-05\npolygon 44             74     58223.40      8.03e-05\npolygon 45            327   2169210.00      2.99e-03\npolygon 46            177    467446.00      6.44e-04\npolygon 47             46    699702.00      9.65e-04\npolygon 48              6     16841.00      2.32e-05\npolygon 49             13     70087.30      9.66e-05\npolygon 50              4      9459.63      1.30e-05\nenclosing rectangle: [2663.93, 56047.79] x [16357.98, 50244.03] units\n                     (53380 x 33890 units)\nWindow area = 725376000 square units\nFraction of frame area: 0.401\n\nplot(childcare_ppp)\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 1545 symbols are shown in the symbol map"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#kernel-density-estimation",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#kernel-density-estimation",
    "title": "Hands-on Exercise 02",
    "section": "Kernel Density Estimation",
    "text": "Kernel Density Estimation\n\nkde_childcareSG_bw &lt;- density(childcareSG_ppp,\n                              sigma=bw.diggle,\n                              edge=TRUE,\n                            kernel=\"gaussian\") \nplot(kde_childcareSG_bw)\n\n\n\nbw &lt;- bw.diggle(childcareSG_ppp)\nbw\n\n   sigma \n298.4095"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#rescaling-kde-values",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#rescaling-kde-values",
    "title": "Hands-on Exercise 02",
    "section": "Rescaling KDE values",
    "text": "Rescaling KDE values\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG.bw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#different-automatic-bandwidth-methods",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#different-automatic-bandwidth-methods",
    "title": "Hands-on Exercise 02",
    "section": "Different Automatic Bandwidth methods",
    "text": "Different Automatic Bandwidth methods\n\n bw.CvL(childcareSG_ppp.km)\n\n   sigma \n4.543278 \n\n bw.scott(childcareSG_ppp.km)\n\n sigma.x  sigma.y \n2.224898 1.450966 \n\n bw.ppl(childcareSG_ppp.km)\n\n    sigma \n0.3897114 \n\n bw.diggle(childcareSG_ppp.km)\n\n    sigma \n0.2984095 \n\n\n\nkde_childcareSG.ppl &lt;- density(childcareSG_ppp.km, \n                               sigma=bw.ppl, \n                               edge=TRUE,\n                               kernel=\"gaussian\")\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"bw.diggle\")\nplot(kde_childcareSG.ppl, main = \"bw.ppl\")\n\n\n\n\nCompute 3 more KDEs using 3 different kernel functions. These are basically shapes of each point smoothing.\n\npar(mfrow=c(2,2))\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"gaussian\"), \n     main=\"Gaussian\")\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"epanechnikov\"), \n     main=\"Epanechnikov\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"quartic\"), \n     main=\"Quartic\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel\n\nplot(density(childcareSG_ppp.km, \n             sigma=bw.ppl, \n             edge=TRUE, \n             kernel=\"disc\"), \n     main=\"Disc\")\n\nWarning in density.ppp(childcareSG_ppp.km, sigma = bw.ppl, edge = TRUE, :\nBandwidth selection will be based on Gaussian kernel"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-fixed-first",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#using-fixed-first",
    "title": "Hands-on Exercise 02",
    "section": "using Fixed first",
    "text": "using Fixed first\n\nkde_childcareSG_600 &lt;- density(childcareSG_ppp.km, sigma=0.6, edge=TRUE, kernel=\"gaussian\")\nplot(kde_childcareSG_600)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#now-adaptive",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#now-adaptive",
    "title": "Hands-on Exercise 02",
    "section": "now adaptive",
    "text": "now adaptive\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\n\nInteresting observation: Adaptive takes longer to compute! Understandably so.\n\npar(mfrow=c(1,2))\nplot(kde_childcareSG.bw, main = \"Fixed bandwidth\")\nplot(kde_childcareSG_adaptive, main = \"Adaptive bandwidth\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#converting-kde-output-into-grid-object",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#converting-kde-output-into-grid-object",
    "title": "Hands-on Exercise 02",
    "section": "Converting KDE output into grid object",
    "text": "Converting KDE output into grid object\n\nlibrary(spatstat)\ngridded_kde_childcareSG_bw &lt;- as.im(kde_childcareSG.bw)\nplot(gridded_kde_childcareSG_bw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#converting-into-raster",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#converting-into-raster",
    "title": "Hands-on Exercise 02",
    "section": "Converting into raster",
    "text": "Converting into raster\n\nlibrary(raster)\nkde_childcareSG_bw_raster &lt;- raster(kde_childcareSG.bw)\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : NA \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)\n\n\ncrs is NA! It shouldn’t be. Let’s complete it.\n\nprojection(kde_childcareSG_bw_raster) &lt;- CRS(\"+init=EPSG:3414\")\nkde_childcareSG_bw_raster\n\nclass      : RasterLayer \ndimensions : 128, 128, 16384  (nrow, ncol, ncell)\nresolution : 0.4170614, 0.2647348  (x, y)\nextent     : 2.663926, 56.04779, 16.35798, 50.24403  (xmin, xmax, ymin, ymax)\ncrs        : +proj=tmerc +lat_0=1.36666666666667 +lon_0=103.833333333333 +k=1 +x_0=28001.642 +y_0=38744.572 +ellps=WGS84 +units=m +no_defs \nsource     : memory\nnames      : layer \nvalues     : -8.476185e-15, 28.51831  (min, max)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#time-to-map",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#time-to-map",
    "title": "Hands-on Exercise 02",
    "section": "Time to map!",
    "text": "Time to map!\n\nlibrary(tmap)\ntm_shape(kde_childcareSG_bw_raster) + \n  tm_raster(\"layer\", palette = \"viridis\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\"), frame = FALSE)\n\nlegend.postion is used for plot mode. Use view.legend.position in tm_view to set the legend position in view mode."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#compare-spatial-point-patterns-using-kde",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#compare-spatial-point-patterns-using-kde",
    "title": "Hands-on Exercise 02",
    "section": "Compare spatial point patterns using KDE",
    "text": "Compare spatial point patterns using KDE\n\nlibrary(dplyr)\npg &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\")\ntm &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"TAMPINES\")\nck &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"CHOA CHU KANG\")\njw &lt;- mpsz_sf %&gt;%\n  filter(PLN_AREA_N == \"JURONG WEST\")\npar(mfrow=c(2,2))\nplot(pg, main = \"Ponggol\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\n\n\nplot(tm, main = \"Tampines\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\nplot(ck, main = \"Choa Chu Kang\")\n\nWarning: plotting the first 10 out of 15 attributes; use max.plot = 15 to plot\nall\n\n\n\n\nplot(jw, main = \"Jurong West\")\n\nWarning: plotting the first 9 out of 15 attributes; use max.plot = 15 to plot\nall"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#owin-object-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#owin-object-1",
    "title": "Hands-on Exercise 02",
    "section": "owin object",
    "text": "owin object\n\npg_owin = as.owin(pg)\ntm_owin = as.owin(tm)\nck_owin = as.owin(ck)\njw_owin = as.owin(jw)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-childcare-points-and-study-area",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#combining-childcare-points-and-study-area",
    "title": "Hands-on Exercise 02",
    "section": "Combining childcare points and study area",
    "text": "Combining childcare points and study area\n\nchildcare_pg_ppp = childcare_ppp_jit[pg_owin]\nchildcare_tm_ppp = childcare_ppp_jit[tm_owin]\nchildcare_ck_ppp = childcare_ppp_jit[ck_owin]\nchildcare_jw_ppp = childcare_ppp_jit[jw_owin]\nchildcare_pg_ppp.km = rescale.ppp(childcare_pg_ppp, 1000, \"km\")\nchildcare_tm_ppp.km = rescale.ppp(childcare_tm_ppp, 1000, \"km\")\nchildcare_ck_ppp.km = rescale.ppp(childcare_ck_ppp, 1000, \"km\")\nchildcare_jw_ppp.km = rescale.ppp(childcare_jw_ppp, 1000, \"km\")\npar(mfrow=c(2,2))\nplot(childcare_pg_ppp.km, main=\"Punggol\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_tm_ppp.km, main=\"Tampines\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 89 symbols are shown in the symbol map\n\nplot(childcare_ck_ppp.km, main=\"Choa Chu Kang\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\nplot(childcare_jw_ppp.km, main=\"Jurong West\")\n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 88 symbols are shown in the symbol map\n\n\n\n\npar(mfrow=c(2,2))\nplot(density(childcare_pg_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tempines\")\nplot(density(childcare_ck_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Choa Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=bw.diggle, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#fixed-bandwidth",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#fixed-bandwidth",
    "title": "Hands-on Exercise 02",
    "section": "Fixed Bandwidth",
    "text": "Fixed Bandwidth\n\npar(mfrow=c(2,2))\nplot(density(childcare_ck_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Chou Chu Kang\")\nplot(density(childcare_jw_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"JUrong West\")\nplot(density(childcare_pg_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Punggol\")\nplot(density(childcare_tm_ppp.km, \n             sigma=0.25, \n             edge=TRUE, \n             kernel=\"gaussian\"),\n     main=\"Tampines\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#nn",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#nn",
    "title": "Hands-on Exercise 02",
    "section": "NN",
    "text": "NN\nnearest neighbour\n\nclarkevans.test(childcareSG_ppp,\n                correction=\"none\",\n                clipregion=\"sg_owin\",\n                alternative=c(\"clustered\"),\n                nsim=99)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcareSG_ppp\nR = 0.55631, p-value &lt; 2.2e-16\nalternative hypothesis: clustered (R &lt; 1)\n\n\nThe Clark and Evans test is used to analyse spatial point patterns to determine if the points are randomly distributed, clustered, or regularly spaced. R = 0.55631: The value of R (the ratio of the observed mean nearest neighbour distance to the expected mean nearest neighbour distance under complete spatial randomness) is less than 1. When R, it suggests that the points are more clustered than would be expected under a random distribution.\nThe p-value is extremely small, indicating that the result is statistically significant. In other words, there is strong evidence against the null hypothesis of complete spatial randomness.\nAlternative hypothesis: clustered (R &lt; 1): The test was conducted under the alternative hypothesis that the points are clustered. Given the significant p-value and R, the conclusion supports the alternative hypothesis that the points are indeed clustered.\nBased on the Clark and Evans test, I can conclude that the spatial point pattern of `childcareSG_ppp` is significantly clustered, meaning that the points tend to occur closer together than would be expected if they were randomly distributed across the space.\nFocus on CCK\n\nclarkevans.test(childcare_ck_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_ck_ppp\nR = 0.95041, p-value = 0.4587\nalternative hypothesis: two-sided\n\n\nNow focus on tampines\n\nclarkevans.test(childcare_tm_ppp,\n                correction=\"none\",\n                clipregion=NULL,\n                alternative=c(\"two.sided\"),\n                nsim=999)\n\n\n    Clark-Evans test\n    No edge correction\n    Z-test\n\ndata:  childcare_tm_ppp\nR = 0.80393, p-value = 0.0004022\nalternative hypothesis: two-sided"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-g-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-g-function",
    "title": "Hands-on Exercise 02",
    "section": "Analysing Spatial Point Process Using G-Function",
    "text": "Analysing Spatial Point Process Using G-Function\n\nG_CK = Gest(childcare_ck_ppp, correction = \"border\")\nplot(G_CK, xlim=c(0,500))\n\n\n\n\nThe steeper rise of the observed G-function at shorter distances suggests that points are more likely to have close neighbors than would be expected under complete spatial randomness, indicating clustering in the childcare center locations. This analysis provides insights into the spatial distribution of childcare centers, suggesting a clustered pattern rather than a completely random distribution."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#performing-complete-spatial-randomness-test",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#performing-complete-spatial-randomness-test",
    "title": "Hands-on Exercise 02",
    "section": "Performing Complete Spatial Randomness Test",
    "text": "Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with G-fucntion\n\nG_CK.csr &lt;- envelope(childcare_ck_ppp, Gest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\n\nAmazing! Just one line of code!\n\nplot(G_CK.csr)\n\n\n\n\nLet’s move on to Tampines.\n\nG_tm = Gest(childcare_tm_ppp, correction = \"best\")\nplot(G_tm)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#performing-complete-spatial-randomness-test-1",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#performing-complete-spatial-randomness-test-1",
    "title": "Hands-on Exercise 02",
    "section": "Performing Complete Spatial Randomness Test",
    "text": "Performing Complete Spatial Randomness Test\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Tampines are randomly distributed.\nH1= The distribution of childcare services at Tampines are not randomly distributed.\nThe null hypothesis will be rejected is p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nG_tm.csr &lt;- envelope(childcare_tm_ppp, Gest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(G_tm.csr)\n\n\n\n\nWow. Powerful stuff!\nThe observed G-function (black line) stays mostly within the grey envelope but deviates slightly towards the upper edge at certain distances. This suggests that while there may be some minor clustering in the pattern, the deviation is not strong enough to conclusively reject the hypothesis of CSR, at least not across the entire range of r. The fact that the observed G-function approaches the upper boundary of the envelope suggests a tendency towards clustering, but it does not seem pronounced enough to confirm significant clustering.\nThe CSR test via envelope analysis suggests that the observed point pattern is not significantly different from a random distribution (CSR) at the 95% confidence level, although there is a slight indication of clustering. This could mean that the pattern has some minor clustering tendencies but not strong enough to reject CSR."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-f-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-f-function",
    "title": "Hands-on Exercise 02",
    "section": "Analysing Spatial Point Process Using F-Function",
    "text": "Analysing Spatial Point Process Using F-Function\n\nF_CK = Fest(childcare_ck_ppp)\nplot(F_CK)\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nMonte Carlo test with F-fucntion\n\nF_CK.csr &lt;- envelope(childcare_ck_ppp, Fest, nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_CK.csr)\n\n\n\n\nNow for Tampines\n\nF_tm = Fest(childcare_tm_ppp, correction = \"best\")\nplot(F_tm)\n\n\n\n\n\nF_tm.csr &lt;- envelope(childcare_tm_ppp, Fest, correction = \"all\", nsim = 999)\n\nGenerating 999 simulations of CSR  ...\n1, 2, 3, ......10.........20.........30.........40.........50.........60..\n.......70.........80.........90.........100.........110.........120.........130\n.........140.........150.........160.........170.........180.........190........\n.200.........210.........220.........230.........240.........250.........260......\n...270.........280.........290.........300.........310.........320.........330....\n.....340.........350.........360.........370.........380.........390.........400..\n.......410.........420.........430.........440.........450.........460.........470\n.........480.........490.........500.........510.........520.........530........\n.540.........550.........560.........570.........580.........590.........600......\n...610.........620.........630.........640.........650.........660.........670....\n.....680.........690.........700.........710.........720.........730.........740..\n.......750.........760.........770.........780.........790.........800.........810\n.........820.........830.........840.........850.........860.........870........\n.880.........890.........900.........910.........920.........930.........940......\n...950.........960.........970.........980.........990........\n999.\n\nDone.\n\nplot(F_tm.csr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-k-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-k-function",
    "title": "Hands-on Exercise 02",
    "section": "Analysing Spatial Point Process Using K-Function",
    "text": "Analysing Spatial Point Process Using K-Function\n\nK_ck = Kest(childcare_ck_ppp, correction = \"Ripley\")\nplot(K_ck, . -r ~ r, ylab= \"K(d)-r\", xlab = \"d(m)\")\n\n\n\n\nTo confirm the observed spatial patterns above, a hypothesis test will be conducted. The hypothesis and test are as follows:\nHo = The distribution of childcare services at Choa Chu Kang are randomly distributed.\nH1= The distribution of childcare services at Choa Chu Kang are not randomly distributed.\nThe null hypothesis will be rejected if p-value is smaller than alpha value of 0.001.\nThe code chunk below is used to perform the hypothesis testing.\n\nK_ck.csr &lt;- envelope(childcare_ck_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"K(d)-r\")\n\n\n\n\n\nK_tm = Kest(childcare_tm_ppp, correction = \"Ripley\")\nplot(K_tm, . -r ~ r, \n     ylab= \"K(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\nK_tm.csr &lt;- envelope(childcare_tm_ppp, Kest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(K_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"K(d)-r\", xlim=c(0,500))"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-l-function",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html#analysing-spatial-point-process-using-l-function",
    "title": "Hands-on Exercise 02",
    "section": "Analysing Spatial Point Process Using L-Function",
    "text": "Analysing Spatial Point Process Using L-Function\n\nL_ck = Lest(childcare_ck_ppp, correction = \"Ripley\")\nplot(L_ck, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\")\n\n\n\n\n\nL_ck.csr &lt;- envelope(childcare_ck_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\n\n\nplot(L_ck.csr, . - r ~ r, xlab=\"d\", ylab=\"L(d)-r\")\n\n\n\n\n\nL_tm = Lest(childcare_tm_ppp, correction = \"Ripley\")\nplot(L_tm, . -r ~ r, \n     ylab= \"L(d)-r\", xlab = \"d(m)\", \n     xlim=c(0,1000))\n\n\n\n\n\nL_tm.csr &lt;- envelope(childcare_tm_ppp, Lest, nsim = 99, rank = 1, glocal=TRUE)\n\nGenerating 99 simulations of CSR  ...\n1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,\n41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60,\n61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, \n99.\n\nDone.\n\nplot(L_tm.csr, . - r ~ r, \n     xlab=\"d\", ylab=\"L(d)-r\", xlim=c(0,500))\n\n\n\n\nThat ends hands-on exercise 2."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#examine-plot",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#examine-plot",
    "title": "Hands-on Exercise 03",
    "section": "Examine plot",
    "text": "Examine plot\n\nplot(st_geometry(network))\nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\nCool!\nLet’s look at it in leaflet form\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +\n  tm_dots() +\n  tm_shape(network) +\n  tm_lines()\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#lixelization",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#lixelization",
    "title": "Hands-on Exercise 03",
    "section": "Lixelization",
    "text": "Lixelization\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\nLixel lines are a concept used in spatial analysis, particularly in network-based analysis.\n\nLixels: This term is a combination of “line” and “pixel”. Just as a pixel is the smallest unit of a raster image, a lixel is the smallest unit of a line in a network.\nPurpose: Lixels are used to discretise continuous linear features (like roads or rivers) into smaller, equal-length segments. This discretization is often necessary for certain types of spatial analysis, especially when working with network data.\nNKDE (Network Kernel Density Estimation): This is a method used to estimate the density of events or phenomena along a network. Before applying NKDE, it’s often necessary to break down the network into these smaller units (lixels) for more accurate analysis.\nMinimal distance: When creating lixels, you specify a minimal distance. This is the length of each lixel segment. The lines in your network will be cut into segments of this length.\nspNetwork package: This is the library that provides functions for spatial network analysis. The lixelize_lines() function is used to perform this lixelization process.\nSpatialLines object: This is a data structure used to represent linear features in a spatial context. The lixelization process is applied to this object.\n\nThe process of creating lixels allows for more precise analysis along a network, as it creates a consistent unit of measurement and analysis along potentially irregular network structures. This can be particularly useful in applications like traffic analysis, crime mapping along street networks, or analyzing the spread of phenomena along river systems. In this case, I will be looking at childcare centres.\n\nlixels &lt;- lixelize_lines(network, \n                         700, \n                         mindist = 375)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#line-centre-points",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#line-centre-points",
    "title": "Hands-on Exercise 03",
    "section": "Line centre points",
    "text": "Line centre points\n\nsamples &lt;- lines_center(lixels)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#actual-nkde",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html#actual-nkde",
    "title": "Hands-on Exercise 03",
    "section": "Actual NKDE",
    "text": "Actual NKDE\n\ndensities &lt;- nkde(network, \n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 300, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(1,1), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\n\nLet’s examine and visualise the NKDE\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities\nsummary(samples$density)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.000e+00 0.000e+00 1.424e-06 3.787e-06 7.430e-06 2.405e-05 \n\nsummary(lixels$density)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.000e+00 0.000e+00 1.424e-06 3.787e-06 7.430e-06 2.405e-05 \n\n\nThat looks really small. Let’s change it to events per KM.\n\n# rescaling to help the mapping\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\nsummary(samples$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.001424 0.003787 0.007430 0.024046 \n\nsummary(lixels$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.001424 0.003787 0.007430 0.024046 \n\n\nOk. Looks better. Let’s visualise it.\n\ntmap_mode('view')\n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\ntm_shape(childcare)+\n  tm_dots()\n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html",
    "title": "Hands-on Exercise 04",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)\n\n\n\n\n\nhunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nhunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#load-packages",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#load-packages",
    "title": "Hands-on Exercise 04",
    "section": "",
    "text": "pacman::p_load(sf, spdep, tmap, tidyverse, knitr)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#importing-data",
    "title": "Hands-on Exercise 04",
    "section": "",
    "text": "hunan &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#left-join",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#left-join",
    "title": "Hands-on Exercise 04",
    "section": "",
    "text": "hunan &lt;- left_join(hunan, hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-queen",
    "title": "Hands-on Exercise 04",
    "section": "Computing QUEEN",
    "text": "Computing QUEEN\n\nwm_q &lt;- poly2nb(hunan, queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one heighbours.\nFor each polygon in our polygon object, wm_q lists all neighboring polygons. For example, to see the neighbors for the first polygon in the object, type:\n\nwm_q[[1]]\n\n[1]  2  3  4 57 85\n\n\nPolygon 1 has 5 neighbors. The numbers represent the polygon IDs as stored in hunan SpatialPolygonsDataFrame class.\nWe can retrive the county name of Polygon ID=1 by using the code chunk below:\n\nhunan$County[1]\n\n[1] \"Anxiang\"\n\n\nTo reveal the county names of the five neighboring polygons, the code chunk will be used, then we can retrieve the GDPPC of these five countries by using the code chunk below.\n\nhunan$NAME_3[c(2,3,4,57,85)]\n\n[1] \"Hanshou\" \"Jinshi\"  \"Li\"      \"Nan\"     \"Taoyuan\"\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-rook",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-rook",
    "title": "Hands-on Exercise 04",
    "section": "Computing ROOK",
    "text": "Computing ROOK\n\nwm_r &lt;- poly2nb(hunan, queen=FALSE)\nsummary(wm_r)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 440 \nPercentage nonzero weights: 5.681818 \nAverage number of links: 5 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 10 \n 2  2 12 20 21 14 11  3  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 10 links\n\n\n\nVisualising contiguity weights\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\nhead(coords)\n\n     longitude latitude\n[1,]  112.1531 29.44362\n[2,]  112.0372 28.86489\n[3,]  111.8917 29.47107\n[4,]  111.7031 29.74499\n[5,]  111.6138 29.49258\n[6,]  111.0341 29.79863\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\n\n\n\n\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#a-look-at-queen-and-rook-contiguity",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#a-look-at-queen-and-rook-contiguity",
    "title": "Hands-on Exercise 04",
    "section": "A look at queen and rook contiguity",
    "text": "A look at queen and rook contiguity\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"Queen Contiguity\")\nplot(wm_q, coords, pch = 19, cex = 0.6, add = TRUE, col= \"red\")\nplot(hunan$geometry, border=\"lightgrey\", main=\"Rook Contiguity\")\nplot(wm_r, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#cut-off-distance",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#cut-off-distance",
    "title": "Hands-on Exercise 04",
    "section": "Cut off distance",
    "text": "Cut off distance\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#computing-fixed-distance-weight-matrix",
    "title": "Hands-on Exercise 04",
    "section": "Computing fixed distance weight matrix",
    "text": "Computing fixed distance weight matrix\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\n\nThe value 3.681818 means that, on average, each region in the dataset has approximately 3.68 neighbours. This is derived by dividing the total number of links (324) by the number of regions (88). Some regions may have more or fewer neighbours, but on average, they each have about 3.68 connections with other regions.\n\ntable(hunan$County, card(wm_d62))\n\n               \n                1 2 3 4 5 6\n  Anhua         1 0 0 0 0 0\n  Anren         0 0 0 1 0 0\n  Anxiang       0 0 0 0 1 0\n  Baojing       0 0 0 0 1 0\n  Chaling       0 0 1 0 0 0\n  Changning     0 0 1 0 0 0\n  Changsha      0 0 0 1 0 0\n  Chengbu       0 1 0 0 0 0\n  Chenxi        0 0 0 1 0 0\n  Cili          0 1 0 0 0 0\n  Dao           0 0 0 1 0 0\n  Dongan        0 0 1 0 0 0\n  Dongkou       0 0 0 1 0 0\n  Fenghuang     0 0 0 1 0 0\n  Guidong       0 0 1 0 0 0\n  Guiyang       0 0 0 1 0 0\n  Guzhang       0 0 0 0 0 1\n  Hanshou       0 0 0 1 0 0\n  Hengdong      0 0 0 0 1 0\n  Hengnan       0 0 0 0 1 0\n  Hengshan      0 0 0 0 0 1\n  Hengyang      0 0 0 0 0 1\n  Hongjiang     0 0 0 0 1 0\n  Huarong       0 0 0 1 0 0\n  Huayuan       0 0 0 1 0 0\n  Huitong       0 0 0 1 0 0\n  Jiahe         0 0 0 0 1 0\n  Jianghua      0 0 1 0 0 0\n  Jiangyong     0 1 0 0 0 0\n  Jingzhou      0 1 0 0 0 0\n  Jinshi        0 0 0 1 0 0\n  Jishou        0 0 0 0 0 1\n  Lanshan       0 0 0 1 0 0\n  Leiyang       0 0 0 1 0 0\n  Lengshuijiang 0 0 1 0 0 0\n  Li            0 0 1 0 0 0\n  Lianyuan      0 0 0 0 1 0\n  Liling        0 1 0 0 0 0\n  Linli         0 0 0 1 0 0\n  Linwu         0 0 0 1 0 0\n  Linxiang      1 0 0 0 0 0\n  Liuyang       0 1 0 0 0 0\n  Longhui       0 0 1 0 0 0\n  Longshan      0 1 0 0 0 0\n  Luxi          0 0 0 0 1 0\n  Mayang        0 0 0 0 0 1\n  Miluo         0 0 0 0 1 0\n  Nan           0 0 0 0 1 0\n  Ningxiang     0 0 0 1 0 0\n  Ningyuan      0 0 0 0 1 0\n  Pingjiang     0 1 0 0 0 0\n  Qidong        0 0 1 0 0 0\n  Qiyang        0 0 1 0 0 0\n  Rucheng       0 1 0 0 0 0\n  Sangzhi       0 1 0 0 0 0\n  Shaodong      0 0 0 0 1 0\n  Shaoshan      0 0 0 0 1 0\n  Shaoyang      0 0 0 1 0 0\n  Shimen        1 0 0 0 0 0\n  Shuangfeng    0 0 0 0 0 1\n  Shuangpai     0 0 0 1 0 0\n  Suining       0 0 0 0 1 0\n  Taojiang      0 1 0 0 0 0\n  Taoyuan       0 1 0 0 0 0\n  Tongdao       0 1 0 0 0 0\n  Wangcheng     0 0 0 1 0 0\n  Wugang        0 0 1 0 0 0\n  Xiangtan      0 0 0 1 0 0\n  Xiangxiang    0 0 0 0 1 0\n  Xiangyin      0 0 0 1 0 0\n  Xinhua        0 0 0 0 1 0\n  Xinhuang      1 0 0 0 0 0\n  Xinning       0 1 0 0 0 0\n  Xinshao       0 0 0 0 0 1\n  Xintian       0 0 0 0 1 0\n  Xupu          0 1 0 0 0 0\n  Yanling       0 0 1 0 0 0\n  Yizhang       1 0 0 0 0 0\n  Yongshun      0 0 0 1 0 0\n  Yongxing      0 0 0 1 0 0\n  You           0 0 0 1 0 0\n  Yuanjiang     0 0 0 0 1 0\n  Yuanling      1 0 0 0 0 0\n  Yueyang       0 0 1 0 0 0\n  Zhijiang      0 0 0 0 1 0\n  Zhongfang     0 0 0 1 0 0\n  Zhuzhou       0 0 0 0 1 0\n  Zixing        0 0 1 0 0 0\n\n\n\nPlotting fixed distance weight matrix\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(wm_d62, coords, add=TRUE)\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\n\n\n\n\n\npar(mfrow=c(1,2))\nplot(hunan$geometry, border=\"lightgrey\", main=\"1st nearest neighbours\")\nplot(k1, coords, add=TRUE, col=\"red\", length=0.08)\nplot(hunan$geometry, border=\"lightgrey\", main=\"Distance link\")\nplot(wm_d62, coords, add=TRUE, pch = 19, cex = 0.6)\n\n\n\n\n\n\nComputing adaptive distance weight matrix\n\nknn6 &lt;- knn2nb(knearneigh(coords, k=6))\nknn6\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 528 \nPercentage nonzero weights: 6.818182 \nAverage number of links: 6 \nNon-symmetric neighbours list\n\nplot(hunan$geometry, border=\"lightgrey\")\nplot(knn6, coords, pch = 19, cex = 0.6, add = TRUE, col = \"red\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#weights-based-on-idw",
    "title": "Hands-on Exercise 04",
    "section": "Weights based on IDW",
    "text": "Weights based on IDW\n\ndist &lt;- nbdists(wm_q, coords, longlat = TRUE)\nids &lt;- lapply(dist, function(x) 1/(x))\nids\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\n[[2]]\n[1] 0.01535405 0.01764308 0.01925924 0.02323898 0.01719350\n\n[[3]]\n[1] 0.03916350 0.02822040 0.03695795 0.01395765\n\n[[4]]\n[1] 0.01820896 0.02822040 0.03414741 0.01539065\n\n[[5]]\n[1] 0.03695795 0.03414741 0.01524598 0.01618354\n\n[[6]]\n[1] 0.015390649 0.015245977 0.021748129 0.011883901 0.009810297\n\n[[7]]\n[1] 0.01708612 0.01473997 0.01150924 0.01872915\n\n[[8]]\n[1] 0.02022144 0.03453056 0.02529256 0.01036340 0.02284457 0.01500600 0.01515314\n\n[[9]]\n[1] 0.02022144 0.01574888 0.02109502 0.01508028 0.02902705 0.01502980\n\n[[10]]\n[1] 0.02281552 0.01387777 0.01538326 0.01346650 0.02100510 0.02631658 0.01874863\n[8] 0.01500046\n\n[[11]]\n[1] 0.01882869 0.02243492 0.02247473\n\n[[12]]\n[1] 0.02779227 0.02419652 0.02333385 0.02986130 0.02335429\n\n[[13]]\n[1] 0.02779227 0.02650020 0.02670323 0.01714243\n\n[[14]]\n[1] 0.01882869 0.01233868 0.02098555\n\n[[15]]\n[1] 0.02650020 0.01233868 0.01096284 0.01562226\n\n[[16]]\n[1] 0.02281552 0.02466962 0.02765018 0.01476814 0.01671430\n\n[[17]]\n[1] 0.01387777 0.02243492 0.02098555 0.01096284 0.02466962 0.01593341 0.01437996\n\n[[18]]\n[1] 0.02039779 0.02032767 0.01481665 0.01473691 0.01459380\n\n[[19]]\n[1] 0.01538326 0.01926323 0.02668415 0.02140253 0.01613589 0.01412874\n\n[[20]]\n[1] 0.01346650 0.02039779 0.01926323 0.01723025 0.02153130 0.01469240 0.02327034\n\n[[21]]\n[1] 0.02668415 0.01723025 0.01766299 0.02644986 0.02163800\n\n[[22]]\n[1] 0.02100510 0.02765018 0.02032767 0.02153130 0.01489296\n\n[[23]]\n[1] 0.01481665 0.01469240 0.01401432 0.02246233 0.01880425 0.01530458 0.01849605\n\n[[24]]\n[1] 0.02354598 0.01837201 0.02607264 0.01220154 0.02514180\n\n[[25]]\n[1] 0.02354598 0.02188032 0.01577283 0.01949232 0.02947957\n\n[[26]]\n[1] 0.02155798 0.01745522 0.02212108 0.02220532\n\n[[27]]\n[1] 0.02155798 0.02490625 0.01562326\n\n[[28]]\n[1] 0.01837201 0.02188032 0.02229549 0.03076171 0.02039506\n\n[[29]]\n[1] 0.02490625 0.01686587 0.01395022\n\n[[30]]\n[1] 0.02090587\n\n[[31]]\n[1] 0.02607264 0.01577283 0.01219005 0.01724850 0.01229012 0.01609781 0.01139438\n[8] 0.01150130\n\n[[32]]\n[1] 0.01220154 0.01219005 0.01712515 0.01340413 0.01280928 0.01198216 0.01053374\n[8] 0.01065655\n\n[[33]]\n[1] 0.01949232 0.01745522 0.02229549 0.02090587 0.01979045\n\n[[34]]\n[1] 0.03113041 0.03589551 0.02882915\n\n[[35]]\n[1] 0.01766299 0.02185795 0.02616766 0.02111721 0.02108253 0.01509020\n\n[[36]]\n[1] 0.01724850 0.03113041 0.01571707 0.01860991 0.02073549 0.01680129\n\n[[37]]\n[1] 0.01686587 0.02234793 0.01510990 0.01550676\n\n[[38]]\n[1] 0.01401432 0.02407426 0.02276151 0.01719415\n\n[[39]]\n[1] 0.01229012 0.02172543 0.01711924 0.02629732 0.01896385\n\n[[40]]\n[1] 0.01609781 0.01571707 0.02172543 0.01506473 0.01987922 0.01894207\n\n[[41]]\n[1] 0.02246233 0.02185795 0.02205991 0.01912542 0.01601083 0.01742892\n\n[[42]]\n[1] 0.02212108 0.01562326 0.01395022 0.02234793 0.01711924 0.01836831 0.01683518\n\n[[43]]\n[1] 0.01510990 0.02629732 0.01506473 0.01836831 0.03112027 0.01530782\n\n[[44]]\n[1] 0.01550676 0.02407426 0.03112027 0.01486508\n\n[[45]]\n[1] 0.03589551 0.01860991 0.01987922 0.02205991 0.02107101 0.01982700\n\n[[46]]\n[1] 0.03453056 0.04033752 0.02689769\n\n[[47]]\n[1] 0.02529256 0.02616766 0.04033752 0.01949145 0.02181458\n\n[[48]]\n[1] 0.02313819 0.03370576 0.02289485 0.01630057 0.01818085\n\n[[49]]\n[1] 0.03076171 0.02138091 0.02394529 0.01990000\n\n[[50]]\n[1] 0.01712515 0.02313819 0.02551427 0.02051530 0.02187179\n\n[[51]]\n[1] 0.03370576 0.02138091 0.02873854\n\n[[52]]\n[1] 0.02289485 0.02394529 0.02551427 0.02873854 0.03516672\n\n[[53]]\n[1] 0.01630057 0.01979945 0.01253977\n\n[[54]]\n[1] 0.02514180 0.02039506 0.01340413 0.01990000 0.02051530 0.03516672\n\n[[55]]\n[1] 0.01280928 0.01818085 0.02187179 0.01979945 0.01882298\n\n[[56]]\n[1] 0.01036340 0.01139438 0.01198216 0.02073549 0.01214479 0.01362855 0.01341697\n\n[[57]]\n[1] 0.028079221 0.017643082 0.031423501 0.029114131 0.013520292 0.009903702\n\n[[58]]\n[1] 0.01925924 0.03142350 0.02722997 0.01434859 0.01567192\n\n[[59]]\n[1] 0.01696711 0.01265572 0.01667105 0.01785036\n\n[[60]]\n[1] 0.02419652 0.02670323 0.01696711 0.02343040\n\n[[61]]\n[1] 0.02333385 0.01265572 0.02343040 0.02514093 0.02790764 0.01219751 0.02362452\n\n[[62]]\n[1] 0.02514093 0.02002219 0.02110260\n\n[[63]]\n[1] 0.02986130 0.02790764 0.01407043 0.01805987\n\n[[64]]\n[1] 0.02911413 0.01689892\n\n[[65]]\n[1] 0.02471705\n\n[[66]]\n[1] 0.01574888 0.01726461 0.03068853 0.01954805 0.01810569\n\n[[67]]\n[1] 0.01708612 0.01726461 0.01349843 0.01361172\n\n[[68]]\n[1] 0.02109502 0.02722997 0.03068853 0.01406357 0.01546511\n\n[[69]]\n[1] 0.02174813 0.01645838 0.01419926\n\n[[70]]\n[1] 0.02631658 0.01963168 0.02278487\n\n[[71]]\n[1] 0.01473997 0.01838483 0.03197403\n\n[[72]]\n[1] 0.01874863 0.02247473 0.01476814 0.01593341 0.01963168\n\n[[73]]\n[1] 0.01500046 0.02140253 0.02278487 0.01838483 0.01652709\n\n[[74]]\n[1] 0.01150924 0.01613589 0.03197403 0.01652709 0.01342099 0.02864567\n\n[[75]]\n[1] 0.011883901 0.010533736 0.012539774 0.018822977 0.016458383 0.008217581\n\n[[76]]\n[1] 0.01352029 0.01434859 0.01689892 0.02471705 0.01954805 0.01349843 0.01406357\n\n[[77]]\n[1] 0.014736909 0.018804247 0.022761507 0.012197506 0.020022195 0.014070428\n[7] 0.008440896\n\n[[78]]\n[1] 0.02323898 0.02284457 0.01508028 0.01214479 0.01567192 0.01546511 0.01140779\n\n[[79]]\n[1] 0.01530458 0.01719415 0.01894207 0.01912542 0.01530782 0.01486508 0.02107101\n\n[[80]]\n[1] 0.01500600 0.02882915 0.02111721 0.01680129 0.01601083 0.01982700 0.01949145\n[8] 0.01362855\n\n[[81]]\n[1] 0.02947957 0.02220532 0.01150130 0.01979045 0.01896385 0.01683518\n\n[[82]]\n[1] 0.02327034 0.02644986 0.01849605 0.02108253 0.01742892\n\n[[83]]\n[1] 0.023354289 0.017142433 0.015622258 0.016714303 0.014379961 0.014593799\n[7] 0.014892965 0.018059871 0.008440896\n\n[[84]]\n[1] 0.01872915 0.02902705 0.01810569 0.01361172 0.01342099 0.01297994\n\n[[85]]\n [1] 0.011451133 0.017193502 0.013957649 0.016183544 0.009810297 0.010656545\n [7] 0.013416965 0.009903702 0.014199260 0.008217581 0.011407794\n\n[[86]]\n[1] 0.01515314 0.01502980 0.01412874 0.02163800 0.01509020 0.02689769 0.02181458\n[8] 0.02864567 0.01297994\n\n[[87]]\n[1] 0.01667105 0.02362452 0.02110260 0.02058034\n\n[[88]]\n[1] 0.01785036 0.02058034"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#row-standardised-weights-matrix",
    "title": "Hands-on Exercise 04",
    "section": "Row-standardised Weights Matrix",
    "text": "Row-standardised Weights Matrix\n\nrswm_q &lt;- nb2listw(wm_q, style=\"W\", zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147\n\n\n\nrswm_q$weights[10]\n\n[[1]]\n[1] 0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125\n\n\nEach neighbor is assigned a 0.125 of the total weight. This means that when R computes the average neighboring income values, each neighbor's income will be multiplied by 0.125 before being tallied.\nUsing the same method, we can also derive a row standardised distance weight matrix by using the code chunk below.\n\nrswm_ids &lt;- nb2listw(wm_q, glist=ids, style=\"B\", zero.policy=TRUE)\nrswm_ids\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn       S0        S1     S2\nB 88 7744 8.786867 0.3776535 3.8137\n\n\n\nrswm_ids$weights[1]\n\n[[1]]\n[1] 0.01535405 0.03916350 0.01820896 0.02807922 0.01145113\n\nsummary(unlist(rswm_ids$weights))\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.008218 0.015088 0.018739 0.019614 0.022823 0.040338"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04.html#application-of-spatial-weight-matrix",
    "title": "Hands-on Exercise 04",
    "section": "Application of Spatial Weight Matrix",
    "text": "Application of Spatial Weight Matrix\n\nSpatial lag with row-standardized weights\n\nGDPPC.lag &lt;- lag.listw(rswm_q, hunan$GDPPC)\nGDPPC.lag\n\n [1] 24847.20 22724.80 24143.25 27737.50 27270.25 21248.80 43747.00 33582.71\n [9] 45651.17 32027.62 32671.00 20810.00 25711.50 30672.33 33457.75 31689.20\n[17] 20269.00 23901.60 25126.17 21903.43 22718.60 25918.80 20307.00 20023.80\n[25] 16576.80 18667.00 14394.67 19848.80 15516.33 20518.00 17572.00 15200.12\n[33] 18413.80 14419.33 24094.50 22019.83 12923.50 14756.00 13869.80 12296.67\n[41] 15775.17 14382.86 11566.33 13199.50 23412.00 39541.00 36186.60 16559.60\n[49] 20772.50 19471.20 19827.33 15466.80 12925.67 18577.17 14943.00 24913.00\n[57] 25093.00 24428.80 17003.00 21143.75 20435.00 17131.33 24569.75 23835.50\n[65] 26360.00 47383.40 55157.75 37058.00 21546.67 23348.67 42323.67 28938.60\n[73] 25880.80 47345.67 18711.33 29087.29 20748.29 35933.71 15439.71 29787.50\n[81] 18145.00 21617.00 29203.89 41363.67 22259.09 44939.56 16902.00 16930.00\n\n\n\nnb1 &lt;- wm_q[[1]]\nnb1 &lt;- hunan$GDPPC[nb1]\nnb1\n\n[1] 20981 34592 24473 21311 22879\n\n\n\nlag.list &lt;- list(hunan$NAME_3, lag.listw(rswm_q, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag.list)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag GDPPC\")\nhunan &lt;- left_join(hunan,lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\nhead(hunan)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 110.4922 ymin: 28.61762 xmax: 112.3013 ymax: 30.12812\nGeodetic CRS:  WGS 84\n   NAME_2  ID_3  NAME_3   ENGTYPE_3  County GDPPC lag GDPPC\n1 Changde 21098 Anxiang      County Anxiang 23667  24847.20\n2 Changde 21100 Hanshou      County Hanshou 20981  22724.80\n3 Changde 21101  Jinshi County City  Jinshi 34592  24143.25\n4 Changde 21102      Li      County      Li 24473  27737.50\n5 Changde 21103   Linli      County   Linli 25554  27270.25\n6 Changde 21104  Shimen      County  Shimen 27137  21248.80\n                        geometry\n1 POLYGON ((112.0625 29.75523...\n2 POLYGON ((112.2288 29.11684...\n3 POLYGON ((111.8927 29.6013,...\n4 POLYGON ((111.3731 29.94649...\n5 POLYGON ((111.6324 29.76288...\n6 POLYGON ((110.8825 30.11675...\n\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_gdppc &lt;- qtm(hunan, \"lag GDPPC\")\ntmap_arrange(gdppc, lag_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\nSpatial lag as a sum of neighboring values\nWe can calculate spatial lag as a sum of neighboring values by assigning binary weights. This requires us to go back to our neighbors list, then apply a function that will assign binary weights, then we use glist = in the nb2listw function to explicitly assign these weights.\nWe start by applying a function that will assign a value of 1 per each neighbor. This is done with lapply, which we have been using to manipulate the neighbors structure throughout the past notebooks. Basically it applies a function across each value in the neighbors structure.\n\nb_weights &lt;- lapply(wm_q, function(x) 0*x + 1)\nb_weights2 &lt;- nb2listw(wm_q, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1    S2\nB 88 7744 448 896 10224\n\n\nWith the proper weights assigned, we can use lag.listw to compute a lag variable from our weight and GDPPC.\n\nlag_sum &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nlag.res &lt;- as.data.frame(lag_sum)\ncolnames(lag.res) &lt;- c(\"NAME_3\", \"lag_sum GDPPC\")\n\nFirst, let us examine the result by using the code chunk below.\n\nlag_sum\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 124236 113624  96573 110950 109081 106244 174988 235079 273907 256221\n[11]  98013 104050 102846  92017 133831 158446 141883 119508 150757 153324\n[21] 113593 129594 142149 100119  82884  74668  43184  99244  46549  20518\n[31] 140576 121601  92069  43258 144567 132119  51694  59024  69349  73780\n[41]  94651 100680  69398  52798 140472 118623 180933  82798  83090  97356\n[51]  59482  77334  38777 111463  74715 174391 150558 122144  68012  84575\n[61] 143045  51394  98279  47671  26360 236917 220631 185290  64640  70046\n[71] 126971 144693 129404 284074 112268 203611 145238 251536 108078 238300\n[81] 108870 108085 262835 248182 244850 404456  67608  33860\n\n\nNext, we will append the lag_sum GDPPC field into hunan sf data frame by using the code chunk below.\nNow, We can plot both the GDPPC and Spatial Lag Sum GDPPC for comparison using the code chunk below.\n\nhunan &lt;- left_join(hunan, lag.res)\n\nJoining with `by = join_by(NAME_3)`\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\nlag_sum_gdppc &lt;- qtm(hunan, \"lag_sum GDPPC\")\ntmap_arrange(gdppc, lag_sum_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\nSpatial window average\nThe spatial window average uses row-standardized weights and includes the diagonal element. To do this in R, we need to go back to the neighbors structure and add the diagonal element before assigning weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\n\nNotice that the Number of nonzero links, Percentage nonzero weights and Average number of links are 536, 6.921488 and 6.090909 respectively as compared to wm_q of 448, 5.785124 and 5.090909\nLet us take a good look at the neighbour list of area [1] by using the code chunk below.\n\nwm_qs[[1]]\n\n[1]  1  2  3  4 57 85\n\n\nNotice that now [1] has six neighbours instead of five.\nNow we obtain weights with nb2listw()\n\nwm_qs &lt;- nb2listw(wm_qs)\nwm_qs\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 30.90265 357.5308\n\n\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\nLastly, we just need to create the lag variable from our weight structure and GDPPC variable.\n\nlag_w_avg_gpdpc &lt;- lag.listw(wm_qs, \n                             hunan$GDPPC)\nlag_w_avg_gpdpc\n\n [1] 24650.50 22434.17 26233.00 27084.60 26927.00 22230.17 47621.20 37160.12\n [9] 49224.71 29886.89 26627.50 22690.17 25366.40 25825.75 30329.00 32682.83\n[17] 25948.62 23987.67 25463.14 21904.38 23127.50 25949.83 20018.75 19524.17\n[25] 18955.00 17800.40 15883.00 18831.33 14832.50 17965.00 17159.89 16199.44\n[33] 18764.50 26878.75 23188.86 20788.14 12365.20 15985.00 13764.83 11907.43\n[41] 17128.14 14593.62 11644.29 12706.00 21712.29 43548.25 35049.00 16226.83\n[49] 19294.40 18156.00 19954.75 18145.17 12132.75 18419.29 14050.83 23619.75\n[57] 24552.71 24733.67 16762.60 20932.60 19467.75 18334.00 22541.00 26028.00\n[65] 29128.50 46569.00 47576.60 36545.50 20838.50 22531.00 42115.50 27619.00\n[73] 27611.33 44523.29 18127.43 28746.38 20734.50 33880.62 14716.38 28516.22\n[81] 18086.14 21244.50 29568.80 48119.71 22310.75 43151.60 17133.40 17009.33\n\n\nNext, we will convert the lag variable listw object into a data.frame by using as.data.frame().\n\nlag.list.wm_qs &lt;- list(hunan$NAME_3, lag.listw(wm_qs, hunan$GDPPC))\nlag_wm_qs.res &lt;- as.data.frame(lag.list.wm_qs)\ncolnames(lag_wm_qs.res) &lt;- c(\"NAME_3\", \"lag_window_avg GDPPC\")\n\nNote: The third command line on the code chunk above renames the field names of lag_wm_q1.res object into NAME_3 and lag_window_avg GDPPC respectively.\nNext, the code chunk below will be used to append lag_window_avg GDPPC values onto hunan sf data.frame by using left_join() of dplyr package.\n\nhunan &lt;- left_join(hunan, lag_wm_qs.res)\n\nJoining with `by = join_by(NAME_3)`\n\n\nTo compare the values of lag GDPPC and Spatial window average, kable() of Knitr package is used to prepare a table using the code chunk below.\n\nhunan %&gt;%\n  dplyr::select(\"County\", \n         \"lag GDPPC\", \n         \"lag_window_avg GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag GDPPC\nlag_window_avg GDPPC\ngeometry\n\n\n\n\nAnxiang\n24847.20\n24650.50\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n22724.80\n22434.17\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n24143.25\n26233.00\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n27737.50\n27084.60\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n27270.25\n26927.00\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n21248.80\n22230.17\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n43747.00\n47621.20\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n33582.71\n37160.12\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n45651.17\n49224.71\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n32027.62\n29886.89\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n32671.00\n26627.50\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n20810.00\n22690.17\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n25711.50\n25366.40\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n30672.33\n25825.75\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n33457.75\n30329.00\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n31689.20\n32682.83\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n20269.00\n25948.62\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n23901.60\n23987.67\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n25126.17\n25463.14\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n21903.43\n21904.38\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n22718.60\n23127.50\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n25918.80\n25949.83\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n20307.00\n20018.75\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n20023.80\n19524.17\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n16576.80\n18955.00\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n18667.00\n17800.40\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n14394.67\n15883.00\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n19848.80\n18831.33\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n15516.33\n14832.50\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518.00\n17965.00\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n17572.00\n17159.89\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n15200.12\n16199.44\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n18413.80\n18764.50\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n14419.33\n26878.75\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n24094.50\n23188.86\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n22019.83\n20788.14\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n12923.50\n12365.20\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n14756.00\n15985.00\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n13869.80\n13764.83\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n12296.67\n11907.43\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n15775.17\n17128.14\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n14382.86\n14593.62\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n11566.33\n11644.29\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n13199.50\n12706.00\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n23412.00\n21712.29\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n39541.00\n43548.25\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n36186.60\n35049.00\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n16559.60\n16226.83\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n20772.50\n19294.40\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n19471.20\n18156.00\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n19827.33\n19954.75\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n15466.80\n18145.17\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n12925.67\n12132.75\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n18577.17\n18419.29\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n14943.00\n14050.83\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n24913.00\n23619.75\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n25093.00\n24552.71\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n24428.80\n24733.67\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n17003.00\n16762.60\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n21143.75\n20932.60\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n20435.00\n19467.75\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n17131.33\n18334.00\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n24569.75\n22541.00\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n23835.50\n26028.00\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360.00\n29128.50\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n47383.40\n46569.00\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n55157.75\n47576.60\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n37058.00\n36545.50\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n21546.67\n20838.50\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n23348.67\n22531.00\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n42323.67\n42115.50\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n28938.60\n27619.00\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n25880.80\n27611.33\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n47345.67\n44523.29\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n18711.33\n18127.43\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n29087.29\n28746.38\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n20748.29\n20734.50\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n35933.71\n33880.62\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n15439.71\n14716.38\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n29787.50\n28516.22\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n18145.00\n18086.14\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n21617.00\n21244.50\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n29203.89\n29568.80\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n41363.67\n48119.71\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n22259.09\n22310.75\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n44939.56\n43151.60\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n16902.00\n17133.40\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n16930.00\n17009.33\nPOLYGON ((111.3659 25.39472…\n\n\n\n\n\nLastly, qtm() of tmap package is used to plot the lag_gdppc and w_ave_gdppc maps next to each other for quick comparison.\n\nw_avg_gdppc &lt;- qtm(hunan, \"lag_window_avg GDPPC\")\ntmap_arrange(lag_gdppc, w_avg_gdppc, asp=1, ncol=2)\n\n\n\n\n\n\nSpatial window sum\nThe spatial window sum is the counter part of the window average, but without using row-standardized weights.\nTo add the diagonal element to the neighbour list, we just need to use include.self() from spdep.\n\nwm_qs &lt;- include.self(wm_q)\nwm_qs\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\n\nNext, we will assign binary weights to the neighbour structure that includes the diagonal element.\n\nb_weights &lt;- lapply(wm_qs, function(x) 0*x + 1)\nb_weights[1]\n\n[[1]]\n[1] 1 1 1 1 1 1\n\n\nNotice that now [1] has six neighbours instead of five.\nAgain, we use nb2listw() and glist() to explicitly assign weight values.\n\nb_weights2 &lt;- nb2listw(wm_qs, \n                       glist = b_weights, \n                       style = \"B\")\nb_weights2\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 536 \nPercentage nonzero weights: 6.921488 \nAverage number of links: 6.090909 \n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 536 1072 14160\n\n\nWith our new weight structure, we can compute the lag variable with lag.listw().\n\nw_sum_gdppc &lt;- list(hunan$NAME_3, lag.listw(b_weights2, hunan$GDPPC))\nw_sum_gdppc\n\n[[1]]\n [1] \"Anxiang\"       \"Hanshou\"       \"Jinshi\"        \"Li\"           \n [5] \"Linli\"         \"Shimen\"        \"Liuyang\"       \"Ningxiang\"    \n [9] \"Wangcheng\"     \"Anren\"         \"Guidong\"       \"Jiahe\"        \n[13] \"Linwu\"         \"Rucheng\"       \"Yizhang\"       \"Yongxing\"     \n[17] \"Zixing\"        \"Changning\"     \"Hengdong\"      \"Hengnan\"      \n[21] \"Hengshan\"      \"Leiyang\"       \"Qidong\"        \"Chenxi\"       \n[25] \"Zhongfang\"     \"Huitong\"       \"Jingzhou\"      \"Mayang\"       \n[29] \"Tongdao\"       \"Xinhuang\"      \"Xupu\"          \"Yuanling\"     \n[33] \"Zhijiang\"      \"Lengshuijiang\" \"Shuangfeng\"    \"Xinhua\"       \n[37] \"Chengbu\"       \"Dongan\"        \"Dongkou\"       \"Longhui\"      \n[41] \"Shaodong\"      \"Suining\"       \"Wugang\"        \"Xinning\"      \n[45] \"Xinshao\"       \"Shaoshan\"      \"Xiangxiang\"    \"Baojing\"      \n[49] \"Fenghuang\"     \"Guzhang\"       \"Huayuan\"       \"Jishou\"       \n[53] \"Longshan\"      \"Luxi\"          \"Yongshun\"      \"Anhua\"        \n[57] \"Nan\"           \"Yuanjiang\"     \"Jianghua\"      \"Lanshan\"      \n[61] \"Ningyuan\"      \"Shuangpai\"     \"Xintian\"       \"Huarong\"      \n[65] \"Linxiang\"      \"Miluo\"         \"Pingjiang\"     \"Xiangyin\"     \n[69] \"Cili\"          \"Chaling\"       \"Liling\"        \"Yanling\"      \n[73] \"You\"           \"Zhuzhou\"       \"Sangzhi\"       \"Yueyang\"      \n[77] \"Qiyang\"        \"Taojiang\"      \"Shaoyang\"      \"Lianyuan\"     \n[81] \"Hongjiang\"     \"Hengyang\"      \"Guiyang\"       \"Changsha\"     \n[85] \"Taoyuan\"       \"Xiangtan\"      \"Dao\"           \"Jiangyong\"    \n\n[[2]]\n [1] 147903 134605 131165 135423 134635 133381 238106 297281 344573 268982\n[11] 106510 136141 126832 103303 151645 196097 207589 143926 178242 175235\n[21] 138765 155699 160150 117145 113730  89002  63532 112988  59330  35930\n[31] 154439 145795 112587 107515 162322 145517  61826  79925  82589  83352\n[41] 119897 116749  81510  63530 151986 174193 210294  97361  96472 108936\n[51]  79819 108871  48531 128935  84305 188958 171869 148402  83813 104663\n[61] 155742  73336 112705  78084  58257 279414 237883 219273  83354  90124\n[71] 168462 165714 165668 311663 126892 229971 165876 271045 117731 256646\n[81] 126603 127467 295688 336838 267729 431516  85667  51028\n\n\n\nw_sum_gdppc.res &lt;- as.data.frame(w_sum_gdppc)\ncolnames(w_sum_gdppc.res) &lt;- c(\"NAME_3\", \"w_sum GDPPC\")\nhunan &lt;- left_join(hunan, w_sum_gdppc.res)\n\nJoining with `by = join_by(NAME_3)`\n\nhunan %&gt;%\n  dplyr::select(\"County\", \"lag_sum GDPPC\", \"w_sum GDPPC\") %&gt;%\n  kable()\n\n\n\n\n\n\n\n\n\n\nCounty\nlag_sum GDPPC\nw_sum GDPPC\ngeometry\n\n\n\n\nAnxiang\n124236\n147903\nPOLYGON ((112.0625 29.75523…\n\n\nHanshou\n113624\n134605\nPOLYGON ((112.2288 29.11684…\n\n\nJinshi\n96573\n131165\nPOLYGON ((111.8927 29.6013,…\n\n\nLi\n110950\n135423\nPOLYGON ((111.3731 29.94649…\n\n\nLinli\n109081\n134635\nPOLYGON ((111.6324 29.76288…\n\n\nShimen\n106244\n133381\nPOLYGON ((110.8825 30.11675…\n\n\nLiuyang\n174988\n238106\nPOLYGON ((113.9905 28.5682,…\n\n\nNingxiang\n235079\n297281\nPOLYGON ((112.7181 28.38299…\n\n\nWangcheng\n273907\n344573\nPOLYGON ((112.7914 28.52688…\n\n\nAnren\n256221\n268982\nPOLYGON ((113.1757 26.82734…\n\n\nGuidong\n98013\n106510\nPOLYGON ((114.1799 26.20117…\n\n\nJiahe\n104050\n136141\nPOLYGON ((112.4425 25.74358…\n\n\nLinwu\n102846\n126832\nPOLYGON ((112.5914 25.55143…\n\n\nRucheng\n92017\n103303\nPOLYGON ((113.6759 25.87578…\n\n\nYizhang\n133831\n151645\nPOLYGON ((113.2621 25.68394…\n\n\nYongxing\n158446\n196097\nPOLYGON ((113.3169 26.41843…\n\n\nZixing\n141883\n207589\nPOLYGON ((113.7311 26.16259…\n\n\nChangning\n119508\n143926\nPOLYGON ((112.6144 26.60198…\n\n\nHengdong\n150757\n178242\nPOLYGON ((113.1056 27.21007…\n\n\nHengnan\n153324\n175235\nPOLYGON ((112.7599 26.98149…\n\n\nHengshan\n113593\n138765\nPOLYGON ((112.607 27.4689, …\n\n\nLeiyang\n129594\n155699\nPOLYGON ((112.9996 26.69276…\n\n\nQidong\n142149\n160150\nPOLYGON ((111.7818 27.0383,…\n\n\nChenxi\n100119\n117145\nPOLYGON ((110.2624 28.21778…\n\n\nZhongfang\n82884\n113730\nPOLYGON ((109.9431 27.72858…\n\n\nHuitong\n74668\n89002\nPOLYGON ((109.9419 27.10512…\n\n\nJingzhou\n43184\n63532\nPOLYGON ((109.8186 26.75842…\n\n\nMayang\n99244\n112988\nPOLYGON ((109.795 27.98008,…\n\n\nTongdao\n46549\n59330\nPOLYGON ((109.9294 26.46561…\n\n\nXinhuang\n20518\n35930\nPOLYGON ((109.227 27.43733,…\n\n\nXupu\n140576\n154439\nPOLYGON ((110.7189 28.30485…\n\n\nYuanling\n121601\n145795\nPOLYGON ((110.9652 28.99895…\n\n\nZhijiang\n92069\n112587\nPOLYGON ((109.8818 27.60661…\n\n\nLengshuijiang\n43258\n107515\nPOLYGON ((111.5307 27.81472…\n\n\nShuangfeng\n144567\n162322\nPOLYGON ((112.263 27.70421,…\n\n\nXinhua\n132119\n145517\nPOLYGON ((111.3345 28.19642…\n\n\nChengbu\n51694\n61826\nPOLYGON ((110.4455 26.69317…\n\n\nDongan\n59024\n79925\nPOLYGON ((111.4531 26.86812…\n\n\nDongkou\n69349\n82589\nPOLYGON ((110.6622 27.37305…\n\n\nLonghui\n73780\n83352\nPOLYGON ((110.985 27.65983,…\n\n\nShaodong\n94651\n119897\nPOLYGON ((111.9054 27.40254…\n\n\nSuining\n100680\n116749\nPOLYGON ((110.389 27.10006,…\n\n\nWugang\n69398\n81510\nPOLYGON ((110.9878 27.03345…\n\n\nXinning\n52798\n63530\nPOLYGON ((111.0736 26.84627…\n\n\nXinshao\n140472\n151986\nPOLYGON ((111.6013 27.58275…\n\n\nShaoshan\n118623\n174193\nPOLYGON ((112.5391 27.97742…\n\n\nXiangxiang\n180933\n210294\nPOLYGON ((112.4549 28.05783…\n\n\nBaojing\n82798\n97361\nPOLYGON ((109.7015 28.82844…\n\n\nFenghuang\n83090\n96472\nPOLYGON ((109.5239 28.19206…\n\n\nGuzhang\n97356\n108936\nPOLYGON ((109.8968 28.74034…\n\n\nHuayuan\n59482\n79819\nPOLYGON ((109.5647 28.61712…\n\n\nJishou\n77334\n108871\nPOLYGON ((109.8375 28.4696,…\n\n\nLongshan\n38777\n48531\nPOLYGON ((109.6337 29.62521…\n\n\nLuxi\n111463\n128935\nPOLYGON ((110.1067 28.41835…\n\n\nYongshun\n74715\n84305\nPOLYGON ((110.0003 29.29499…\n\n\nAnhua\n174391\n188958\nPOLYGON ((111.6034 28.63716…\n\n\nNan\n150558\n171869\nPOLYGON ((112.3232 29.46074…\n\n\nYuanjiang\n122144\n148402\nPOLYGON ((112.4391 29.1791,…\n\n\nJianghua\n68012\n83813\nPOLYGON ((111.6461 25.29661…\n\n\nLanshan\n84575\n104663\nPOLYGON ((112.2286 25.61123…\n\n\nNingyuan\n143045\n155742\nPOLYGON ((112.0715 26.09892…\n\n\nShuangpai\n51394\n73336\nPOLYGON ((111.8864 26.11957…\n\n\nXintian\n98279\n112705\nPOLYGON ((112.2578 26.0796,…\n\n\nHuarong\n47671\n78084\nPOLYGON ((112.9242 29.69134…\n\n\nLinxiang\n26360\n58257\nPOLYGON ((113.5502 29.67418…\n\n\nMiluo\n236917\n279414\nPOLYGON ((112.9902 29.02139…\n\n\nPingjiang\n220631\n237883\nPOLYGON ((113.8436 29.06152…\n\n\nXiangyin\n185290\n219273\nPOLYGON ((112.9173 28.98264…\n\n\nCili\n64640\n83354\nPOLYGON ((110.8822 29.69017…\n\n\nChaling\n70046\n90124\nPOLYGON ((113.7666 27.10573…\n\n\nLiling\n126971\n168462\nPOLYGON ((113.5673 27.94346…\n\n\nYanling\n144693\n165714\nPOLYGON ((113.9292 26.6154,…\n\n\nYou\n129404\n165668\nPOLYGON ((113.5879 27.41324…\n\n\nZhuzhou\n284074\n311663\nPOLYGON ((113.2493 28.02411…\n\n\nSangzhi\n112268\n126892\nPOLYGON ((110.556 29.40543,…\n\n\nYueyang\n203611\n229971\nPOLYGON ((113.343 29.61064,…\n\n\nQiyang\n145238\n165876\nPOLYGON ((111.5563 26.81318…\n\n\nTaojiang\n251536\n271045\nPOLYGON ((112.0508 28.67265…\n\n\nShaoyang\n108078\n117731\nPOLYGON ((111.5013 27.30207…\n\n\nLianyuan\n238300\n256646\nPOLYGON ((111.6789 28.02946…\n\n\nHongjiang\n108870\n126603\nPOLYGON ((110.1441 27.47513…\n\n\nHengyang\n108085\n127467\nPOLYGON ((112.7144 26.98613…\n\n\nGuiyang\n262835\n295688\nPOLYGON ((113.0811 26.04963…\n\n\nChangsha\n248182\n336838\nPOLYGON ((112.9421 28.03722…\n\n\nTaoyuan\n244850\n267729\nPOLYGON ((112.0612 29.32855…\n\n\nXiangtan\n404456\n431516\nPOLYGON ((113.0426 27.8942,…\n\n\nDao\n67608\n85667\nPOLYGON ((111.498 25.81679,…\n\n\nJiangyong\n33860\n51028\nPOLYGON ((111.3659 25.39472…\n\n\n\n\nw_sum_gdppc &lt;- qtm(hunan, \"w_sum GDPPC\")\ntmap_arrange(lag_sum_gdppc, w_sum_gdppc, asp=1, ncol=2)\n\n\n\n\nEnd."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot)\n\n\ntidyverse: A collection of R packages for data manipulation, visualization, and analysis.\nsf: Provides support for simple features, a standardized way to encode spatial vector data.\ntmap: Creates thematic maps, offering a flexible, layer-based approach to map design.\nggstatsplot: Extends ggplot2 for creating graphics with statistical details included in the plots.\n\n\n\n\n\nmpsz14_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n#mpsz14_kml &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Dat\n#There's error! Must be data source error.\n\nLet’s fix this error. We shall convert the shp sf data.frame into kml.\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\nGreat! Now that that’s fixed, let’s move on to preschool data. I downloaded the kml and geojson files.\n\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\") \n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNow, let’s import the Master Plan 2019.\n\nmpsz19_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz19_kml &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWGS 84 is popular because it captures location and is used by cell phones, in decimel degree. In geospatial analysis, we need to know distance difference. If we use WGS 84, 1 degree is different when you are at north pole or equator. So when we do geospatial analysis, we always use projected coordinate systems (PCS). For Singapore, we are using metre SVY 21. Now, let’s convert it.\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\npreschool &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nLet’s count the number of preschools.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )\n\nEDA and CDA\n\nmpsz19_shp$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\nmpsz19_shp$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \nmpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n\nggscatterstats(data = mpsz19_shp,\n               x = `PreSch Density`,\n               y = `PreSch Count`,\n               type = \"parametric\")\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nRead population data from Singstat.\n\npopdata &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)\n\nJoin popdata2023 and mpsz19_shp\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmpsz_pop2023 &lt;- st_as_sf(mpsz_pop2023)\nclass(mpsz_pop2023)\n\n[1] \"sf\"         \"data.frame\"\n\nqtm(mpsz_pop2023, \n    fill = \"DEPENDENCY\")\n\n\n\ntm_shape(mpsz_pop2023)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\npercentmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\nggplot(data = mpsz_pop2023,\n       aes(x = \"\",\n           y = DEPENDENCY)) +\n  geom_boxplot()\n\n\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThat ends in-class ex01."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#load-the-packages",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#load-the-packages",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot)\n\n\ntidyverse: A collection of R packages for data manipulation, visualization, and analysis.\nsf: Provides support for simple features, a standardized way to encode spatial vector data.\ntmap: Creates thematic maps, offering a flexible, layer-based approach to map design.\nggstatsplot: Extends ggplot2 for creating graphics with statistical details included in the plots."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#read-the-files",
    "href": "In-class_Ex/In-class_Ex01/In-class_Ex01.html#read-the-files",
    "title": "In-Class Exercise 1",
    "section": "",
    "text": "mpsz14_shp &lt;- st_read(dsn = \"data/\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n#mpsz14_kml &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Dat\n#There's error! Must be data source error.\n\nLet’s fix this error. We shall convert the shp sf data.frame into kml.\n\nst_write(mpsz14_shp, \n         \"data/MP14_SUBZONE_WEB_PL.kml\",\n         delete_dsn = TRUE)\n\nDeleting source `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting layer `MP14_SUBZONE_WEB_PL' to data source \n  `data/MP14_SUBZONE_WEB_PL.kml' using driver `KML'\nWriting 323 features with 15 fields and geometry type Multi Polygon.\n\n\nGreat! Now that that’s fixed, let’s move on to preschool data. I downloaded the kml and geojson files.\n\npreschool_kml &lt;- st_read(\"data/PreSchoolsLocation.kml\")\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\npreschool_geojson &lt;- st_read(\"data/PreSchoolsLocation.geojson\") \n\nReading layer `PreSchoolsLocation' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nNow, let’s import the Master Plan 2019.\n\nmpsz19_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/\", \n                  layer = \"MPSZ-2019\")\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\nmpsz19_kml &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/MasterPlan2019SubzoneBoundaryNoSeaKML.kml\")\n\nReading layer `URA_MP19_SUBZONE_NO_SEA_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\MasterPlan2019SubzoneBoundaryNoSeaKML.kml' \n  using driver `KML'\nSimple feature collection with 332 features and 2 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY, XYZ\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nWGS 84 is popular because it captures location and is used by cell phones, in decimel degree. In geospatial analysis, we need to know distance difference. If we use WGS 84, 1 degree is different when you are at north pole or equator. So when we do geospatial analysis, we always use projected coordinate systems (PCS). For Singapore, we are using metre SVY 21. Now, let’s convert it.\n\nst_crs(mpsz19_shp)\n\nCoordinate Reference System:\n  User input: WGS 84 \n  wkt:\nGEOGCRS[\"WGS 84\",\n    DATUM[\"World Geodetic System 1984\",\n        ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n            LENGTHUNIT[\"metre\",1]]],\n    PRIMEM[\"Greenwich\",0,\n        ANGLEUNIT[\"degree\",0.0174532925199433]],\n    CS[ellipsoidal,2],\n        AXIS[\"latitude\",north,\n            ORDER[1],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        AXIS[\"longitude\",east,\n            ORDER[2],\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n    ID[\"EPSG\",4326]]\n\n\n\nmpsz19_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/\",\n                layer = \"MPSZ-2019\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `MPSZ-2019' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 332 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 103.6057 ymin: 1.158699 xmax: 104.0885 ymax: 1.470775\nGeodetic CRS:  WGS 84\n\npreschool &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/PreSchoolsLocation.kml\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `PRESCHOOLS_LOCATION' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data\\PreSchoolsLocation.kml' \n  using driver `KML'\nSimple feature collection with 2290 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6878 ymin: 1.247759 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\n\nLet’s count the number of preschools.\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(`PreSch Count` = lengths(\n    st_intersects(mpsz19_shp, preschool)))\n\n\nmpsz19_shp &lt;- mpsz19_shp %&gt;%\n  mutate(Area = units::drop_units(\n    st_area(.)),\n    `PreSch Density` = `PreSch Count` / Area * 1000000\n  )\n\nEDA and CDA\n\nmpsz19_shp$`PreSch Density` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Density`))\nmpsz19_shp$`PreSch Count` &lt;- as.numeric(as.character(mpsz19_shp$`PreSch Count`)) \nmpsz19_shp &lt;- as.data.frame(mpsz19_shp)\n\nggscatterstats(data = mpsz19_shp,\n               x = `PreSch Density`,\n               y = `PreSch Count`,\n               type = \"parametric\")\n\nRegistered S3 method overwritten by 'ggside':\n  method from   \n  +.gg   ggplot2\n\n\n`stat_xsidebin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_ysidebin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nRead population data from Singstat.\n\npopdata &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data/respopagesextod2023.csv\")\n\nRows: 100928 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): PA, SZ, AG, Sex, TOD\ndbl (2): Pop, Time\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npopdata2023 &lt;- popdata %&gt;% \n  group_by(PA, SZ, AG) %&gt;% \n  summarise(`POP`=sum(`Pop`)) %&gt;%  \n  ungroup() %&gt;% \n  pivot_wider(names_from=AG,\n              values_from = POP)\n\n`summarise()` has grouped output by 'PA', 'SZ'. You can override using the\n`.groups` argument.\n\ncolnames(popdata2023)\n\n [1] \"PA\"          \"SZ\"          \"0_to_4\"      \"10_to_14\"    \"15_to_19\"   \n [6] \"20_to_24\"    \"25_to_29\"    \"30_to_34\"    \"35_to_39\"    \"40_to_44\"   \n[11] \"45_to_49\"    \"50_to_54\"    \"55_to_59\"    \"5_to_9\"      \"60_to_64\"   \n[16] \"65_to_69\"    \"70_to_74\"    \"75_to_79\"    \"80_to_84\"    \"85_to_89\"   \n[21] \"90_and_Over\"\n\n\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate(YOUNG=rowSums(.[3:6]) # Aged 0 - 24, 10 - 24\n         +rowSums(.[14])) %&gt;% # Aged 5 - 9\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:13])+ # Aged 25 - 59\n  rowSums(.[15])) %&gt;%  # Aged 60 -64\n  mutate(`AGED`=rowSums(.[16:21])) %&gt;%\n  mutate(`TOTAL`=rowSums(.[3:21])) %&gt;%\n  mutate(`DEPENDENCY`=(`YOUNG` + `AGED`)\n  / `ECONOMY ACTIVE`) %&gt;% \n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`,\n         `TOTAL`, `DEPENDENCY`)\n\nJoin popdata2023 and mpsz19_shp\n\npopdata2023 &lt;- popdata2023 %&gt;%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = list(toupper)) \nmpsz_pop2023 &lt;- left_join(mpsz19_shp, popdata2023,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\npop2023_mpsz &lt;- left_join(popdata2023, mpsz19_shp, \n                          by = c(\"SZ\" = \"SUBZONE_N\"))\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nmpsz_pop2023 &lt;- st_as_sf(mpsz_pop2023)\nclass(mpsz_pop2023)\n\n[1] \"sf\"         \"data.frame\"\n\nqtm(mpsz_pop2023, \n    fill = \"DEPENDENCY\")\n\n\n\ntm_shape(mpsz_pop2023)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nmpsz_pop2023 &lt;- mpsz_pop2023 %&gt;%\n  drop_na()\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% \n    st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\npercentmap &lt;- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent &lt;- c(0,.01,.1,.5,.9,.99,1)\n  var &lt;- get.var(vnam, df)\n  bperc &lt;- quantile(var, percent)\n  tm_shape(mpsz_pop2023) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"&lt; 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"&gt; 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\npercentmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\nggplot(data = mpsz_pop2023,\n       aes(x = \"\",\n           y = DEPENDENCY)) +\n  geom_boxplot()\n\n\n\n\n\nboxbreaks &lt;- function(v,mult=1.5) {\n  qv &lt;- unname(quantile(v))\n  iqr &lt;- qv[4] - qv[2]\n  upfence &lt;- qv[4] + mult * iqr\n  lofence &lt;- qv[2] - mult * iqr\n  # initialize break points vector\n  bb &lt;- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence &lt; qv[1]) {  # no lower outliers\n    bb[1] &lt;- lofence\n    bb[2] &lt;- floor(qv[1])\n  } else {\n    bb[2] &lt;- lofence\n    bb[1] &lt;- qv[1]\n  }\n  if (upfence &gt; qv[5]) { # no upper outliers\n    bb[7] &lt;- upfence\n    bb[6] &lt;- ceiling(qv[5])\n  } else {\n    bb[6] &lt;- upfence\n    bb[7] &lt;- qv[5]\n  }\n  bb[3:5] &lt;- qv[2:4]\n  return(bb)\n}\nget.var &lt;- function(vname,df) {\n  v &lt;- df[vname] %&gt;% st_set_geometry(NULL)\n  v &lt;- unname(v[,1])\n  return(v)\n}\nboxmap &lt;- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var &lt;- get.var(vnam,df)\n  bb &lt;- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"&lt; 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"&gt; 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\n\n\n\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"view\")\n\ntmap mode set to interactive viewing\n\nboxmap(\"DEPENDENCY\", mpsz_pop2023)\n\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\nWarning: The shape df is invalid (after reprojection). See sf::st_is_valid\n\n\n\n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThat ends in-class ex01."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Maptools have been retired. So we installed it from the CRAN repository.\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")\n\n\n\n\n\npacman::p_load(tidyverse, sf, tmap, ggstatsplot, spatstat)\nset.seed(1234)\n\n\n\n\n\nmpsz14_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#finding-maptools",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#finding-maptools",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "Maptools have been retired. So we installed it from the CRAN repository.\n\ninstall.packages(\"maptools\", repos = \"https://packagemanager.posit.co/cran/2023-10-13\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#load-packages",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#load-packages",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "pacman::p_load(tidyverse, sf, tmap, ggstatsplot, spatstat)\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#read-the-map-data",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#read-the-map-data",
    "title": "In-class Exercise 2",
    "section": "",
    "text": "mpsz14_shp &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/In-class_Ex/In-class_Ex01/Data\",\n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex01\\data' using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#union-for-the-outline",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#union-for-the-outline",
    "title": "In-class Exercise 2",
    "section": "Union for the outline",
    "text": "Union for the outline\n\nsg_sf &lt;- mpsz14_shp %&gt;%\n  st_union()\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\nqtm(sg_sf)\n\n\n\n\nLet’s try the spatstet.geom method.\n\nchildcare_sf &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex02/data/child-care-services-geojson.geojson\") %&gt;%\n  st_transform(crs = 3414)\n\nReading layer `child-care-services-geojson' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex02\\data\\child-care-services-geojson.geojson' \n  using driver `GeoJSON'\nSimple feature collection with 1545 features and 2 fields\nGeometry type: POINT\nDimension:     XYZ\nBounding box:  xmin: 103.6824 ymin: 1.248403 xmax: 103.9897 ymax: 1.462134\nz_range:       zmin: 0 zmax: 0\nGeodetic CRS:  WGS 84\n\nchildcare &lt;- as_Spatial(childcare_sf)\nchildcareSG_ppp &lt;- as.ppp(childcare_sf)\n\nWarning in as.ppp.sf(childcare_sf): only first attribute column is used for\nmarks\n\nsg_owin &lt;- as.owin(sg_sf)\nplot(sg_owin)\n\n\n\nchildcareSG_ppp &lt;- childcareSG_ppp[sg_owin]\n\nchildcareSG_ppp.km &lt;- rescale.ppp(childcareSG_ppp, 1000, \"km\")\nkde_childcareSG.bw &lt;- density(childcareSG_ppp.km, sigma=bw.diggle, edge=TRUE, kernel=\"gaussian\")\n\nkde_childcareSG_adaptive &lt;- adaptive.density(childcareSG_ppp.km, method=\"kernel\")\nplot(kde_childcareSG_adaptive)\n\n\n\ngridded_kde_childcareSG_ad &lt;- as(\n  kde_childcareSG_adaptive,\n  \"SpatialGridDataFrame\")\npacman::p_load(sp)\nspplot(gridded_kde_childcareSG_ad)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#dive-into-punggol",
    "href": "In-class_Ex/In-class_Ex02/In-class_Ex02.html#dive-into-punggol",
    "title": "In-class Exercise 2",
    "section": "Dive into Punggol",
    "text": "Dive into Punggol\n\npg_owin &lt;- mpsz14_shp %&gt;%\n  filter(PLN_AREA_N == \"PUNGGOL\") %&gt;%\n  as.owin()\n\nchildcare_pg = childcare_ppp[pg_owin]\n\nplot(childcare_pg)  \n\nWarning in default.charmap(ntypes, chars): Too many types to display every type\nas a different character\n\n\nWarning: Only 10 out of 61 symbols are shown in the symbol map\n\n\n\n\n\n\nset.seed(1234)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "Hands-on Exercise 03",
    "section": "",
    "text": "pacman::p_load(sf, spNetwork, tmap, tidyverse)\n\nReiterate - sf we used in hands-on exercise 1. This is R’s way to handle and import data. It also allows us to write into RDS (R Datafile) format. One good way to use this function is to filter and write out a subset of a large data file, then it will shorten processing time.\nTidyverse is mainly for different data fields. Includes lubridate for date fields.\nspNetwork is for kernel densities. Different from spatstat. It is also based on sp. But sp was retired. spNetwork is no longer ocnforming to sp, and now to sf, “moving to sf”. So actually what we are using is all sf already! No need for owin etc as it is taken care in this package."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#examine-plot",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#examine-plot",
    "title": "Hands-on Exercise 03",
    "section": "Examine plot",
    "text": "Examine plot\n\nplot(st_geometry(network)) \nplot(childcare,add=T,col='red',pch = 19)\n\n\n\n\nCool! st_read is used because the .shp file is in ESRI shapefile format. Because of this, I have to use dsn Destination folder. Note: No need for extension, because it can automatically pick out the shape file for conversion.\nChildcare is in data.gov file. It was converted into kml first, then into a shp file. KML likes to have x, y, z. z is the height. Hence we remove z in the data cleaning process. Check out the line “Dimension: xyz”. spNetwork only can take xy. Need to get rid of point z.\nplot is a basic function based on base R. basic, but useful. Sequence is important. Road network first, then whatever is on top, which is the childcare centres. “Add=T” means we add on to whatever is plotting already.\nst_geometry is used so it only pulls the geometry, without the value assigned to it. Without using st_geometry will result in multiple same plots, each using one of the value fields in the dataset, which is not what we want. Then what about childcare? It’s also geometric. But we already coloured it into one colour, so there is no multiple colour. Note the multiple ways to do things.\nLet’s look at it in leaflet form.\n\ntmap_mode('view') \n\ntmap mode set to interactive viewing\n\ntm_shape(childcare) +   tm_dots() +   tm_shape(network) +   tm_lines()  \n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nThis is using tmap library, logic is around the same. We have to specify the layers we use. We don’t use it but using tmap shape, we are using the extend of the map area, then we can shade it into different formats. Dots is used instead of bubble to keep the size same when we zoom in and out, useing leaflet as a backdrop.\nWhy use plot over tmap? Simple and little lines of code. Why use tmap over plot? More flexibility and functions (via leaflet, zooming and hovering, a lite-weight, javascript-based mapping). This is especially useful after the kernel density estimation analysis."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#lixelization",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#lixelization",
    "title": "Hands-on Exercise 03",
    "section": "Lixelization",
    "text": "Lixelization\nBefore computing NKDE, the SpatialLines object need to be cut into lixels with a specified minimal distance. This task can be performed by using with lixelize_lines() of spNetwork as shown in the code chunk below.\nLixel lines are a concept used in spatial analysis, particularly in network-based analysis.\n\nLixels: This term is a combination of “line” and “pixel”. Just as a pixel is the smallest unit of a raster image, a lixel is the smallest unit of a line in a network.\nPurpose: Lixels are used to discretise continuous linear features (like roads or rivers) into smaller, equal-length segments. This discretization is often necessary for certain types of spatial analysis, especially when working with network data.\nNKDE (Network Kernel Density Estimation): This is a method used to estimate the density of events or phenomena along a network. Before applying NKDE, it’s often necessary to break down the network into these smaller units (lixels) for more accurate analysis.\nMinimal distance: When creating lixels, you specify a minimal distance. This is the length of each lixel segment. The lines in your network will be cut into segments of this length.\nspNetwork package: This is the library that provides functions for spatial network analysis. The lixelize_lines() function is used to perform this lixelization process.\nSpatialLines object: This is a data structure used to represent linear features in a spatial context. The lixelization process is applied to this object.\n\nThe process of creating lixels allows for more precise analysis along a network, as it creates a consistent unit of measurement and analysis along potentially irregular network structures. This can be particularly useful in applications like traffic analysis, crime mapping along street networks, or analyzing the spread of phenomena along river systems. In this case, I will be looking at childcare centres.\n\nlixels &lt;- lixelize_lines(network,\n                         700,\n                         mindist = 50)\n\nWhy these values? 700 and 375 was experimented on. this is a road network, we’re looking at childcare. Usually, in typical neighbourhoods, we will get other caregivers to bring kids to and fro childcare centres. So, let’s take reasonable walking distance. NTU researchers said in general, walking distance - based on weather and perceived hindrance - is roughly about 700m. That’s why it’s 700m here.\nThen mindist, (minimium distance), this is by instinct. Using search radius of 700m, this we set as half of 700. But we can change it. Let’s test and try. Original network had 2642 obs. of 3 variables (i.e. segments). They are not continuous. The line network is made of 2642 segments. We ask the machine to split them into line segments, of each 700m, with centrepoints minimum 350m. But after running, we have 2645 segments now! We have 3 more. Now if we increased mindist to 50, we will have more segments 2648.\nNow, determination of this distance is by calculating nearest neighbour. Plot it out to see which one will catch reasonable insights. We should be able to pick up reasonable interest points. I can look at distribution first, take the lower 25. That might catch at least at any one time, the lowest 25 in any line segment. So use the distance to help to determine."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#line-centre-points",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#line-centre-points",
    "title": "Hands-on Exercise 03",
    "section": "Line centre points",
    "text": "Line centre points\n\nsamples &lt;- lines_center(lixels)  \n\nThis code calculates centre points. The idea is at each road segment, we have 2645, we will have 2645 centrepoints; same. Let’s plot it out and look at it.\n\ntmap_mode('view') \n\ntmap mode set to interactive viewing\n\ntm_shape(samples) +   tm_dots() +   tm_shape(network) +   tm_lines()  \n\n\n\n\n\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\n\nSamples is also in sf format. You can review it. They are points, based on lixel samples."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#actual-nkde",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html#actual-nkde",
    "title": "Hands-on Exercise 03",
    "section": "Actual NKDE",
    "text": "Actual NKDE\n\ndensities &lt;- nkde(network,\n                  events = childcare,\n                  w = rep(1, nrow(childcare)),\n                  samples = samples,\n                  kernel_name = \"quartic\", #Different kernel type, slight changes to smoothing.\n                  bw = 300,                    \n                  div= \"bw\",\n                  method = \"simple\", #Simple, Discontinuous, and Continuous\n                  digits = 1,\n                  tol = 1,\n                  grid_shape = c(1,1),\n                  max_depth = 8,\n                  agg = 5,\n                  sparse = TRUE,\n                  verbose = FALSE)\n\nFor kernel type, try not to use Gaussian as it may give negative towards the end points. The rest, can test it out :) Output is actually one line of numbers; a list contained in one R object. It gives intensity. After this, we need to append the intensity values into the simple tibble dataframe, or the lixelised dataframe.\nLet’s examine and visualise the NKDE\nSample originally has 4 columns. If we add in density, there will be 5 columns. DO NOT SORT IN BETWEEN THESE STEPS. Then it will not mapped correctly. Please be careful! Like a left join but without unique identifier.\n\nsamples$density &lt;- densities\nlixels$density &lt;- densities \nsummary(samples$density) \n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.000e+00 0.000e+00 1.422e-06 3.783e-06 7.422e-06 2.405e-05 \n\nsummary(lixels$density)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n0.000e+00 0.000e+00 1.422e-06 3.783e-06 7.422e-06 2.405e-05 \n\n\nThat looks really small. SVY21 projection system is in meter. The densities become small. Let’s change it to events per KM.\n\n# rescaling to help the mapping \nsamples$density &lt;- samples$density*1000  # Consider writing somewhere that events is unit per KM\nlixels$density &lt;- lixels$density*1000 \nsummary(samples$density) \n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.001422 0.003783 0.007422 0.024046 \n\nsummary(lixels$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.001422 0.003783 0.007422 0.024046 \n\n\nOk. Looks better. Let’s visualise it.\n\ntmap_mode('view') \n\ntmap mode set to interactive viewing\n\ntm_shape(lixels)+\n  tm_lines(col=\"density\")+\n  tm_shape(childcare)+\n  tm_dots() \n\n\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "Geographically weighted summary statistics, gwModel methods\nbw.gwr is the method to recommend the bandwidth to cut off, or if using adaptive distance, the optimal number of neighbours to get statistifically signifant insights as much as possible.\n\npacman::p_load(sf, spdep, tmap, tidyverse, knitr, GWmodel, ggstatsplot, viridis)\n\n\nhunan_sf &lt;- st_read(dsn = \"data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\In-class_Ex\\In-class_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"data/aspatial/Hunan_2012.csv\") #read_csv is better\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhunan_sf &lt;- left_join(hunan_sf, hunan2012) %&gt;%\n  dplyr::select(1:3, 7, 15, 16, 17, 31, 32)\n\nJoining with `by = join_by(County)`\n\n\nIn order to use GWModel, we need to convert from sf to sp. Use the following chunk.\n\nhunan_sp &lt;- hunan_sf %&gt;%\n  as_Spatial()\n\n\nbw_CV &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = TRUE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth: 62 CV score: 15515442343 \nAdaptive bandwidth: 46 CV score: 14937956887 \nAdaptive bandwidth: 36 CV score: 14408561608 \nAdaptive bandwidth: 29 CV score: 14198527496 \nAdaptive bandwidth: 26 CV score: 13898800611 \nAdaptive bandwidth: 22 CV score: 13662299974 \nAdaptive bandwidth: 22 CV score: 13662299974 \n\n\n\nbw_AIC &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = TRUE, #if this is false, then it's fixed bandwidth\n                kernel = \"bisquare\",\n                longlat = T) #longlat indicates that it is in decimel degree. documentation says if it's set to TRUE, it applies \"great circle distance calculation\" Only thing to take note here, is because it is global, it is in kilometres (converted to kilometres). Later when we see the results of a fixed kernel, they are in km.\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1923.156 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1920.469 \nAdaptive bandwidth (number of nearest neighbours): 36 AICc value: 1917.324 \nAdaptive bandwidth (number of nearest neighbours): 29 AICc value: 1916.661 \nAdaptive bandwidth (number of nearest neighbours): 26 AICc value: 1914.897 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \nAdaptive bandwidth (number of nearest neighbours): 22 AICc value: 1914.045 \n\n\nStarts with all (88), after that, it chips away the neighbours, to 22. And that’s the optimal number of neighbours. Based on GDP per capita, the optimal neighbour is 22.\nIf we use fix?\n\nbw_CV_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"CV\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 CV score: 16265191728 \nFixed bandwidth: 220.985 CV score: 14954930931 \nFixed bandwidth: 136.6204 CV score: 14134185837 \nFixed bandwidth: 84.48025 CV score: 13693362460 \nFixed bandwidth: 52.25585 CV score: Inf \nFixed bandwidth: 104.396 CV score: 13891052305 \nFixed bandwidth: 72.17162 CV score: 13577893677 \nFixed bandwidth: 64.56447 CV score: 14681160609 \nFixed bandwidth: 76.8731 CV score: 13444716890 \nFixed bandwidth: 79.77877 CV score: 13503296834 \nFixed bandwidth: 75.07729 CV score: 13452450771 \nFixed bandwidth: 77.98296 CV score: 13457916138 \nFixed bandwidth: 76.18716 CV score: 13442911302 \nFixed bandwidth: 75.76323 CV score: 13444600639 \nFixed bandwidth: 76.44916 CV score: 13442994078 \nFixed bandwidth: 76.02523 CV score: 13443285248 \nFixed bandwidth: 76.28724 CV score: 13442844774 \nFixed bandwidth: 76.34909 CV score: 13442864995 \nFixed bandwidth: 76.24901 CV score: 13442855596 \nFixed bandwidth: 76.31086 CV score: 13442847019 \nFixed bandwidth: 76.27264 CV score: 13442846793 \nFixed bandwidth: 76.29626 CV score: 13442844829 \nFixed bandwidth: 76.28166 CV score: 13442845238 \nFixed bandwidth: 76.29068 CV score: 13442844678 \nFixed bandwidth: 76.29281 CV score: 13442844691 \nFixed bandwidth: 76.28937 CV score: 13442844698 \nFixed bandwidth: 76.2915 CV score: 13442844676 \nFixed bandwidth: 76.292 CV score: 13442844679 \nFixed bandwidth: 76.29119 CV score: 13442844676 \nFixed bandwidth: 76.29099 CV score: 13442844676 \nFixed bandwidth: 76.29131 CV score: 13442844676 \nFixed bandwidth: 76.29138 CV score: 13442844676 \nFixed bandwidth: 76.29126 CV score: 13442844676 \nFixed bandwidth: 76.29123 CV score: 13442844676 \n\n\nThis determines fixed distance, and shows which one is best for the search. This is in KM.\nLet’s take a look at AIC.\n\nbw_AIC_fixed &lt;- bw.gwr(GDPPC ~ 1,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = FALSE,\n                kernel = \"bisquare\",\n                longlat = T)\n\nFixed bandwidth: 357.4897 AICc value: 1927.631 \nFixed bandwidth: 220.985 AICc value: 1921.547 \nFixed bandwidth: 136.6204 AICc value: 1919.993 \nFixed bandwidth: 84.48025 AICc value: 1940.603 \nFixed bandwidth: 168.8448 AICc value: 1919.457 \nFixed bandwidth: 188.7606 AICc value: 1920.007 \nFixed bandwidth: 156.5362 AICc value: 1919.41 \nFixed bandwidth: 148.929 AICc value: 1919.527 \nFixed bandwidth: 161.2377 AICc value: 1919.392 \nFixed bandwidth: 164.1433 AICc value: 1919.403 \nFixed bandwidth: 159.4419 AICc value: 1919.393 \nFixed bandwidth: 162.3475 AICc value: 1919.394 \nFixed bandwidth: 160.5517 AICc value: 1919.391 \n\n\nDistance is larger. Some geographical spaces are larger, resulting in discrepancy.\n\ngwstat &lt;- gwss(data = hunan_sp,\n               vars = \"GDPPC\",\n               bw = bw_AIC,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T)\n\n\nclass(gwstat)\n\n[1] \"gwss\"\n\n\ngwstat is a gwss object class. Special to GWmodel. we are interested in gwstst$SDF and “gwstat[[”SDF”]]@data”\nGDPPC_LM is the local mean. LVar is the variance wrt the 22 neighbours, LCV is local correlation variance. LSKe is error. LSD is local standard deviation.\nIn order to use it, we have to use two steps. pull the list out and convert into dataframe. And now append it.\n\ngwstat_df &lt;- as.data.frame(gwstat$SDF)\nhunan_gstat &lt;- cbind(hunan_sf, gwstat_df) #cbind is to append row by row. Sequence matters.\n\n\ntm_shape(hunan_gstat) +\n  tm_polygons(col = \"GDPPC_LM\", \n              style = \"quantile\",\n              title = \"GDP per capita (local mean)\",\n              palette = \"YlOrRd\") +\n  tm_layout(main.title = \"Hunan Province GDP per capita\",\n            main.title.size = 1.2,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\")\n\n\n\n\n\n\nCorrelation coeficient.\nIs there any relationship between GDP per capita and gross industry output?\n\nbw_AIC_cor &lt;- bw.gwr(GDPPC ~ GIO,\n                data = hunan_sp,\n                approach = \"AIC\",\n                adaptive = TRUE, #if this is false, then it's fixed bandwidth\n                kernel = \"bisquare\",\n                longlat = T)\n\nAdaptive bandwidth (number of nearest neighbours): 62 AICc value: 1870.499 \nAdaptive bandwidth (number of nearest neighbours): 46 AICc value: 1870.902 \nAdaptive bandwidth (number of nearest neighbours): 72 AICc value: 1869.93 \nAdaptive bandwidth (number of nearest neighbours): 78 AICc value: 1869.589 \nAdaptive bandwidth (number of nearest neighbours): 82 AICc value: 1869.428 \nAdaptive bandwidth (number of nearest neighbours): 84 AICc value: 1869.688 \nAdaptive bandwidth (number of nearest neighbours): 80 AICc value: 1869.385 \nAdaptive bandwidth (number of nearest neighbours): 79 AICc value: 1869.47 \nAdaptive bandwidth (number of nearest neighbours): 80 AICc value: 1869.385 \n\ngwstat_cor &lt;- gwss(data = hunan_sp,\n               vars = c(\"GDPPC\",\"GIO\"),\n               bw = bw_AIC_cor,\n               kernel = \"bisquare\",\n               adaptive = TRUE,\n               longlat = T) \n\n\ngwstat_cor_df &lt;- as.data.frame(gwstat_cor$SDF) %&gt;%\n  select(12,13)\nhunan_gstat_cor &lt;- cbind(hunan_sf, gwstat_cor_df)  #cbind is to append row by row. Sequence matters.\nnames(hunan_gstat_cor)[11] &lt;- \"spearman\"\n\ntm_shape(hunan_gstat_cor) +\n  tm_polygons(col = \"spearman\",\n              style = \"quantile\",\n              title = \"Spearman Coefficient between GDPCC and GIO\",\n              palette = \"YlOrRd\") +\n  tm_layout(main.title = \"Coefficient Coefficient between GDPCC and GIO\",\n            main.title.size = 1.2,\n            legend.outside = TRUE,\n            legend.outside.position = \"right\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS626GAA",
    "section": "",
    "text": "Welcome to Xian Zu’s ISSS626 Visual Analytics and Applications homepage. In this website, you will find my homework for Prof Kam’s course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "pacman::p_load(\n  readr,       # for importing data\n  tidyverse,    # for data manipulation and visualization\n  sf,           # for spatial data handling\n  tmap,         # for thematic maps\n  lubridate,    # for date/time manipulation\n  spatstat,     # for point pattern analysis\n  ggstatsplot,  # for statistical data viz\n  maptools,     # for spatial object manipulation\n  raster,       # for raster data handling\n  sp,           # for spatial data classes and methods\n  leaflet,      # for interactive maps\n  ggplot2,      # for advanced plotting\n  spNetwork,    # for spatial network analysis\n  sparr,        # for spatio-temporal analysis\n  KernSmooth    # for kernel smoothing\n)\nset.seed(1234)\n\n\n\n\nIn this section, we will load and prepare the datasets necessary for our analysis of road traffic accidents in the Bangkok Metropolitan Region (BMR). The BMR, also known as Greater Bangkok, encompasses the city of Bangkok and its surrounding provinces. According to Wikipedia, this area includes Bangkok itself and five adjacent provinces: Nakhon Pathom, Pathum Thani, Nonthaburi, Samut Prakan, and Samut Sakhon. Our analysis will focus on this region, which serves as the political, economic, and cultural heart of Thailand.\nI will be working with three primary datasets: Thailand Road Accident data from 2019-2022, road network data from OpenStreetMap, and administrative boundary data. These datasets will allow me to conduct a comprehensive spatio-temporal analysis of road traffic accidents in this densely populated and economically significant area of Thailand.\n\n\n\nIn preparing our analysis of road traffic accidents in the Bangkok Metropolitan Region, care is taken to ensure our data is accurate and spatially consistent. First, we import the road accident data from 2019 to 2022 using read_csv(), a function chosen for its robust handling of various CSV formats (includes automatic reading of headers and correct tagging of date and time columns). Crucially, we filter out records with missing or empty longitude and latitude values. This step is vital as geographic coordinates are the cornerstone of our spatial analysis; including records without valid locations would skew our results and potentially lead to misleading conclusions about accident patterns.\nWe then transform this data into a spatial format using st_as_sf(). This conversion is essential as it allows us to perform spatial operations and visualisations. We specify the coordinate reference system (CRS) as EPSG:32647, which is tailored for Thailand. This was double-checked on https://epsg.io/. This choice is deliberate - using a local CRS ensures more accurate distance calculations and area representations compared to a global system like WGS84. For the road network data, sourced from OpenStreetMap, we employ st_read() to load the shapefile. Recognizing that OSM data can sometimes contain geometry inconsistencies, we apply st_make_valid(). This crucial step corrects any invalid geometries that could potentially crash our analysis or produce erroneous results in spatial operations. Lastly, we import administrative boundary data, again ensuring it aligns with our chosen CRS.\n\nrdacc_sf &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/Take-home_Ex/Take-home_Ex01/data/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%  #WGS84, decimel degree\n  st_transform(crs = 32647)  #32647 is Thai's\n#read_csv from Readr is better than read.csv base R. It matters for headers with spacing, and also can autodetect dates. \n\nroads_sf &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/Take-home_Ex/Take-home_Ex01/data/hotosm_tha_roads_lines_shp.shp\") %&gt;%\n  st_make_valid() %&gt;%\n  st_set_crs(4326) %&gt;%\n  st_transform(crs = 32647)\n\nadmin_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Take-Home_Ex/Take-Home_Ex01/data\", layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_set_crs(4326) %&gt;%\n  st_transform(crs = 32647)\n\n\nclass(admin_sf) # check class\nclass(rdacc_sf)\nclass(roads_sf)\n\n\n\n\n\nclass(rdacc_sf$incident_datetime)\nclass(rdacc_sf$report_datetime)\n\nThe incident_datetime and report_datetime fields are stored in POSIXct format, a structure that captures year, month, date, and time information. This format allows for easy extraction of specific temporal components such as month, day of the year, or year via lubridate package. The level of detail and flexibility in datetime handling is only available when the data is properly imported and parsed using readr.\n\n\n\nThe initial datasets cover all of Thailand and include various road types, which makes the dataset bloated and difficult to use. To focus on the Bangkok Metropolitan Region (BMR), a spatial filter is applied to extract data for Bangkok and its five adjacent provinces: Nakhon Pathom, Pathum Thani, Nonthaburi, Samut Prakan, and Samut Sakhon. This step reduces data volume and ensures geographic relevance. Additionally, the road network data is filtered to include only roads accessible to motor vehicles, excluding roads like pedestrian paths and cycling lanes. These filtering processes enhance the accuracy of the subsequent analysis by focusing on relevant geographic areas and road types where motor vehicle accidents are likely to occur.\n\nbangkok_areas &lt;- c(\"Bangkok\",\n                   \"Nonthaburi\",\n                   \"Samut Prakan\",\n                   \"Pathum Thani\",\n                   \"Samut Sakhon\",\n                   \"Nakhon Pathom\")\n\nadmin_sf_bkk &lt;- admin_sf %&gt;%\n  filter(!is.na(ADM1_EN) & ADM1_EN %in% bangkok_areas)\nunique(admin_sf_bkk$ADM1_EN)     #check\nplot(st_geometry(admin_sf_bkk))  #check, eval has been set to false, so no plots yet\nst_geometry_type(admin_sf_bkk)   #check\n\nrdacc_sf_bkk &lt;- rdacc_sf %&gt;%\n  filter(!is.na(province_en) & province_en %in% bangkok_areas)\nunique(rdacc_sf_bkk$province_en) #check\nplot(st_geometry(rdacc_sf_bkk))  #check\n\nroads_sf_bkk &lt;- st_intersection(roads_sf, admin_sf_bkk)\nunique(roads_sf_bkk$highway)     #check\nroads_sf_bkk_veh &lt;- roads_sf_bkk %&gt;%\n  filter(!is.na(highway) & \n           !(highway %in% c(\"pedestrian\",\n                            \"bridleway\",\n                            \"cycleway\",\n                            \"footway\",\n                            \"steps\",\n                            \"path\")))\nplot(st_geometry(roads_sf_bkk_veh)) #check\n\n\n\n\n\n\n\nThailand Highway Classification\n\n\n\nRefer to https://wiki.openstreetmap.org/wiki/WikiProject_Thailand#Highway_classification for definitions of different roads and access that is legally allowed.\n\n\n\n\n\nThe road network data contains both linestrings and multilinestrings. Multilinestrings represent complex road segments with multiple connected lines, while linestrings are single, continuous lines. Converting all geometries to linestrings simplifies the data structure, ensuring uniformity across the dataset, and makes it easier for lixelisation. Having multistrings may result in error. This conversion is necessary for consistent analysis, as many spatial operations work more efficiently with simple linestring geometries.\n\ngeometry_types &lt;- roads_sf_bkk_veh %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\n#check for linestrings and multistrings\nif(length(geometry_types) == 1 && geometry_types == \"LINESTRING\") {\n  print(\"All geometries are LINESTRING\")\n} else {\n  print(\"Not all geometries are LINESTRING. Types found:\")\n  print(geometry_types)\n}\n\n#convert to linstrings only\nroads_sf_bkk_veh_ls &lt;- roads_sf_bkk_veh %&gt;%\n  st_cast(\"MULTILINESTRING\", group_or_split = TRUE) %&gt;%  \n  st_cast(\"LINESTRING\")\n\n\ngeometry_types &lt;- roads_sf_bkk_veh_ls %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\n#check for linestrings and multistrings again to double confirm\nif(length(geometry_types) == 1 && geometry_types == \"LINESTRING\") {\n  print(\"All geometries are LINESTRING\")\n} else {\n  print(\"Not all geometries are LINESTRING. Types found:\")\n  print(geometry_types)\n}\n\n\n\n\nThis segment makes our data smaller and easier to work with. It is saved in a special format (RDS) in a ‘sandbox’ folder. This helps my computer run faster and keeps the project tidy. I used commands to save and load data, and tell some parts of our code not to run again if not needed.\n\nwrite_rds(roads_sf_bkk_veh_ls, \"data/sandbox/roads.rds\")\nwrite_rds(rdacc_sf_bkk, \"data/sandbox/rdacc.rds\")\nwrite_rds(admin_sf_bkk, \"data/sandbox/admin.rds\")\n\n\nroads &lt;- read_rds(\"data/sandbox/roads.rds\")\nrdacc &lt;- read_rds(\"data/sandbox/rdacc.rds\")\nadmin &lt;- read_rds(\"data/sandbox/admin.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-packages",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "pacman::p_load(\n  readr,       # for importing data\n  tidyverse,    # for data manipulation and visualization\n  sf,           # for spatial data handling\n  tmap,         # for thematic maps\n  lubridate,    # for date/time manipulation\n  spatstat,     # for point pattern analysis\n  ggstatsplot,  # for statistical data viz\n  maptools,     # for spatial object manipulation\n  raster,       # for raster data handling\n  sp,           # for spatial data classes and methods\n  leaflet,      # for interactive maps\n  ggplot2,      # for advanced plotting\n  spNetwork,    # for spatial network analysis\n  sparr,        # for spatio-temporal analysis\n  KernSmooth    # for kernel smoothing\n)\nset.seed(1234)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-files",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#load-files",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this section, we will load and prepare the datasets necessary for our analysis of road traffic accidents in the Bangkok Metropolitan Region (BMR). The BMR, also known as Greater Bangkok, encompasses the city of Bangkok and its surrounding provinces. According to Wikipedia, this area includes Bangkok itself and five adjacent provinces: Nakhon Pathom, Pathum Thani, Nonthaburi, Samut Prakan, and Samut Sakhon. Our analysis will focus on this region, which serves as the political, economic, and cultural heart of Thailand.\nI will be working with three primary datasets: Thailand Road Accident data from 2019-2022, road network data from OpenStreetMap, and administrative boundary data. These datasets will allow me to conduct a comprehensive spatio-temporal analysis of road traffic accidents in this densely populated and economically significant area of Thailand."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-1-correct-coordinate-reference-system",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-1-correct-coordinate-reference-system",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In preparing our analysis of road traffic accidents in the Bangkok Metropolitan Region, care is taken to ensure our data is accurate and spatially consistent. First, we import the road accident data from 2019 to 2022 using read_csv(), a function chosen for its robust handling of various CSV formats (includes automatic reading of headers and correct tagging of date and time columns). Crucially, we filter out records with missing or empty longitude and latitude values. This step is vital as geographic coordinates are the cornerstone of our spatial analysis; including records without valid locations would skew our results and potentially lead to misleading conclusions about accident patterns.\nWe then transform this data into a spatial format using st_as_sf(). This conversion is essential as it allows us to perform spatial operations and visualisations. We specify the coordinate reference system (CRS) as EPSG:32647, which is tailored for Thailand. This was double-checked on https://epsg.io/. This choice is deliberate - using a local CRS ensures more accurate distance calculations and area representations compared to a global system like WGS84. For the road network data, sourced from OpenStreetMap, we employ st_read() to load the shapefile. Recognizing that OSM data can sometimes contain geometry inconsistencies, we apply st_make_valid(). This crucial step corrects any invalid geometries that could potentially crash our analysis or produce erroneous results in spatial operations. Lastly, we import administrative boundary data, again ensuring it aligns with our chosen CRS.\n\nrdacc_sf &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/Take-home_Ex/Take-home_Ex01/data/thai_road_accident_2019_2022.csv\") %&gt;%\n  filter(!is.na(longitude) & longitude != \"\",\n         !is.na(latitude) & latitude != \"\") %&gt;%\n  st_as_sf(coords = c(\n    \"longitude\", \"latitude\"),\n    crs=4326) %&gt;%  #WGS84, decimel degree\n  st_transform(crs = 32647)  #32647 is Thai's\n#read_csv from Readr is better than read.csv base R. It matters for headers with spacing, and also can autodetect dates. \n\nroads_sf &lt;- st_read(\"C:/zzzzzuu/ISSS626GAA/Take-home_Ex/Take-home_Ex01/data/hotosm_tha_roads_lines_shp.shp\") %&gt;%\n  st_make_valid() %&gt;%\n  st_set_crs(4326) %&gt;%\n  st_transform(crs = 32647)\n\nadmin_sf &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Take-Home_Ex/Take-Home_Ex01/data\", layer = \"tha_admbnda_adm1_rtsd_20220121\") %&gt;%\n  st_set_crs(4326) %&gt;%\n  st_transform(crs = 32647)\n\n\nclass(admin_sf) # check class\nclass(rdacc_sf)\nclass(roads_sf)"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#check-date-and-time-format-posixct",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#check-date-and-time-format-posixct",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "class(rdacc_sf$incident_datetime)\nclass(rdacc_sf$report_datetime)\n\nThe incident_datetime and report_datetime fields are stored in POSIXct format, a structure that captures year, month, date, and time information. This format allows for easy extraction of specific temporal components such as month, day of the year, or year via lubridate package. The level of detail and flexibility in datetime handling is only available when the data is properly imported and parsed using readr."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-2-filtering-to-a-smaller-subset-of-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#data-wrangling-2-filtering-to-a-smaller-subset-of-data",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The initial datasets cover all of Thailand and include various road types, which makes the dataset bloated and difficult to use. To focus on the Bangkok Metropolitan Region (BMR), a spatial filter is applied to extract data for Bangkok and its five adjacent provinces: Nakhon Pathom, Pathum Thani, Nonthaburi, Samut Prakan, and Samut Sakhon. This step reduces data volume and ensures geographic relevance. Additionally, the road network data is filtered to include only roads accessible to motor vehicles, excluding roads like pedestrian paths and cycling lanes. These filtering processes enhance the accuracy of the subsequent analysis by focusing on relevant geographic areas and road types where motor vehicle accidents are likely to occur.\n\nbangkok_areas &lt;- c(\"Bangkok\",\n                   \"Nonthaburi\",\n                   \"Samut Prakan\",\n                   \"Pathum Thani\",\n                   \"Samut Sakhon\",\n                   \"Nakhon Pathom\")\n\nadmin_sf_bkk &lt;- admin_sf %&gt;%\n  filter(!is.na(ADM1_EN) & ADM1_EN %in% bangkok_areas)\nunique(admin_sf_bkk$ADM1_EN)     #check\nplot(st_geometry(admin_sf_bkk))  #check, eval has been set to false, so no plots yet\nst_geometry_type(admin_sf_bkk)   #check\n\nrdacc_sf_bkk &lt;- rdacc_sf %&gt;%\n  filter(!is.na(province_en) & province_en %in% bangkok_areas)\nunique(rdacc_sf_bkk$province_en) #check\nplot(st_geometry(rdacc_sf_bkk))  #check\n\nroads_sf_bkk &lt;- st_intersection(roads_sf, admin_sf_bkk)\nunique(roads_sf_bkk$highway)     #check\nroads_sf_bkk_veh &lt;- roads_sf_bkk %&gt;%\n  filter(!is.na(highway) & \n           !(highway %in% c(\"pedestrian\",\n                            \"bridleway\",\n                            \"cycleway\",\n                            \"footway\",\n                            \"steps\",\n                            \"path\")))\nplot(st_geometry(roads_sf_bkk_veh)) #check\n\n\n\n\n\n\n\nThailand Highway Classification\n\n\n\nRefer to https://wiki.openstreetmap.org/wiki/WikiProject_Thailand#Highway_classification for definitions of different roads and access that is legally allowed."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-multilinestrings-to-linestrings",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#converting-multilinestrings-to-linestrings",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "The road network data contains both linestrings and multilinestrings. Multilinestrings represent complex road segments with multiple connected lines, while linestrings are single, continuous lines. Converting all geometries to linestrings simplifies the data structure, ensuring uniformity across the dataset, and makes it easier for lixelisation. Having multistrings may result in error. This conversion is necessary for consistent analysis, as many spatial operations work more efficiently with simple linestring geometries.\n\ngeometry_types &lt;- roads_sf_bkk_veh %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\n#check for linestrings and multistrings\nif(length(geometry_types) == 1 && geometry_types == \"LINESTRING\") {\n  print(\"All geometries are LINESTRING\")\n} else {\n  print(\"Not all geometries are LINESTRING. Types found:\")\n  print(geometry_types)\n}\n\n#convert to linstrings only\nroads_sf_bkk_veh_ls &lt;- roads_sf_bkk_veh %&gt;%\n  st_cast(\"MULTILINESTRING\", group_or_split = TRUE) %&gt;%  \n  st_cast(\"LINESTRING\")\n\n\ngeometry_types &lt;- roads_sf_bkk_veh_ls %&gt;%\n  st_geometry_type() %&gt;%\n  as.character() %&gt;%\n  unique()\n\n#check for linestrings and multistrings again to double confirm\nif(length(geometry_types) == 1 && geometry_types == \"LINESTRING\") {\n  print(\"All geometries are LINESTRING\")\n} else {\n  print(\"Not all geometries are LINESTRING. Types found:\")\n  print(geometry_types)\n}"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#write-a-smaller-subset-of-the-data-for-easier-compute-times",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#write-a-smaller-subset-of-the-data-for-easier-compute-times",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "This segment makes our data smaller and easier to work with. It is saved in a special format (RDS) in a ‘sandbox’ folder. This helps my computer run faster and keeps the project tidy. I used commands to save and load data, and tell some parts of our code not to run again if not needed.\n\nwrite_rds(roads_sf_bkk_veh_ls, \"data/sandbox/roads.rds\")\nwrite_rds(rdacc_sf_bkk, \"data/sandbox/rdacc.rds\")\nwrite_rds(admin_sf_bkk, \"data/sandbox/admin.rds\")\n\n\nroads &lt;- read_rds(\"data/sandbox/roads.rds\")\nrdacc &lt;- read_rds(\"data/sandbox/rdacc.rds\")\nadmin &lt;- read_rds(\"data/sandbox/admin.rds\")"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixelisation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#lixelisation",
    "title": "Take-home Exercise 1",
    "section": "Lixelisation",
    "text": "Lixelisation\nTo prepare for Network Kernel Density Estimation (NKDE), the road network is divided into small, equal segments called lixels using the lixelize_lines() function from the spNetwork package. Lixels are like pixels for lines, allowing more precise analysis along the network. This process is crucial for accurately studying patterns of childcare centers along the road network. It creates a consistent unit of measurement, which is especially useful when dealing with irregular network structures.\n\nlixels &lt;- lixelize_lines(roads_filtered, # Create lixels from filtered roads\n                         700, \n                         mindist = 500)\nsamples &lt;- lines_center(lixels) # Generate center points of lixels\ndensities &lt;- nkde(roads_filtered, \n                  events = rdacc,\n                  w = rep(1, nrow(rdacc)), # Assign equal weight to each accident\n                  samples = samples,\n                  kernel_name = \"quartic\",\n                  bw = 100,  # Set bandwidth to 100 meters\n                  div= \"bw\", # Divide by bandwidth\n                  method = \"simple\", \n                  digits = 1, # Round results to 1 decimal place\n                  tol = 1,\n                  grid_shape = c(4,4), # Set grid shape for calculations\n                  max_depth = 8,\n                  agg = 5, # Aggregate every 5 points\n                  sparse = TRUE,\n                  verbose = FALSE)\nsamples$density &lt;- densities\nlixels$density &lt;- densities\nsummary(samples$density)\n\nThe values seem small. The measurements must be in metres. Let’s correct that to km later. Let’s save the lixelised data first.\n\nwrite_rds(lixels, \"data/sandbox/lixels.rds\")\nwrite_rds(samples, \"data/sandbox/samples.rds\")\n\nNow let’s read in the data and correct the measurement.\n\nlixels &lt;- read_rds(\"data/sandbox/lixels.rds\")\nsamples &lt;- read_rds(\"data/sandbox/samples.rds\")\nsamples$density &lt;- samples$density*1000\nlixels$density &lt;- lixels$density*1000\nsummary(samples$density)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.00000 0.01504 0.00000 2.58070 \n\nsummary(lixels$density)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n0.00000 0.00000 0.00000 0.01504 0.00000 2.58070 \n\n\nThat looks better. From the quantiles, means and medians, it seems that the hotspots are quite scant and concentrated at the top. It would be good to merge everything below the mean, while having more granular breaks in the top quartile to examine the hot spots in more detail.\nLet’s try to plot it."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overall-situation-of-road-accidents-in-bmr",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#overall-situation-of-road-accidents-in-bmr",
    "title": "Take-home Exercise 1",
    "section": "Overall situation of road accidents in BMR",
    "text": "Overall situation of road accidents in BMR\n\n#This is to help me identify the road names, used in \"View\" mode. For website's puposes, I have changed to \"plot\" mode to save on memory, so you won't see the road name in the plot, but know that it is available.\nlixels$display_name &lt;- ifelse(is.na(lixels$name_en), \n                              paste(lixels$highway,\": Unnamed Road\"),\n                              paste(lixels$highway,\": \",lixels$name_en))\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ncustom_breaks &lt;- c(0, quantile(lixels$density, c(0.85, \n                                                 0.9, \n                                                 0.95,\n                                                 0.99, \n                                                 1)))\ntm_shape(lixels) +\n  tm_lines(col = \"density\",\n           id = \"display_name\",\n           breaks = custom_breaks,\n           palette = \"YlOrRd\",\n           lwd = 1.5)+\n  tm_shape(admin) +  \n  tm_borders(col = \"black\", lwd = 2, alpha = 0.5)\n\n\n\n\nThe accident density map of Bangkok and its surrounding provinces reveals patterns in road safety across the region. The central area, primarily Bangkok, exhibits some concentrations of accident hotspots, indicating a greater risk in the urban core. This concentration likely correlates with higher population density, increased traffic volume, and more complex road networks typical of major city centers.\nWhile accident density generally decreases towards the outskirts, there are notable hotspots in the peripheral areas surrounding Bangkok. These could represent key transportation corridors or rapidly developing suburban zones with high traffic flow. It looks like this happens mainly on the Kanchanaphisek Road.\nThe skewed distribution of accident densities, as shown in the legend, highlights the presence of extreme hotspots amid generally moderate-to-high risk areas. This pattern underscores the need for targeted interventions in specific high-risk locations while also addressing broader regional safety concerns. We should look into them.\nThe specific roads that warrant more attention are:\n\nKanchanaphisek Road (both east and west portions of the long road)\nBangkok-Chonburi Motorway\nBorommaratchachonnani Road\nRama II Road\nSuk Sawat Road\nIndustrial Ring Road"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis-of-road-accidents",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis-of-road-accidents",
    "title": "Take-home Exercise 1",
    "section": "Temporal analysis of road accidents",
    "text": "Temporal analysis of road accidents\nIn the following analysis, let’s examine temporal patterns of road accidents in the Bangkok Metropolitan Region from 2019 to 2022. Let’s visualize accident frequencies across different time scales, including hours of the day, days of the week, months, and years. This temporal breakdown will help identify high-risk periods influencing accident rates.\n\n# Ensure datetime columns are properly formatted\nrdacc$incident_datetime &lt;- ymd_hms(rdacc$incident_datetime)\n\nWarning: 16 failed to parse.\n\n# Create new columns for analysis\nrdacc_inc &lt;- rdacc %&gt;%\n  mutate(\n    hour = hour(incident_datetime),\n    day_of_week = wday(incident_datetime, label = TRUE),\n    month = month(incident_datetime, label = TRUE),\n    year = year(incident_datetime)\n  )\n\n# Accidents by hour of day\nggplot(rdacc_inc, aes(x = hour)) +\n  geom_bar() +\n  labs(title = \"Accidents by Hour of Day\", x = \"Hour\", y = \"Number of Accidents\")\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n#Insight: Accidents appear to happen from 7am to 11am and 7pm.\n\n# Accidents by day of week\nggplot(rdacc_inc, aes(x = day_of_week)) +\n  geom_bar() +\n  labs(title = \"Accidents by Day of Week\", x = \"Day\", y = \"Number of Accidents\")\n\n\n\n#Insight: Accidents appear to happen on Friday and Saturday.\n\n# Accidents by month\nggplot(rdacc_inc, aes(x = month)) +\n  geom_bar() +\n  labs(title = \"Accidents by Month\", x = \"Month\", y = \"Number of Accidents\")\n\n\n\n#Insight: Accidents appear to happen In Dec, Jan, Apr, and Oct.\n\n# Time series of accidents by date\nrdacc_inc %&gt;%\n  count(date = as.Date(incident_datetime)) %&gt;%\n  ggplot(aes(x = date, y = n)) +\n  geom_line() +\n  labs(title = \"Daily Accident Counts Over Time\", x = \"Date\", y = \"Number of Accidents\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n#Insight: Accidents spike every year in Jan/ Dec and Apr.\n\n# Time series of accidents by year\nggplot(rdacc_inc, aes(x = year)) +\n  geom_bar() +\n  labs(title = \"Accidents by Year\", x = \"Year\", y = \"Number of Accidents\")\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n#Insight: Fluctuating with a graduate increase per year.\n\nLet’s take a look at two heatmaps that examines when accidents happen.\n\nlibrary(viridis)\n\nWarning: package 'viridis' was built under R version 4.3.3\n\n\nLoading required package: viridisLite\n\nrdacc_time &lt;- rdacc %&gt;%\n  mutate(\n    month = month(incident_datetime, label = TRUE, abbr = TRUE),\n    hour = hour(incident_datetime)\n  )\n\naccident_counts &lt;- rdacc_time %&gt;%\n  count(month, hour)\n\nggplot(accident_counts, aes(x = hour, y = month, fill = n)) +\n  geom_tile() +\n  scale_fill_viridis(name = \"Number of Accidents\", \n                     option = \"inferno\", \n                     breaks = seq(20, 80, by = 20),\n                     limits = c(20, 80)) +\n  scale_x_continuous(breaks = seq(0, 23, by = 3), \n                     labels = c(\"12am\", \"3am\", \"6am\", \"9am\", \"12pm\", \"3pm\", \"6pm\", \"9pm\")) +\n  scale_y_discrete(limits = rev(levels(accident_counts$month))) +\n  labs(title = \"Heatmap of Accidents by Month and Time of Day\",\n       subtitle = \"Bangkok Metropolitan Region, 2019-2022\",\n       x = \"Time of Day\",\n       y = \"Month\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 12, color = \"gray50\"),\n    axis.title = element_text(face = \"bold\")\n  )\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\n\n\n\nIt appears that Jan, Apr, Oct, Dec is worth investigating.\nKey observations:\n\nSeasonal trends: Apr and Dec shows consistently high accident rates throughout the day. This could be related to increased holiday traffic or year-end celebrations.\nMorning trends: There’s a noticeable increase in accidents starting around 6am across most months, likely corresponding to morning rush hour.\nNight-time patterns: Accident rates generally decrease late at night (12am-3am), but remain somewhat elevated compared to early morning hours (3am-6am)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-date-and-time-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#creating-date-and-time-analysis",
    "title": "Take-home Exercise 1",
    "section": "Creating date and time analysis",
    "text": "Creating date and time analysis\nWIP"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-apr",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-apr",
    "title": "Take-home Exercise 1",
    "section": "Focused look at Apr",
    "text": "Focused look at Apr\n\nrdacc_apr &lt;- rdacc %&gt;%\n  filter(month(incident_datetime) == 4)\n\nlixels_apr &lt;- lixelize_lines(roads_filtered, \n                         700, \n                         mindist = 500)\nsamples_apr &lt;- lines_center(lixels_apr) \ndensities_apr &lt;- nkde(roads_filtered, \n                  events = rdacc_apr,\n                  w = rep(1, nrow(rdacc_apr)),\n                  samples = samples_apr,\n                  kernel_name = \"quartic\",\n                  bw = 100, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(4,4), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\nsamples_apr$density &lt;- densities_apr\nlixels_apr$density &lt;- densities_apr\nsummary(samples_apr$density)\n\n\nwrite_rds(lixels_apr, \"data/sandbox/lixels_apr.rds\")\nwrite_rds(samples_apr, \"data/sandbox/samples_apr.rds\")\n\n\nlixels_apr &lt;- read_rds(\"data/sandbox/lixels_apr.rds\")\nsamples_apr &lt;- read_rds(\"data/sandbox/samples_apr.rds\")\nsamples_apr$density &lt;- samples_apr$density*1000\nlixels_apr$density &lt;- lixels_apr$density*1000\nsummary(samples_apr$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.001457 0.000000 0.468568 \n\nsummary(lixels_apr$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.001457 0.000000 0.468568 \n\n\n\nlixels_apr$display_name &lt;- ifelse(is.na(lixels_apr$name_en), \n                              paste(lixels_apr$highway,\": Unnamed Road\"),\n                              paste(lixels_apr$highway,\": \",lixels_apr$name_en))\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ncustom_breaks &lt;- c(0, quantile(lixels_apr$density, c(0.99,\n                                                     0.992,\n                                                     0.994,\n                                                     0.996,\n                                                     0.998,\n                                                     1)))\ntm_shape(lixels_apr) +\n  tm_lines(col = \"density\",\n           id = \"display_name\",\n           breaks = custom_breaks,\n           palette = \"YlOrRd\",\n           lwd = 1.5)+\n  tm_shape(admin) +  \n  tm_borders(col = \"black\", lwd = 2, alpha = 0.5)\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nAccidents are spread across the entire region, but with varying densities. These highways seem to be attracting accidents:\n\nKanchanaphisek Road (east portion of the long road)\nBangkok-Chonburi Motorway\nBorommaratchachonnani Road\nIndustrial Ring Road"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-jan-and-dec",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-jan-and-dec",
    "title": "Take-home Exercise 1",
    "section": "Focused look at Jan and Dec",
    "text": "Focused look at Jan and Dec\n\nrdacc_jandec &lt;- rdacc %&gt;%\n  filter(month(incident_datetime) %in% c(1, 12))\n\nlixels_jandec &lt;- lixelize_lines(roads_filtered, \n                         700, \n                         mindist = 500)\nsamples_jandec &lt;- lines_center(lixels_jandec) \ndensities_jandec &lt;- nkde(roads_filtered, \n                  events = rdacc_jandec,\n                  w = rep(1, nrow(rdacc_jandec)),\n                  samples = samples_jandec,\n                  kernel_name = \"quartic\",\n                  bw = 100, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(4,4), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\nsamples_jandec$density &lt;- densities_jandec\nlixels_jandec$density &lt;- densities_jandec\nsummary(samples_jandec$density)\n\n\nwrite_rds(lixels_jandec, \"data/sandbox/lixels_jandec.rds\")\nwrite_rds(samples_jandec, \"data/sandbox/samples_jandec.rds\")\n\n\nlixels_jandec &lt;- read_rds(\"data/sandbox/lixels_jandec.rds\")\nsamples_jandec &lt;- read_rds(\"data/sandbox/samples_jandec.rds\")\nsamples_jandec$density &lt;- samples_jandec$density*1000\nlixels_jandec$density &lt;- lixels_jandec$density*1000\nsummary(samples_jandec$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.002753 0.000000 0.658608 \n\nsummary(lixels_jandec$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.002753 0.000000 0.658608 \n\n\n\nlixels_jandec$display_name &lt;- ifelse(is.na(lixels_jandec$name_en), \n                                     paste(lixels_jandec$highway,\": Unnamed Road\"),\n                                     paste(lixels_jandec$highway,\": \",lixels_jandec$name_en))\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ncustom_breaks &lt;- c(0, quantile(lixels_jandec$density, c(0.99,\n                                                     0.992,\n                                                     0.994,\n                                                     0.996,\n                                                     0.998,\n                                                     1)))\ntm_shape(lixels_jandec) +\n  tm_lines(col = \"density\",\n           id = \"display_name\",\n           breaks = custom_breaks,\n           palette = \"YlOrRd\",\n           lwd = 1.5)+\n  tm_shape(admin) +  \n  tm_borders(col = \"black\", lwd = 2, alpha = 0.5)\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nSimilar patterns observed.\nWe should be able to merge Apr accidents with that of Jan, Oct and Dec."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis",
    "title": "Take-home Exercise 1",
    "section": "Temporal analysis",
    "text": "Temporal analysis\nLet’s try a simple month breakdown first to see the seasonal changes across months.\n\ntm_shape(admin)+\n  tm_polygons() +\ntm_shape(rdacc_spatiotemporal) +\n  tm_dots(size = 0.1) +\ntm_facets(by=\"Month_fac\", \n            free.coords=FALSE, \n            drop.units = TRUE)\n\n\n\n\nThe December months appear more sparse, but that is roughly all I can tell from visual inspection.\nTo analyse with more statistical rigour, I’ll try to calculate a non-network constrained KDE to examine the hotspots. Simply put, it smooths the road accidents over the owin space. I will need to use ppp for this.\n\nrdacc_spatiotemporal_month &lt;- rdacc_spatiotemporal %&gt;% \n  dplyr::select(Month_num)\nrdacc_spatiotemporal_month_ppp &lt;- as.ppp(rdacc_spatiotemporal_month)\nrdacc_spatiotemporal_month_ppp\n\nMarked planar point pattern: 12986 points\nmarks are numeric, of storage type  'double'\nwindow: rectangle = [591277.5, 710166.1] x [1486845.7, 1576520.5] units\n\nany(duplicated(rdacc_spatiotemporal_month_ppp))\n\n[1] TRUE\n\nrdacc_spatiotemporal_month_ppp_jit &lt;- rjitter(rdacc_spatiotemporal_month_ppp, \n                                              retry=TRUE, \n                                              nsim=1, \n                                              drop=TRUE)\nany(duplicated(rdacc_spatiotemporal_month_ppp_jit))\n\n[1] FALSE\n\n\nThis next segment plots the points within the owin.\n\nrdacc_month_owin &lt;- rdacc_spatiotemporal_month_ppp_jit[admin_owin]\nsummary(rdacc_month_owin)\n\nMarked planar point pattern:  12979 points\nAverage intensity 1.6924e-06 points per square unit\n\nCoordinates are given to 10 decimal places\n\nmarks are numeric, of type 'double'\nSummary:\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  1.000   4.000   7.000   6.667  10.000  12.000 \n\nWindow: polygonal boundary\nsingle connected closed polygon with 13779 vertices\nenclosing rectangle: [587893.5, 712440.5] x [1484413.7, 1579076.3] units\n                     (124500 x 94660 units)\nWindow area = 7668990000 square units\nFraction of frame area: 0.65\n\nplot(rdacc_month_owin)\n\n\n\n\nThis next segment calculates the KDE within the owin.\n\nst_kde &lt;- spattemp.density(rdacc_month_owin)\n\nCalculating trivariate smooth...Done.\nEdge-correcting...Done.\nConditioning on time...Done.\n\nsummary(st_kde)\n\nSpatiotemporal Kernel Density Estimate\n\nBandwidths\n  h = 4255.367 (spatial)\n  lambda = 0.0114 (temporal)\n\nNo. of observations\n  12979 \n\nSpatial bound\n  Type: polygonal\n  2D enclosure: [587893.5, 712440.5] x [1484414, 1579076]\n\nTemporal bound\n  [1, 12]\n\nEvaluation\n  128 x 128 x 12 trivariate lattice\n  Density range: [4.83487e-18, 6.233343e-09]\n\n\nLet’s plot the months out to see how it shifts.\n\ntims &lt;- c(1:12)\npar(mfcol=c(2,3))\nfor(i in tims){ \n  plot(st_kde, i, \n       override.par=FALSE, \n       fix.range=TRUE, \n       main=paste(\"KDE at month\",i))\n}\n\n\n\n\n\n\n\nWe can make it into a gif for easier examination of how the months change from each other.\n\ncreate_and_save_plot &lt;- function(i) {\n  png(filename = paste0(\"kde_plot_month_\", i, \".png\"), \n      width = 800, height = 600)  # Adjust width and height as needed\n  plot(st_kde, i, \n       override.par = FALSE, \n       fix.range = TRUE, \n       main = paste(\"KDE at month\", i))\n  dev.off()\n}\n\n# Create and save each plot separately\nfor(i in tims) {\n  create_and_save_plot(i)\n}\n\nI examine the change using the below gif.\nIt does look like there is a slight increase in road accidents in Apr, but the larger increase is in December and January. However, this is not constrained to a network, so it still does not show which road the accidents are on. So this analysis is insufficient, and we need to explore a network constrained solution.\n\nLet’s try network constraining the KDE. First, I’ll format the time so that it is counting days.\n\n# converting the Date field to a numeric field (counting months)\nrdacc_spatiotemporal &lt;- rdacc\nrdacc_spatiotemporal$Time &lt;- as.POSIXct(rdacc_spatiotemporal$incident_datetime, format = \"%Y/%m/%d\")\nstart &lt;- as.POSIXct(\"2019/01/01\", format = \"%Y/%m/%d\")\nend &lt;- as.POSIXct(\"2022/12/31\", format = \"%Y/%m/%d\")\nrdacc_spatiotemporal$Time &lt;- difftime(rdacc_spatiotemporal$Time, start, units = \"days\")\nrdacc_spatiotemporal$Time &lt;- as.numeric(rdacc_spatiotemporal$Time)\n\nmonths &lt;- as.character(1:12)\nmonths &lt;- ifelse(nchar(months)==1, paste0(\"0\", months), months)\nmonths_starts_labs &lt;- paste(\"2019/\",months,\"/01\", sep = \"\")\nmonths_starts_num &lt;- as.POSIXct(months_starts_labs, format = \"%Y/%m/%d\")\nmonths_starts_num &lt;- difftime(months_starts_num, start, units = \"days\")\nmonths_starts_num &lt;- as.numeric(months_starts_num)\nmonths_starts_labs &lt;- gsub(\"2019/\", \"\", months_starts_labs, fixed = TRUE)\n\n# Create breaks for each year\nyears &lt;- seq(start, end, by = \"year\")\nyear_breaks &lt;- as.numeric(difftime(years, start, units = \"days\"))\n\n# Create labels for each year\nyear_labels &lt;- format(years, \"%Y\")\n\nggplot(rdacc_spatiotemporal) + \n  geom_histogram(aes(x = Time), bins = 48, color = \"white\") +  # 48 bins for monthly-like divisions\n  scale_x_continuous(breaks = year_breaks, \n                     labels = year_labels,\n                     limits = c(0, max(rdacc_spatiotemporal$Time))) +\n  labs(x = \"Year\", y = \"Frequency\", title = \"Distribution of Incidents Over Time\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nWarning: Removed 2 rows containing missing values or values outside the scale range\n(`geom_bar()`).\n\n\n\n\n\nI shall smooth out the number of incidents across days.\n\nw &lt;- rep(1,nrow(rdacc_spatiotemporal))\nsamples &lt;- seq(0, max(rdacc_spatiotemporal$Time), 0.5)\n\nbw1 &lt;- bw.bcv(rdacc_spatiotemporal$Time, nb = 1000, lower = 1, upper = 80)\nbw2 &lt;- bw.ucv(rdacc_spatiotemporal$Time, nb = 1000, lower = 1, upper = 80)\nbw3 &lt;- bw.SJ(rdacc_spatiotemporal$Time, nb = 1000, lower = 1, upper = 80)\n\n\ntime_kernel_values &lt;- data.frame(\n  bw_bcv = tkde(rdacc_spatiotemporal$Time, w = w, samples = samples, bw = bw1, kernel_name = \"quartic\"),\n  bw_ucv = tkde(rdacc_spatiotemporal$Time, w = w, samples = samples, bw = bw2, kernel_name = \"quartic\"),\n  bw_SJ = tkde(rdacc_spatiotemporal$Time, w = w, samples = samples, bw = bw3, kernel_name = \"quartic\"),\n  time = samples\n)\n\ndf_time &lt;- reshape2::melt(time_kernel_values,id.vars = \"time\")\ndf_time$variable &lt;- as.factor(df_time$variable)\n\nggplot(data = df_time) + \n  geom_line(aes(x = time, y = value)) +\n  scale_x_continuous(breaks = year_breaks, \n                     labels = year_labels,\n                     limits = c(0, max(rdacc_spatiotemporal$Time))) +\n  facet_wrap(vars(variable), ncol=2, scales = \"free\")  + \n  theme(axis.text = element_text(size = 5))\n\n\n\n\nBy comparing bandwidth selection methods, there are insights into the temporal patterns of road accidents . The BCV and SJ methods particularly highlight meaningful patterns compared to UCV method as it is too noisy and may lead to misinterpretation. It appears there are seasonal patterns as we have seen."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatio-temporal-analysis-with-network-constraint",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#spatio-temporal-analysis-with-network-constraint",
    "title": "Take-home Exercise 1",
    "section": "Spatio-temporal analysis with network constraint",
    "text": "Spatio-temporal analysis with network constraint\nNext we do spatio-temporal analysis to verify this observation. We start by examining the bandwidths that are required to have a useful smoothing.\n\ncv_scores &lt;- bw_tnkde_cv_likelihood_calc(\n  bws_net = seq(1000,10000,2000),\n  bws_time = seq(1,1460,200),\n  lines = roads_filtered,\n  events = rdacc_spatiotemporal,\n  time_field = \"incident_datetime\",\n  w = rep(1, nrow(rdacc_spatiotemporal)),\n  kernel_name = \"quartic\",\n  method = \"discontinuous\",\n  diggle_correction = FALSE,\n  study_area = NULL,\n  max_depth = 10,\n  digits = 2,\n  tol = 0.1,\n  agg = 10,\n  sparse=TRUE,\n  grid_shape=c(20,20),\n  sub_sample=1,\n  verbose = FALSE,\n  check = TRUE)\nwrite_rds(cv_scores, \"data/sandbox/cv_scores.rds\")\n\n\ncv_scores &lt;- read_rds(\"data/sandbox/cv_scores.rds\")\nknitr::kable(cv_scores)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n201\n401\n601\n801\n1001\n1201\n1401\n\n\n\n\n1000\n-706.1509\n-705.3445\n-704.8251\n-703.1704\n-702.8447\n-701.8549\n-700.9763\n-700.4512\n\n\n3000\n-705.0980\n-704.1014\n-702.7534\n-700.4870\n-700.0528\n-698.6526\n-697.3181\n-696.6342\n\n\n5000\n-704.4165\n-703.1201\n-701.5165\n-699.2029\n-698.5118\n-696.5971\n-694.6536\n-693.7567\n\n\n7000\n-703.8892\n-702.2912\n-700.2770\n-697.2513\n-696.5538\n-694.4873\n-692.1887\n-690.9826\n\n\n9000\n-703.6275\n-701.6716\n-699.3488\n-696.0194\n-695.1658\n-692.9957\n-690.0855\n-688.8752\n\n\n\n\n\nThe tables show that AIC does not really decrease much. So I shall pick a logical bandwidth to work with and proceed from there - 1km and 60 days.\nBut because the KDE calculation is producing errors due to large dataset, I chose to filter the road system again.\n\nunique(roads$highway)\n\n [1] \"secondary\"      \"residential\"    \"secondary_link\" \"service\"       \n [5] \"track\"          \"tertiary\"       \"primary\"        \"primary_link\"  \n [9] \"unclassified\"   \"trunk_link\"     \"motorway_link\"  \"motorway\"      \n[13] \"construction\"   \"trunk\"          \"corridor\"       \"tertiary_link\" \n[17] \"raceway\"        \"busway\"         \"road\"           \"proposed\"      \n\nroads_filtered_again &lt;- roads %&gt;%\n  filter(!is.na(highway) & \n           (highway %in% c(\"secondary\", #Dropped  links to scope to smaller network\n                           \"primary\",\n                           \"trunk\",\n                           \"motorway\")))\nplot(st_geometry(roads_filtered_again))\n\n\n\n\nAbove seems ok to use. However, my computer still couldn’t handle the load. So I have to use sampling to make the calculation possible. Below is the code to sample for a usable ammount of network and accidents.\n\n# Redo this part just to be safe: converting the Date field to a numeric field (counting months)\nrdacc_spatiotemporal &lt;- rdacc\nrdacc_spatiotemporal$Time &lt;- as.POSIXct(rdacc_spatiotemporal$incident_datetime, format = \"%Y/%m/%d\")\nstart &lt;- as.POSIXct(\"2019/01/01\", format = \"%Y/%m/%d\")\nend &lt;- as.POSIXct(\"2022/12/31\", format = \"%Y/%m/%d\")\nrdacc_spatiotemporal$Time &lt;- difftime(rdacc_spatiotemporal$Time, start, units = \"days\")\nrdacc_spatiotemporal$Time &lt;- as.numeric(rdacc_spatiotemporal$Time)\n\n# choosing sample in times (every 50 days)\nsample_time &lt;- seq(0, max(as.numeric(rdacc_spatiotemporal$Time)), 50)\nrdacc_spatiotemporal_sample &lt;- rdacc_spatiotemporal %&gt;%\n  slice_sample(n = 5000)\nroads_filtered_again_sample &lt;- roads_filtered_again %&gt;%\n  slice_sample(n = 5000)\n\n# calculating densities\ntnkde_densities &lt;- tnkde(lines = roads_filtered_again_sample, # Input road network\n                         events = rdacc_spatiotemporal_sample, # Accident data\n                         time_field = \"Time\", # Column name for time\n                         w = rep(1, nrow(rdacc_spatiotemporal_sample)), # Equal weights for all events\n                         samples_loc = samples, # Spatial locations for density estimation\n                         samples_time = sample_time, # Time points for density estimation\n                         kernel_name = \"quartic\",# Type of kernel function\n                         bw_net = 1000, bw_time = 60,# Bandwidth for network and time\n                         adaptive = TRUE,# Use adaptive bandwidth\n                         trim_bw_net = 900,# Trim bandwidths\n                         trim_bw_time = 80,\n                         method = \"continuous\",# Use continuous TNKDE method\n                         div = \"bw\", max_depth = 10,# Divide by bandwidth\n                         digits = 2, tol = 0.01,# Tolerance for calculations\n                         agg = 15, grid_shape = c(1,1), # Aggregate every 15 points\n                         verbose  = FALSE)# Don't print progress messages\n\nwrite_rds(tnkde_densities, \"data/sandbox/tnkde_densities.rds\")\n\n\n# Eval set to false since the gif is already drawn\ntnkde_densities &lt;- read_rds(\"data/sandbox/tnkde_densities.rds\")\n\n# creating a color palette for all the densities\nlibrary(classInt)\nlibrary(viridis)\nall_densities &lt;- c(tnkde_densities$k)\ncolor_breaks &lt;- classIntervals(all_densities, n = 10, style = \"kmeans\")\n\n# generating a map at each sample time\nall_maps &lt;- lapply(1:ncol(tnkde_densities$k), function(i){\n  time &lt;- sample_time[[i]]\n  date &lt;- as.Date(start) + time\n  \n  samples$density &lt;- tnkde_densities$k[,i]\n  map1 &lt;- tm_shape(samples) + \n  tm_dots(col = \"density\", size = 0.01,\n          breaks = color_breaks$brks, palette = viridis(10)) + \n    tm_layout(legend.show=FALSE, main.title = as.character(date), main.title.size = 0.5)\n  return(map1)\n})\n\n# creating a gif with all the maps\ntmap_animation(all_maps, filename = \"animated_map.gif\", \n               width = 1000, height = 1000, dpi = 300, delay = 50)\n\n\n\n\nSpatiotemporalgif\n\n\nThe spatio-temporal map shows that Kanchanaphisek Road, Borommaratchachonnani Road and Industrial Ring Road are serious hotspots for road accidents."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5",
    "section": "",
    "text": "Let’s learn how to compute the GMSA from spdep."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#load-packages",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#load-packages",
    "title": "Hands-on Exercise 5",
    "section": "Load packages",
    "text": "Load packages\n\npacman::p_load(sf, spdep, tmap, tidyverse)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#import-shapefiles",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#import-shapefiles",
    "title": "Hands-on Exercise 5",
    "section": "Import shapefiles",
    "text": "Import shapefiles\n\nhunan &lt;- st_read(dsn = \"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex04/data/geospatial\", \n                 layer = \"Hunan\")\n\nReading layer `Hunan' from data source \n  `C:\\zzzzzuu\\ISSS626GAA\\Hands-on_Ex\\Hands-on_Ex04\\data\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 88 features and 7 fields\nGeometry type: POLYGON\nDimension:     XY\nBounding box:  xmin: 108.7831 ymin: 24.6342 xmax: 114.2544 ymax: 30.12812\nGeodetic CRS:  WGS 84\n\nhunan2012 &lt;- read_csv(\"C:/zzzzzuu/ISSS626GAA/Hands-on_Ex/Hands-on_Ex04/data/aspatial/Hunan_2012.csv\")\n\nRows: 88 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): County, City\ndbl (27): avg_wage, deposite, FAI, Gov_Rev, Gov_Exp, GDP, GDPPC, GIO, Loan, ...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#join",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#join",
    "title": "Hands-on Exercise 5",
    "section": "Join",
    "text": "Join\n\nhunan &lt;- left_join(hunan,hunan2012) %&gt;%\n  dplyr::select(1:4, 7, 15)\n\nJoining with `by = join_by(County)`"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#compute-spatial-weights",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#compute-spatial-weights",
    "title": "Hands-on Exercise 5",
    "section": "Compute spatial weights",
    "text": "Compute spatial weights\nTo analyse spatial patterns, we first need to define which areas are “neighbors” to each other. This is done by creating a spatial weights matrix.\nWe’ll use the poly2nb() function from the spdep package to do this. This function looks at our map and figures out which areas touch each other.\nBy default, it uses what’s called the “Queen” method. This means it considers areas as neighbors if they share any border or corner, just like how a queen can move in chess.\nHere’s how we’d typically write the code to do this:\n\nwm_q &lt;- poly2nb(hunan, \n                queen=TRUE)\nsummary(wm_q)\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \nLink number distribution:\n\n 1  2  3  4  5  6  7  8  9 11 \n 2  2 12 16 24 14 11  4  2  1 \n2 least connected regions:\n30 65 with 1 link\n1 most connected region:\n85 with 11 links\n\n\nThis creates a list showing which areas are neighbors to each other, based on shared borders or corners.\nThe summary report above shows that there are 88 area units in Hunan. The most connected area unit has 11 neighbours. There are two area units with only one neighbours.\nAfter identifying neighbors, we need to decide how much influence each neighbor has. We’ll use a simple method where each neighbor has equal importance.\nHere’s how it works:\n\nFor each area, we count how many neighbors it has.\nWe give each neighbor a weight of 1 divided by the total number of neighbors.\n\nFor example, if an area has 4 neighbors, each neighbor gets a weight of 1/4.\nThis method is called “row standardization” and is denoted as style=“W” in R.\nOne drawback: Areas at the edges of our map have fewer neighbors, which might skew our results a bit.\nHere’s how we’d typically code this:\n\nrswm_q &lt;- nb2listw(wm_q, \n                   style=\"W\", \n                   zero.policy = TRUE)\nrswm_q\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 448 \nPercentage nonzero weights: 5.785124 \nAverage number of links: 5.090909 \n\nWeights style: W \nWeights constants summary:\n   n   nn S0       S1       S2\nW 88 7744 88 37.86334 365.9147"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gmsa-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gmsa-morans-i",
    "title": "Hands-on Exercise 5",
    "section": "GMSA: Moran’s I",
    "text": "GMSA: Moran’s I\n\nmoran.test(hunan$GDPPC, \n           listw=rswm_q, \n           zero.policy = TRUE, \n           na.action=na.omit)\n\n\n    Moran I test under randomisation\n\ndata:  hunan$GDPPC  \nweights: rswm_q    \n\nMoran I statistic standard deviate = 4.7351, p-value = 1.095e-06\nalternative hypothesis: greater\nsample estimates:\nMoran I statistic       Expectation          Variance \n      0.300749970      -0.011494253       0.004348351 \n\n\n\nThe Moran’s I statistic is 0.30074970, which is positive and relatively strong. This indicates positive spatial autocorrelation in the GDPPC (Gross Domestic Product Per Capita) data for Hunan.\nThe p-value is extremely small (1.095e-06 or 0.000001095), which is much less than the typical significance levels (e.g., 0.05 or 0.01). This very low p-value indicates strong evidence against the null hypothesis of spatial randomness.\nThe test statistic (z-score) is 4.7351, which is well above the critical value for a normal distribution at any common significance level.\n\nGiven these results, we can conclude that there is statistically significant positive spatial autocorrelation in the GDPPC across the regions of Hunan. This means that areas with high GDPPC tend to be located near other areas with high GDPPC, and areas with low GDPPC tend to be near other areas with low GDPPC. The pattern observed is very unlikely to have occurred by random chance.\nIn simpler terms, the economic performance (as measured by GDPPC) of regions in Hunan is not randomly distributed but shows a clear spatial pattern where similar values cluster together geographically."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gsma-monte-carlos-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gsma-monte-carlos-morans-i",
    "title": "Hands-on Exercise 5",
    "section": "GSMA: Monte Carlo’s Moran’s I",
    "text": "GSMA: Monte Carlo’s Moran’s I\n\nset.seed(1234)\nbperm= moran.mc(hunan$GDPPC, \n                listw=rswm_q, \n                nsim=999, \n                zero.policy = TRUE, \n                na.action=na.omit)\nbperm\n\n\n    Monte-Carlo simulation of Moran I\n\ndata:  hunan$GDPPC \nweights: rswm_q  \nnumber of simulations + 1: 1000 \n\nstatistic = 0.30075, observed rank = 1000, p-value = 0.001\nalternative hypothesis: greater\n\n\n\nThe Moran’s I statistic is 0.30075, which is positive and indicates positive spatial autocorrelation in the GDPPC (Gross Domestic Product Per Capita) data for Hunan.\nThe p-value is 0.001, which is less than common significance levels (e.g., 0.05 or 0.01). This low p-value provides strong evidence against the null hypothesis of spatial randomness.\nThe observed rank is 1000 out of 1000 simulations, which means the observed Moran’s I value is higher than all the simulated values under spatial randomness.\nThe alternative hypothesis is “greater”, indicating we’re testing for positive spatial autocorrelation.\n\nGiven these results, we can conclude that there is statistically significant positive spatial autocorrelation in the GDPPC across the regions of Hunan. The pattern observed is very unlikely to have occurred by random chance (probability of 0.001 or 0.1%).\nThis confirms the results from the previous test, providing robust evidence that areas with similar GDPPC values (either high or low) tend to cluster together geographically in Hunan. The Monte Carlo simulation adds further confidence to this conclusion by comparing the observed statistic against many randomized scenarios."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising",
    "title": "Hands-on Exercise 5",
    "section": "Visualising",
    "text": "Visualising\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, \n     freq=TRUE, \n     breaks=20, \n     xlab=\"Simulated Moran's I\")\nabline(v=0, \n       col=\"red\") \n\n\n\n\n\nDistribution of simulated Moran’s I values:\n\nThe histogram shows the distribution of simulated Moran’s I values under the null hypothesis of spatial randomness.\nThe distribution appears to be roughly normal (bell-shaped), centered slightly below zero.\n\nCentral tendency:\n\nMean of simulated Moran’s I: -0.01504572\nMedian: -0.02125 These values are close to zero, which is expected under spatial randomnes\n\nSpread:\n\nVariance: 0.004371574\nRange: from Min (-0.18339) to Max (0.27593) This indicates the variability of Moran’s I values that could occur by chance.\n\nObserved Moran’s I:\n\nThe red vertical line in the histogram represents the observed Moran’s I value (0.30075 from the previous output).\nThis observed value falls far to the right of the simulated distribution, well beyond the typical range of values expected under spatial randomness.\n\nSignificance:\n\nThe fact that the observed Moran’s I (red line) is far from the bulk of the simulated distribution visually confirms the statistical significance found earlier.\nIt’s clear that the observed spatial autocorrelation is much stronger than what would be expected by chance.\n\nRarity of the observed value:\n\nThe observed Moran’s I is greater than all simulated values, which aligns with the previous finding of a p-value of 0.001 and a rank of 1000 out of 1000.\n\n\nThese observations strongly support the conclusion that there is significant positive spatial autocorrelation in the GDPPC data for Hunan, as the observed pattern is extremely unlikely to have occurred by random chance."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gsma-gearys-c",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gsma-gearys-c",
    "title": "Hands-on Exercise 5",
    "section": "GSMA: Geary’s C",
    "text": "GSMA: Geary’s C\n\ngeary.test(hunan$GDPPC, listw=rswm_q)\n\n\n    Geary C test under randomisation\n\ndata:  hunan$GDPPC \nweights: rswm_q   \n\nGeary C statistic standard deviate = 3.6108, p-value = 0.0001526\nalternative hypothesis: Expectation greater than statistic\nsample estimates:\nGeary C statistic       Expectation          Variance \n        0.6907223         1.0000000         0.0073364 \n\n\n\nThe Geary’s C statistic is 0.6907223. This value is less than 1, which indicates positive spatial autocorrelation in the GDPPC (Gross Domestic Product Per Capita) data for Hunan. (Note: For Geary’s C, values less than 1 indicate positive spatial autocorrelation, while values greater than 1 indicate negative spatial autocorrelation.)\nThe p-value is very small (0.0001526), which is much less than typical significance levels (e.g., 0.05 or 0.01). This extremely low p-value provides strong evidence against the null hypothesis of spatial randomness.\nThe test statistic (standard deviate) is 3.6108, which is well above the critical value for a normal distribution at common significance levels.\nThe alternative hypothesis is “Expectation greater than statistic,” which aligns with testing for positive spatial autocorrelation in Geary’s C (remember, lower values indicate positive autocorrelation).\nThe expected value under spatial randomness is 1.0000000, and the observed statistic (0.6907223) is clearly lower than this.\n\nGiven these results, we can conclude that there is statistically significant positive spatial autocorrelation in the GDPPC across the regions of Hunan. This means that areas with similar GDPPC values (either high or low) tend to be located near each other geographically. The pattern observed is very unlikely to have occurred by random chance.\nThis result is consistent with and reinforces the conclusions drawn from the Moran’s I test, providing additional evidence of spatial clustering in the economic performance of Hunan’s regions."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-1",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#visualising-1",
    "title": "Hands-on Exercise 5",
    "section": "Visualising",
    "text": "Visualising\n\nmean(bperm$res[1:999])\n\n[1] -0.01504572\n\nvar(bperm$res[1:999])\n\n[1] 0.004371574\n\nsummary(bperm$res[1:999])\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n-0.18339 -0.06168 -0.02125 -0.01505  0.02611  0.27593 \n\nhist(bperm$res, freq=TRUE, breaks=20, xlab=\"Simulated Geary c\")\nabline(v=1, col=\"red\") \n\n\n\n\nFrom the output and histogram provided for the Geary’s C test, we can draw several statistical observations:\n\nDistribution of simulated Geary’s C values:\n\nThe histogram shows the distribution of simulated Geary’s C values under the null hypothesis of spatial randomness.\nThe distribution appears to be roughly normal (bell-shaped), centered slightly below zero\n\nCentral tendency:\n\nMean of simulated Geary’s C: -0.01504572\nMedian: -0.02125 These values are close to zero, which is expected under spatial randomness.\n\nSpread:\n\nVariance: 0.004371574\nRange: from Min (-0.18339) to Max (0.27593) This indicates the variability of Geary’s C values that could occur by chance.\n\nObserved Geary’s C:\n\nThe red vertical line in the histogram represents the observed Geary’s C value (0.6907223 from the previous output).\nHowever, there seems to be a discrepancy here, as the red line is positioned at -1 on the x-axis, which doesn’t match the observed Geary’s C value. This positioning appears to be an error in the visualization.\n\nSignificance:\n\nDespite the visualization error, we know from the previous output that the observed Geary’s C (0.6907223) is significantly different from the expected value of 1 under spatial randomness.\nThe p-value of 0.0001526 from the previous output confirms that this difference is statistically significant.\n\nInterpretation challenge:\n\nThere’s a mismatch between the x-axis label (“Simulated Geary c”) and the actual values shown, which seem to be centered around 0 rather than 1 (the expected value for Geary’s C under randomness).\nThis suggests that the histogram might actually be showing transformed or normalized values, rather than raw Geary’s C statistics.\n\nConsistency with previous findings:\n\nDespite the visualization issues, the overall conclusion of significant positive spatial autocorrelation remains consistent with the earlier Geary’s C test results and the Moran’s I analysis.\n\n\nIn conclusion, while the histogram and summary statistics provide additional insight into the distribution of possible Geary’s C values under randomness, there are some inconsistencies in the visualization that make direct interpretation challenging. Nevertheless, the core finding of significant positive spatial autocorrelation in the GDPPC data for Hunan is supported by the earlier statistical test results."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-correlogram",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#morans-i-correlogram",
    "title": "Hands-on Exercise 5",
    "section": "Moran’s I Correlogram",
    "text": "Moran’s I Correlogram\n\nMI_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"I\", \n                          style=\"W\")\nplot(MI_corr)\n\n\n\n\n\nprint(MI_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Moran's I\n         estimate expectation   variance standard deviate Pr(I) two sided    \n1 (88)  0.3007500  -0.0114943  0.0043484           4.7351       2.189e-06 ***\n2 (88)  0.2060084  -0.0114943  0.0020962           4.7505       2.029e-06 ***\n3 (88)  0.0668273  -0.0114943  0.0014602           2.0496        0.040400 *  \n4 (88)  0.0299470  -0.0114943  0.0011717           1.2107        0.226015    \n5 (88) -0.1530471  -0.0114943  0.0012440          -4.0134       5.984e-05 ***\n6 (88) -0.1187070  -0.0114943  0.0016791          -2.6164        0.008886 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nStrong positive spatial autocorrelation at short distances:\n\nThe first lag shows the highest Moran’s I value (about 0.3), which is statistically significant (p &lt; 0.001).\nThis indicates that neighboring areas have very similar GDPPC values.\n2 Decreasing autocorrelation with distance:\nThe Moran’s I values decrease as the lag distance increases, showing that spatial dependency weakens with distance.\n3 Transition to negative autocorrelation:\nAround lag 5 and 6, the Moran’s I values become negative, suggesting a potential pattern of dissimilarity at larger distances.\n4 Statistical significance:\nThe first two lags (1 and 2) show highly significant autocorrelation (p &lt; 0.001).\nLag 3 is significant at the 0.05 level.\nLags 4-6 are not statistically significant at the 0.05 level.\n5 Range of spatial dependency:\nThe positive autocorrelation remains significant up to about lag 3, suggesting that the spatial influence on GDPPC extends to this distance.\n6 Overall pattern:\nThe correlogram reveals a clear spatial structure in the GDPPC data, with strong local similarities that diminish and potentially reverse at larger distances.\nThese observations suggest that the economic performance (GDPPC) in Hunan exhibits a clear spatial pattern, with nearby areas showing similar values and this similarity decreasing with distance. This pattern could be due to factors like economic spillovers, shared resources, or administrative boundaries influencing economic development.\n\nCompute Geary’s C correlogram and plot\n\nGC_corr &lt;- sp.correlogram(wm_q, \n                          hunan$GDPPC, \n                          order=6, \n                          method=\"C\", \n                          style=\"W\")\nplot(GC_corr)\n\n\n\nprint(GC_corr)\n\nSpatial correlogram for hunan$GDPPC \nmethod: Geary's C\n        estimate expectation  variance standard deviate Pr(I) two sided    \n1 (88) 0.6907223   1.0000000 0.0073364          -3.6108       0.0003052 ***\n2 (88) 0.7630197   1.0000000 0.0049126          -3.3811       0.0007220 ***\n3 (88) 0.9397299   1.0000000 0.0049005          -0.8610       0.3892612    \n4 (88) 1.0098462   1.0000000 0.0039631           0.1564       0.8757128    \n5 (88) 1.2008204   1.0000000 0.0035568           3.3673       0.0007592 ***\n6 (88) 1.0773386   1.0000000 0.0058042           1.0151       0.3100407    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#local-morans-i",
    "title": "Hands-on Exercise 5",
    "section": "Local Moran’s I",
    "text": "Local Moran’s I\n\nfips &lt;- order(hunan$County)\nlocalMI &lt;- localmoran(hunan$GDPPC, rswm_q)\nhead(localMI)\n\n            Ii          E.Ii       Var.Ii        Z.Ii Pr(z != E(Ii))\n1 -0.001468468 -2.815006e-05 4.723841e-04 -0.06626904      0.9471636\n2  0.025878173 -6.061953e-04 1.016664e-02  0.26266425      0.7928094\n3 -0.011987646 -5.366648e-03 1.133362e-01 -0.01966705      0.9843090\n4  0.001022468 -2.404783e-07 5.105969e-06  0.45259801      0.6508382\n5  0.014814881 -6.829362e-05 1.449949e-03  0.39085814      0.6959021\n6 -0.038793829 -3.860263e-04 6.475559e-03 -0.47728835      0.6331568\n\n\nlocalmoran() function returns a matrix of values whose columns are:\n\nIi: the local Moran’s I statistics\nE.Ii: the expectation of local moran statistic under the randomisation hypothesis\nVar.Ii: the variance of local moran statistic under the randomisation hypothesis\nZ.Ii:the standard deviate of local moran statistic\nPr(): the p-value of local moran statistic\n\n\nprintCoefmat(data.frame(\n  localMI[fips,], \n  row.names=hunan$County[fips]),\n  check.names=FALSE)\n\n                       Ii        E.Ii      Var.Ii        Z.Ii Pr.z....E.Ii..\nAnhua         -2.2493e-02 -5.0048e-03  5.8235e-02 -7.2467e-02         0.9422\nAnren         -3.9932e-01 -7.0111e-03  7.0348e-02 -1.4791e+00         0.1391\nAnxiang       -1.4685e-03 -2.8150e-05  4.7238e-04 -6.6269e-02         0.9472\nBaojing        3.4737e-01 -5.0089e-03  8.3636e-02  1.2185e+00         0.2230\nChaling        2.0559e-02 -9.6812e-04  2.7711e-02  1.2932e-01         0.8971\nChangning     -2.9868e-05 -9.0010e-09  1.5105e-07 -7.6828e-02         0.9388\nChangsha       4.9022e+00 -2.1348e-01  2.3194e+00  3.3590e+00         0.0008\nChengbu        7.3725e-01 -1.0534e-02  2.2132e-01  1.5895e+00         0.1119\nChenxi         1.4544e-01 -2.8156e-03  4.7116e-02  6.8299e-01         0.4946\nCili           7.3176e-02 -1.6747e-03  4.7902e-02  3.4200e-01         0.7324\nDao            2.1420e-01 -2.0824e-03  4.4123e-02  1.0297e+00         0.3032\nDongan         1.5210e-01 -6.3485e-04  1.3471e-02  1.3159e+00         0.1882\nDongkou        5.2918e-01 -6.4461e-03  1.0748e-01  1.6338e+00         0.1023\nFenghuang      1.8013e-01 -6.2832e-03  1.3257e-01  5.1198e-01         0.6087\nGuidong       -5.9160e-01 -1.3086e-02  3.7003e-01 -9.5104e-01         0.3416\nGuiyang        1.8240e-01 -3.6908e-03  3.2610e-02  1.0305e+00         0.3028\nGuzhang        2.8466e-01 -8.5054e-03  1.4152e-01  7.7931e-01         0.4358\nHanshou        2.5878e-02 -6.0620e-04  1.0167e-02  2.6266e-01         0.7928\nHengdong       9.9964e-03 -4.9063e-04  6.7742e-03  1.2742e-01         0.8986\nHengnan        2.8064e-02 -3.2160e-04  3.7597e-03  4.6294e-01         0.6434\nHengshan      -5.8201e-03 -3.0437e-05  5.1076e-04 -2.5618e-01         0.7978\nHengyang       6.2997e-02 -1.3046e-03  2.1865e-02  4.3486e-01         0.6637\nHongjiang      1.8790e-01 -2.3019e-03  3.1725e-02  1.0678e+00         0.2856\nHuarong       -1.5389e-02 -1.8667e-03  8.1030e-02 -4.7503e-02         0.9621\nHuayuan        8.3772e-02 -8.5569e-04  2.4495e-02  5.4072e-01         0.5887\nHuitong        2.5997e-01 -5.2447e-03  1.1077e-01  7.9685e-01         0.4255\nJiahe         -1.2431e-01 -3.0550e-03  5.1111e-02 -5.3633e-01         0.5917\nJianghua       2.8651e-01 -3.8280e-03  8.0968e-02  1.0204e+00         0.3076\nJiangyong      2.4337e-01 -2.7082e-03  1.1746e-01  7.1800e-01         0.4728\nJingzhou       1.8270e-01 -8.5106e-04  2.4363e-02  1.1759e+00         0.2396\nJinshi        -1.1988e-02 -5.3666e-03  1.1334e-01 -1.9667e-02         0.9843\nJishou        -2.8680e-01 -2.6305e-03  4.4028e-02 -1.3543e+00         0.1756\nLanshan        6.3334e-02 -9.6365e-04  2.0441e-02  4.4972e-01         0.6529\nLeiyang        1.1581e-02 -1.4948e-04  2.5082e-03  2.3422e-01         0.8148\nLengshuijiang -1.7903e+00 -8.2129e-02  2.1598e+00 -1.1623e+00         0.2451\nLi             1.0225e-03 -2.4048e-07  5.1060e-06  4.5260e-01         0.6508\nLianyuan      -1.4672e-01 -1.8983e-03  1.9145e-02 -1.0467e+00         0.2952\nLiling         1.3774e+00 -1.5097e-02  4.2601e-01  2.1335e+00         0.0329\nLinli          1.4815e-02 -6.8294e-05  1.4499e-03  3.9086e-01         0.6959\nLinwu         -2.4621e-03 -9.0703e-06  1.9258e-04 -1.7676e-01         0.8597\nLinxiang       6.5904e-02 -2.9028e-03  2.5470e-01  1.3634e-01         0.8916\nLiuyang        3.3688e+00 -7.7502e-02  1.5180e+00  2.7972e+00         0.0052\nLonghui        8.0801e-01 -1.1377e-02  1.5538e-01  2.0787e+00         0.0376\nLongshan       7.5663e-01 -1.1100e-02  3.1449e-01  1.3690e+00         0.1710\nLuxi           1.8177e-01 -2.4855e-03  3.4249e-02  9.9561e-01         0.3194\nMayang         2.1852e-01 -5.8773e-03  9.8049e-02  7.1663e-01         0.4736\nMiluo          1.8704e+00 -1.6927e-02  2.7925e-01  3.5715e+00         0.0004\nNan           -9.5789e-03 -4.9497e-04  6.8341e-03 -1.0988e-01         0.9125\nNingxiang      1.5607e+00 -7.3878e-02  8.0012e-01  1.8274e+00         0.0676\nNingyuan       2.0910e-01 -7.0884e-03  8.2306e-02  7.5356e-01         0.4511\nPingjiang     -9.8964e-01 -2.6457e-03  5.6027e-02 -4.1698e+00         0.0000\nQidong         1.1806e-01 -2.1207e-03  2.4747e-02  7.6396e-01         0.4449\nQiyang         6.1966e-02 -7.3374e-04  8.5743e-03  6.7712e-01         0.4983\nRucheng       -3.6992e-01 -8.8999e-03  2.5272e-01 -7.1814e-01         0.4727\nSangzhi        2.5053e-01 -4.9470e-03  6.8000e-02  9.7972e-01         0.3272\nShaodong      -3.2659e-02 -3.6592e-05  5.0546e-04 -1.4510e+00         0.1468\nShaoshan       2.1223e+00 -5.0227e-02  1.3668e+00  1.8583e+00         0.0631\nShaoyang       5.9499e-01 -1.1253e-02  1.3012e-01  1.6807e+00         0.0928\nShimen        -3.8794e-02 -3.8603e-04  6.4756e-03 -4.7729e-01         0.6332\nShuangfeng     9.2835e-03 -2.2867e-03  3.1516e-02  6.5174e-02         0.9480\nShuangpai      8.0591e-02 -3.1366e-04  8.9838e-03  8.5358e-01         0.3933\nSuining        3.7585e-01 -3.5933e-03  4.1870e-02  1.8544e+00         0.0637\nTaojiang      -2.5394e-01 -1.2395e-03  1.4477e-02 -2.1002e+00         0.0357\nTaoyuan        1.4729e-02 -1.2039e-04  8.5103e-04  5.0903e-01         0.6107\nTongdao        4.6482e-01 -6.9870e-03  1.9879e-01  1.0582e+00         0.2900\nWangcheng      4.4220e+00 -1.1067e-01  1.3596e+00  3.8873e+00         0.0001\nWugang         7.1003e-01 -7.8144e-03  1.0710e-01  2.1935e+00         0.0283\nXiangtan       2.4530e-01 -3.6457e-04  3.2319e-03  4.3213e+00         0.0000\nXiangxiang     2.6271e-01 -1.2703e-03  2.1290e-02  1.8092e+00         0.0704\nXiangyin       5.4525e-01 -4.7442e-03  7.9236e-02  1.9539e+00         0.0507\nXinhua         1.1810e-01 -6.2649e-03  8.6001e-02  4.2409e-01         0.6715\nXinhuang       1.5725e-01 -4.1820e-03  3.6648e-01  2.6667e-01         0.7897\nXinning        6.8928e-01 -9.6674e-03  2.0328e-01  1.5502e+00         0.1211\nXinshao        5.7578e-02 -8.5932e-03  1.1769e-01  1.9289e-01         0.8470\nXintian       -7.4050e-03 -5.1493e-03  1.0877e-01 -6.8395e-03         0.9945\nXupu           3.2406e-01 -5.7468e-03  5.7735e-02  1.3726e+00         0.1699\nYanling       -6.9021e-02 -5.9211e-04  9.9306e-03 -6.8667e-01         0.4923\nYizhang       -2.6844e-01 -2.2463e-03  4.7588e-02 -1.2202e+00         0.2224\nYongshun       6.3064e-01 -1.1350e-02  1.8830e-01  1.4795e+00         0.1390\nYongxing       4.3411e-01 -9.0735e-03  1.5088e-01  1.1409e+00         0.2539\nYou            7.8750e-02 -7.2728e-03  1.2116e-01  2.4714e-01         0.8048\nYuanjiang      2.0004e-04 -1.7760e-04  2.9798e-03  6.9181e-03         0.9945\nYuanling       8.7298e-03 -2.2981e-06  2.3221e-05  1.8121e+00         0.0700\nYueyang        4.1189e-02 -1.9768e-04  2.3113e-03  8.6085e-01         0.3893\nZhijiang       1.0476e-01 -7.8123e-04  1.3100e-02  9.2214e-01         0.3565\nZhongfang     -2.2685e-01 -2.1455e-03  3.5927e-02 -1.1855e+00         0.2358\nZhuzhou        3.2864e-01 -5.2432e-04  7.2391e-03  3.8688e+00         0.0001\nZixing        -7.6849e-01 -8.8210e-02  9.4057e-01 -7.0144e-01         0.4830\n\n\n\nhunan.localMI &lt;- cbind(hunan,localMI) %&gt;%\n  rename(Pr.Ii = Pr.z....E.Ii..)\n\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\",\n          palette = \"RdBu\",\n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\nMap p-values\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nBoth together now\n\nlocalMI.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Ii\", \n          style = \"pretty\", \n          title = \"local moran statistics\") +\n  tm_borders(alpha = 0.5)\n\npvalue.map &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"Pr.Ii\", \n          breaks=c(-Inf, 0.001, 0.01, 0.05, 0.1, Inf),\n          palette=\"-Blues\", \n          title = \"local Moran's I p-values\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(localMI.map, pvalue.map, asp=1, ncol=2)\n\nVariable(s) \"Ii\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#lisa-cluster-map",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#lisa-cluster-map",
    "title": "Hands-on Exercise 5",
    "section": "LISA Cluster map",
    "text": "LISA Cluster map\n\nnci &lt;- moran.plot(hunan$GDPPC, rswm_q,\n                  labels=as.character(hunan$County), \n                  xlab=\"GDPPC 2012\", \n                  ylab=\"Spatially Lag GDPPC 2012\")\n\n\n\n\nThe Moran scatterplot is an illustration of the relationship between the values of the chosen attribute at each location and the average value of the same attribute at neighboring locations.\nNotice that the plot is split in 4 quadrants. The top right corner belongs to areas that have high GDPPC and are surrounded by other areas that have the average level of GDPPC. This are the high-high locations in the lesson slide.\n\nhunan$Z.GDPPC &lt;- scale(hunan$GDPPC) %&gt;% \n  as.vector \nnci2 &lt;- moran.plot(hunan$Z.GDPPC, rswm_q,\n                   labels=as.character(hunan$County),\n                   xlab=\"z-GDPPC 2012\", \n                   ylab=\"Spatially Lag z-GDPPC 2012\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#prepare-lisa-map-classes",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#prepare-lisa-map-classes",
    "title": "Hands-on Exercise 5",
    "section": "Prepare LISA map classes",
    "text": "Prepare LISA map classes\n\nquadrant &lt;- vector(mode=\"numeric\",length=nrow(localMI))\nhunan$lag_GDPPC &lt;- lag.listw(rswm_q, hunan$GDPPC)\nDV &lt;- hunan$lag_GDPPC - mean(hunan$lag_GDPPC)     \nLM_I &lt;- localMI[,1]   \nsignif &lt;- 0.05       \nquadrant[DV &lt;0 & LM_I&gt;0] &lt;- 1\nquadrant[DV &gt;0 & LM_I&lt;0] &lt;- 2\nquadrant[DV &lt;0 & LM_I&lt;0] &lt;- 3  \nquadrant[DV &gt;0 & LM_I&gt;0] &lt;- 4    \nquadrant[localMI[,5]&gt;signif] &lt;- 0\n\nPlot\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\ntm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\n\n\n\nPlot side by side\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nhunan.localMI$quadrant &lt;- quadrant\ncolors &lt;- c(\"#ffffff\", \"#2c7bb6\", \"#abd9e9\", \"#fdae61\", \"#d7191c\")\nclusters &lt;- c(\"insignificant\", \"low-low\", \"low-high\", \"high-low\", \"high-high\")\n\nLISAmap &lt;- tm_shape(hunan.localMI) +\n  tm_fill(col = \"quadrant\", \n          style = \"cat\", \n          palette = colors[c(sort(unique(quadrant)))+1], \n          labels = clusters[c(sort(unique(quadrant)))+1],\n          popup.vars = c(\"\")) +\n  tm_view(set.zoom.limits = c(11,17)) +\n  tm_borders(alpha=0.5)\n\ntmap_arrange(gdppc, LISAmap, \n             asp=1, ncol=2)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#getis-and-ords-g-statistics",
    "title": "Hands-on Exercise 5",
    "section": "Getis and Ord’s G-Statistics",
    "text": "Getis and Ord’s G-Statistics\n\nDerive centroid\n\nlongitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[1]])\nlatitude &lt;- map_dbl(hunan$geometry, ~st_centroid(.x)[[2]])\ncoords &lt;- cbind(longitude, latitude)\n\n\n\nDetermine cut off distance\n\n#coords &lt;- coordinates(hunan)\nk1 &lt;- knn2nb(knearneigh(coords))\nk1dists &lt;- unlist(nbdists(k1, coords, longlat = TRUE))\nsummary(k1dists)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  24.79   32.57   38.01   39.07   44.52   61.79 \n\n\n\n\nCompute fixed distance weight\n\nwm_d62 &lt;- dnearneigh(coords, 0, 62, longlat = TRUE)\nwm_d62\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \n\nwm62_lw &lt;- nb2listw(wm_d62, style = 'B')\nsummary(wm62_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 324 \nPercentage nonzero weights: 4.183884 \nAverage number of links: 3.681818 \nLink number distribution:\n\n 1  2  3  4  5  6 \n 6 15 14 26 20  7 \n6 least connected regions:\n6 15 30 32 56 65 with 1 link\n7 most connected regions:\n21 28 35 45 50 52 82 with 6 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0  S1   S2\nB 88 7744 324 648 5440\n\n\n\n\ncompute adaptive distance weivht matrix\n\nknn &lt;- knn2nb(knearneigh(coords, k=8))\nknn\n\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\n\nknn_lw &lt;- nb2listw(knn, style = 'B')\nsummary(knn_lw)\n\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 88 \nNumber of nonzero links: 704 \nPercentage nonzero weights: 9.090909 \nAverage number of links: 8 \nNon-symmetric neighbours list\nLink number distribution:\n\n 8 \n88 \n88 least connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n88 most connected regions:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 with 8 links\n\nWeights style: B \nWeights constants summary:\n   n   nn  S0   S1    S2\nB 88 7744 704 1300 23014"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gi-stats",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html#gi-stats",
    "title": "Hands-on Exercise 5",
    "section": "Gi Stats",
    "text": "Gi Stats\n\nfips &lt;- order(hunan$County)\ngi.fixed &lt;- localG(hunan$GDPPC, wm62_lw)\ngi.fixed\n\n [1]  0.436075843 -0.265505650 -0.073033665  0.413017033  0.273070579\n [6] -0.377510776  2.863898821  2.794350420  5.216125401  0.228236603\n[11]  0.951035346 -0.536334231  0.176761556  1.195564020 -0.033020610\n[16]  1.378081093 -0.585756761 -0.419680565  0.258805141  0.012056111\n[21] -0.145716531 -0.027158687 -0.318615290 -0.748946051 -0.961700582\n[26] -0.796851342 -1.033949773 -0.460979158 -0.885240161 -0.266671512\n[31] -0.886168613 -0.855476971 -0.922143185 -1.162328599  0.735582222\n[36] -0.003358489 -0.967459309 -1.259299080 -1.452256513 -1.540671121\n[41] -1.395011407 -1.681505286 -1.314110709 -0.767944457 -0.192889342\n[46]  2.720804542  1.809191360 -1.218469473 -0.511984469 -0.834546363\n[51] -0.908179070 -1.541081516 -1.192199867 -1.075080164 -1.631075961\n[56] -0.743472246  0.418842387  0.832943753 -0.710289083 -0.449718820\n[61] -0.493238743 -1.083386776  0.042979051  0.008596093  0.136337469\n[66]  2.203411744  2.690329952  4.453703219 -0.340842743 -0.129318589\n[71]  0.737806634 -1.246912658  0.666667559  1.088613505 -0.985792573\n[76]  1.233609606 -0.487196415  1.626174042 -1.060416797  0.425361422\n[81] -0.837897118 -0.314565243  0.371456331  4.424392623 -0.109566928\n[86]  1.364597995 -1.029658605 -0.718000620\nattr(,\"internals\")\n               Gi      E(Gi)        V(Gi)        Z(Gi) Pr(z != E(Gi))\n [1,] 0.064192949 0.05747126 2.375922e-04  0.436075843   6.627817e-01\n [2,] 0.042300020 0.04597701 1.917951e-04 -0.265505650   7.906200e-01\n [3,] 0.044961480 0.04597701 1.933486e-04 -0.073033665   9.417793e-01\n [4,] 0.039475779 0.03448276 1.461473e-04  0.413017033   6.795941e-01\n [5,] 0.049767939 0.04597701 1.927263e-04  0.273070579   7.847990e-01\n [6,] 0.008825335 0.01149425 4.998177e-05 -0.377510776   7.057941e-01\n [7,] 0.050807266 0.02298851 9.435398e-05  2.863898821   4.184617e-03\n [8,] 0.083966739 0.04597701 1.848292e-04  2.794350420   5.200409e-03\n [9,] 0.115751554 0.04597701 1.789361e-04  5.216125401   1.827045e-07\n[10,] 0.049115587 0.04597701 1.891013e-04  0.228236603   8.194623e-01\n[11,] 0.045819180 0.03448276 1.420884e-04  0.951035346   3.415864e-01\n[12,] 0.049183846 0.05747126 2.387633e-04 -0.536334231   5.917276e-01\n[13,] 0.048429181 0.04597701 1.924532e-04  0.176761556   8.596957e-01\n[14,] 0.034733752 0.02298851 9.651140e-05  1.195564020   2.318667e-01\n[15,] 0.011262043 0.01149425 4.945294e-05 -0.033020610   9.736582e-01\n[16,] 0.065131196 0.04597701 1.931870e-04  1.378081093   1.681783e-01\n[17,] 0.027587075 0.03448276 1.385862e-04 -0.585756761   5.580390e-01\n[18,] 0.029409313 0.03448276 1.461397e-04 -0.419680565   6.747188e-01\n[19,] 0.061466754 0.05747126 2.383385e-04  0.258805141   7.957856e-01\n[20,] 0.057656917 0.05747126 2.371303e-04  0.012056111   9.903808e-01\n[21,] 0.066518379 0.06896552 2.820326e-04 -0.145716531   8.841452e-01\n[22,] 0.045599896 0.04597701 1.928108e-04 -0.027158687   9.783332e-01\n[23,] 0.030646753 0.03448276 1.449523e-04 -0.318615290   7.500183e-01\n[24,] 0.035635552 0.04597701 1.906613e-04 -0.748946051   4.538897e-01\n[25,] 0.032606647 0.04597701 1.932888e-04 -0.961700582   3.362000e-01\n[26,] 0.035001352 0.04597701 1.897172e-04 -0.796851342   4.255374e-01\n[27,] 0.012746354 0.02298851 9.812587e-05 -1.033949773   3.011596e-01\n[28,] 0.061287917 0.06896552 2.773884e-04 -0.460979158   6.448136e-01\n[29,] 0.014277403 0.02298851 9.683314e-05 -0.885240161   3.760271e-01\n[30,] 0.009622875 0.01149425 4.924586e-05 -0.266671512   7.897221e-01\n[31,] 0.014258398 0.02298851 9.705244e-05 -0.886168613   3.755267e-01\n[32,] 0.005453443 0.01149425 4.986245e-05 -0.855476971   3.922871e-01\n[33,] 0.043283712 0.05747126 2.367109e-04 -0.922143185   3.564539e-01\n[34,] 0.020763514 0.03448276 1.393165e-04 -1.162328599   2.451020e-01\n[35,] 0.081261843 0.06896552 2.794398e-04  0.735582222   4.619850e-01\n[36,] 0.057419907 0.05747126 2.338437e-04 -0.003358489   9.973203e-01\n[37,] 0.013497133 0.02298851 9.624821e-05 -0.967459309   3.333145e-01\n[38,] 0.019289310 0.03448276 1.455643e-04 -1.259299080   2.079223e-01\n[39,] 0.025996272 0.04597701 1.892938e-04 -1.452256513   1.464303e-01\n[40,] 0.016092694 0.03448276 1.424776e-04 -1.540671121   1.233968e-01\n[41,] 0.035952614 0.05747126 2.379439e-04 -1.395011407   1.630124e-01\n[42,] 0.031690963 0.05747126 2.350604e-04 -1.681505286   9.266481e-02\n[43,] 0.018750079 0.03448276 1.433314e-04 -1.314110709   1.888090e-01\n[44,] 0.015449080 0.02298851 9.638666e-05 -0.767944457   4.425202e-01\n[45,] 0.065760689 0.06896552 2.760533e-04 -0.192889342   8.470456e-01\n[46,] 0.098966900 0.05747126 2.326002e-04  2.720804542   6.512325e-03\n[47,] 0.085415780 0.05747126 2.385746e-04  1.809191360   7.042128e-02\n[48,] 0.038816536 0.05747126 2.343951e-04 -1.218469473   2.230456e-01\n[49,] 0.038931873 0.04597701 1.893501e-04 -0.511984469   6.086619e-01\n[50,] 0.055098610 0.06896552 2.760948e-04 -0.834546363   4.039732e-01\n[51,] 0.033405005 0.04597701 1.916312e-04 -0.908179070   3.637836e-01\n[52,] 0.043040784 0.06896552 2.829941e-04 -1.541081516   1.232969e-01\n[53,] 0.011297699 0.02298851 9.615920e-05 -1.192199867   2.331829e-01\n[54,] 0.040968457 0.05747126 2.356318e-04 -1.075080164   2.823388e-01\n[55,] 0.023629663 0.04597701 1.877170e-04 -1.631075961   1.028743e-01\n[56,] 0.006281129 0.01149425 4.916619e-05 -0.743472246   4.571958e-01\n[57,] 0.063918654 0.05747126 2.369553e-04  0.418842387   6.753313e-01\n[58,] 0.070325003 0.05747126 2.381374e-04  0.832943753   4.048765e-01\n[59,] 0.025947288 0.03448276 1.444058e-04 -0.710289083   4.775249e-01\n[60,] 0.039752578 0.04597701 1.915656e-04 -0.449718820   6.529132e-01\n[61,] 0.049934283 0.05747126 2.334965e-04 -0.493238743   6.218439e-01\n[62,] 0.030964195 0.04597701 1.920248e-04 -1.083386776   2.786368e-01\n[63,] 0.058129184 0.05747126 2.343319e-04  0.042979051   9.657182e-01\n[64,] 0.046096514 0.04597701 1.932637e-04  0.008596093   9.931414e-01\n[65,] 0.012459080 0.01149425 5.008051e-05  0.136337469   8.915545e-01\n[66,] 0.091447733 0.05747126 2.377744e-04  2.203411744   2.756574e-02\n[67,] 0.049575872 0.02298851 9.766513e-05  2.690329952   7.138140e-03\n[68,] 0.107907212 0.04597701 1.933581e-04  4.453703219   8.440175e-06\n[69,] 0.019616151 0.02298851 9.789454e-05 -0.340842743   7.332220e-01\n[70,] 0.032923393 0.03448276 1.454032e-04 -0.129318589   8.971056e-01\n[71,] 0.030317663 0.02298851 9.867859e-05  0.737806634   4.606320e-01\n[72,] 0.019437582 0.03448276 1.455870e-04 -1.246912658   2.124295e-01\n[73,] 0.055245460 0.04597701 1.932838e-04  0.666667559   5.049845e-01\n[74,] 0.074278054 0.05747126 2.383538e-04  1.088613505   2.763244e-01\n[75,] 0.013269580 0.02298851 9.719982e-05 -0.985792573   3.242349e-01\n[76,] 0.049407829 0.03448276 1.463785e-04  1.233609606   2.173484e-01\n[77,] 0.028605749 0.03448276 1.455139e-04 -0.487196415   6.261191e-01\n[78,] 0.039087662 0.02298851 9.801040e-05  1.626174042   1.039126e-01\n[79,] 0.031447120 0.04597701 1.877464e-04 -1.060416797   2.889550e-01\n[80,] 0.064005294 0.05747126 2.359641e-04  0.425361422   6.705732e-01\n[81,] 0.044606529 0.05747126 2.357330e-04 -0.837897118   4.020885e-01\n[82,] 0.063700493 0.06896552 2.801427e-04 -0.314565243   7.530918e-01\n[83,] 0.051142205 0.04597701 1.933560e-04  0.371456331   7.102977e-01\n[84,] 0.102121112 0.04597701 1.610278e-04  4.424392623   9.671399e-06\n[85,] 0.021901462 0.02298851 9.843172e-05 -0.109566928   9.127528e-01\n[86,] 0.064931813 0.04597701 1.929430e-04  1.364597995   1.723794e-01\n[87,] 0.031747344 0.04597701 1.909867e-04 -1.029658605   3.031703e-01\n[88,] 0.015893319 0.02298851 9.765131e-05 -0.718000620   4.727569e-01\nattr(,\"cluster\")\n [1] Low  Low  High High High High High High High Low  Low  High Low  Low  Low \n[16] High High High High Low  High High Low  Low  High Low  Low  Low  Low  Low \n[31] Low  Low  Low  High Low  Low  Low  Low  Low  Low  High Low  Low  Low  Low \n[46] High High Low  Low  Low  Low  High Low  Low  Low  Low  Low  High Low  Low \n[61] Low  Low  Low  High High High Low  High Low  Low  High Low  High High Low \n[76] High Low  Low  Low  Low  Low  Low  High High Low  High Low  Low \nLevels: Low High\nattr(,\"gstari\")\n[1] FALSE\nattr(,\"call\")\nlocalG(x = hunan$GDPPC, listw = wm62_lw)\nattr(,\"class\")\n[1] \"localG\"\n\n\n\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.fixed)) %&gt;%\n  rename(gstat_fixed = as.matrix.gi.fixed.)\n\n\ngdppc &lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;-tm_shape(hunan.gi) +\n  tm_fill(col = \"gstat_fixed\", \n          style = \"pretty\",\n          palette=\"-RdBu\",\n          title = \"local Gi\") +\n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, Gimap, asp=1, ncol=2)\n\nVariable(s) \"gstat_fixed\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nfips &lt;- order(hunan$County)\ngi.adaptive &lt;- localG(hunan$GDPPC, knn_lw)\nhunan.gi &lt;- cbind(hunan, as.matrix(gi.adaptive)) %&gt;%\n  rename(gstat_adaptive = as.matrix.gi.adaptive.)\n\n\nmapping Gi Values with adaptive distance\n\ngdppc&lt;- qtm(hunan, \"GDPPC\")\n\nGimap &lt;- tm_shape(hunan.gi) + \n  tm_fill(col = \"gstat_adaptive\", \n          style = \"pretty\", \n          palette=\"-RdBu\", \n          title = \"local Gi\") + \n  tm_borders(alpha = 0.5)\n\ntmap_arrange(gdppc, \n             Gimap, \n             asp=1, \n             ncol=2)\n\nVariable(s) \"gstat_adaptive\" contains positive and negative values, so midpoint is set to 0. Set midpoint = NA to show the full spectrum of the color palette.\n\n\n\n\n\n\nSpatial clustering: The map reveals clear spatial patterns of high and low values of the Gi statistic, indicating the presence of statistically significant hot spots and cold spots.\nHot spots: The eastern part of the region shows a large cluster of high positive Gi values (red and dark red areas). This suggests a concentration of high GDPPC values in this area, surrounded by other high values.\nCold spots: There’s a noticeable cold spot (blue area) in the south-central part of the region. This indicates a cluster of low GDPPC values surrounded by other low values.\nTransition zones: Areas with light colors (pale blue to pale red) represent transition zones where the GDPPC values are not significantly different from their neighbors.\nWest-East divide: There appears to be a general trend of higher Gi values in the east and lower values in the west, suggesting an economic disparity between these parts of the region.\nCorrelation with GDPPC map: The Gi map correlates well with the GDPPC map on the left, confirming that the hot spots correspond to areas of high GDPPC and cold spots to areas of low GDPPC.\nLocal variations: The Gi map reveals local patterns that might not be immediately apparent from the raw GDPPC map, highlighting the importance of spatial statistics in understanding geographic patterns.\n\nThese observations suggest that there is significant spatial autocorrelation in the GDPPC data, with clear patterns of economic clustering within the region. This information can be valuable for understanding economic disparities and potentially for guiding regional development policies."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis-of-road-accidents-non-geospatial-segment",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#temporal-analysis-of-road-accidents-non-geospatial-segment",
    "title": "Take-home Exercise 1",
    "section": "Temporal analysis of road accidents (non-geospatial segment)",
    "text": "Temporal analysis of road accidents (non-geospatial segment)\nIn the following analysis, let’s examine temporal patterns of road accidents in the Bangkok Metropolitan Region from 2019 to 2022. Let’s visualize accident frequencies across different time scales, including hours of the day, days of the week, months, and years. This temporal breakdown will help identify high-risk periods influencing accident rates.\n\n# Ensure datetime columns are properly formatted\nrdacc$incident_datetime &lt;- ymd_hms(rdacc$incident_datetime)\n\nWarning: 16 failed to parse.\n\n# Create new columns for analysis\nrdacc_inc &lt;- rdacc %&gt;%\n  mutate(\n    hour = hour(incident_datetime),\n    day_of_week = wday(incident_datetime, label = TRUE),\n    month = month(incident_datetime, label = TRUE),\n    year = year(incident_datetime)\n  )\n\n# Accidents by hour of day\nggplot(rdacc_inc, aes(x = hour)) +\n  geom_bar() +\n  labs(title = \"Accidents by Hour of Day\", x = \"Hour\", y = \"Number of Accidents\")\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n#Insight: Accidents appear to happen from 7am to 11am and 7pm.\n\n# Accidents by day of week\nggplot(rdacc_inc, aes(x = day_of_week)) +\n  geom_bar() +\n  labs(title = \"Accidents by Day of Week\", x = \"Day\", y = \"Number of Accidents\")\n\n\n\n#Insight: Accidents appear to happen on Friday and Saturday.\n\n# Accidents by month\nggplot(rdacc_inc, aes(x = month)) +\n  geom_bar() +\n  labs(title = \"Accidents by Month\", x = \"Month\", y = \"Number of Accidents\")\n\n\n\n#Insight: Accidents appear to happen In Dec, Jan, Apr, and Oct.\n\n# Time series of accidents by date\nrdacc_inc %&gt;%\n  count(date = as.Date(incident_datetime)) %&gt;%\n  ggplot(aes(x = date, y = n)) +\n  geom_line() +\n  labs(title = \"Daily Accident Counts Over Time\", x = \"Date\", y = \"Number of Accidents\")\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_line()`).\n\n\n\n\n#Insight: Accidents spike every year in Jan/ Dec and Apr.\n\n# Time series of accidents by year\nggplot(rdacc_inc, aes(x = year)) +\n  geom_bar() +\n  labs(title = \"Accidents by Year\", x = \"Year\", y = \"Number of Accidents\")\n\nWarning: Removed 16 rows containing non-finite outside the scale range\n(`stat_count()`).\n\n\n\n\n#Insight: Fluctuating with a graduate increase per year.\n\nLet’s take a look at two heatmaps that examines when accidents happen.\n\nlibrary(viridis)\n\nWarning: package 'viridis' was built under R version 4.3.3\n\n\nLoading required package: viridisLite\n\nrdacc_time &lt;- rdacc %&gt;%\n  mutate(\n    month = month(incident_datetime, label = TRUE, abbr = TRUE),\n    hour = hour(incident_datetime)\n  )\n\naccident_counts &lt;- rdacc_time %&gt;%\n  count(month, hour)\n\nggplot(accident_counts, aes(x = hour, y = month, fill = n)) +\n  geom_tile() +\n  scale_fill_viridis(name = \"Number of Accidents\", \n                     option = \"inferno\", \n                     breaks = seq(20, 80, by = 20),\n                     limits = c(20, 80)) +\n  scale_x_continuous(breaks = seq(0, 23, by = 3), \n                     labels = c(\"12am\", \"3am\", \"6am\", \"9am\", \"12pm\", \"3pm\", \"6pm\", \"9pm\")) +\n  scale_y_discrete(limits = rev(levels(accident_counts$month))) +\n  labs(title = \"Heatmap of Accidents by Month and Time of Day\",\n       subtitle = \"Bangkok Metropolitan Region, 2019-2022\",\n       x = \"Time of Day\",\n       y = \"Month\") +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    legend.position = \"right\",\n    plot.title = element_text(face = \"bold\", size = 14),\n    plot.subtitle = element_text(size = 12, color = \"gray50\"),\n    axis.title = element_text(face = \"bold\")\n  )\n\nWarning: Removed 1 row containing missing values or values outside the scale range\n(`geom_tile()`).\n\n\n\n\n\nIt appears that Jan, Apr, Oct, Dec is worth investigating.\nKey observations:\n\nSeasonal trends: Apr and Dec shows consistently high accident rates throughout the day. This could be related to increased holiday traffic or year-end celebrations.\nMorning trends: There’s a noticeable increase in accidents starting around 6am across most months, likely corresponding to morning rush hour.\nNight-time patterns: Accident rates generally decrease late at night (12am-3am), but remain somewhat elevated compared to early morning hours (3am-6am)."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-apr---lixelisation-of-apr-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-apr---lixelisation-of-apr-data",
    "title": "Take-home Exercise 1",
    "section": "Focused look at Apr -> Lixelisation of Apr data",
    "text": "Focused look at Apr -&gt; Lixelisation of Apr data\n\nrdacc_apr &lt;- rdacc %&gt;%\n  filter(month(incident_datetime) == 4)\n\nlixels_apr &lt;- lixelize_lines(roads_filtered, \n                         700, \n                         mindist = 500)\nsamples_apr &lt;- lines_center(lixels_apr) \ndensities_apr &lt;- nkde(roads_filtered, \n                  events = rdacc_apr,\n                  w = rep(1, nrow(rdacc_apr)),\n                  samples = samples_apr,\n                  kernel_name = \"quartic\",\n                  bw = 100, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(4,4), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\nsamples_apr$density &lt;- densities_apr\nlixels_apr$density &lt;- densities_apr\nsummary(samples_apr$density)\n\n\nwrite_rds(lixels_apr, \"data/sandbox/lixels_apr.rds\")\nwrite_rds(samples_apr, \"data/sandbox/samples_apr.rds\")\n\n\nlixels_apr &lt;- read_rds(\"data/sandbox/lixels_apr.rds\")\nsamples_apr &lt;- read_rds(\"data/sandbox/samples_apr.rds\")\nsamples_apr$density &lt;- samples_apr$density*1000\nlixels_apr$density &lt;- lixels_apr$density*1000\nsummary(samples_apr$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.001457 0.000000 0.468568 \n\nsummary(lixels_apr$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.001457 0.000000 0.468568 \n\n\n\nlixels_apr$display_name &lt;- ifelse(is.na(lixels_apr$name_en), \n                              paste(lixels_apr$highway,\": Unnamed Road\"),\n                              paste(lixels_apr$highway,\": \",lixels_apr$name_en))\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ncustom_breaks &lt;- c(0, quantile(lixels_apr$density, c(0.99,\n                                                     0.992,\n                                                     0.994,\n                                                     0.996,\n                                                     0.998,\n                                                     1)))\ntm_shape(lixels_apr) +\n  tm_lines(col = \"density\",\n           id = \"display_name\",\n           breaks = custom_breaks,\n           palette = \"YlOrRd\",\n           lwd = 1.5)+\n  tm_shape(admin) +  \n  tm_borders(col = \"black\", lwd = 2, alpha = 0.5)\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nAccidents are spread across the entire region, but with varying densities. These highways seem to be attracting accidents:\n\nKanchanaphisek Road (east portion of the long road)\nBangkok-Chonburi Motorway\nBorommaratchachonnani Road\nIndustrial Ring Road"
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-jan-and-dec---lixelisation-of-jandec-data",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#focused-look-at-jan-and-dec---lixelisation-of-jandec-data",
    "title": "Take-home Exercise 1",
    "section": "Focused look at Jan and Dec -> Lixelisation of Jan+Dec data",
    "text": "Focused look at Jan and Dec -&gt; Lixelisation of Jan+Dec data\n\nrdacc_jandec &lt;- rdacc %&gt;%\n  filter(month(incident_datetime) %in% c(1, 12))\n\nlixels_jandec &lt;- lixelize_lines(roads_filtered, \n                         700, \n                         mindist = 500)\nsamples_jandec &lt;- lines_center(lixels_jandec) \ndensities_jandec &lt;- nkde(roads_filtered, \n                  events = rdacc_jandec,\n                  w = rep(1, nrow(rdacc_jandec)),\n                  samples = samples_jandec,\n                  kernel_name = \"quartic\",\n                  bw = 100, \n                  div= \"bw\", \n                  method = \"simple\", \n                  digits = 1, \n                  tol = 1,\n                  grid_shape = c(4,4), \n                  max_depth = 8,\n                  agg = 5, \n                  sparse = TRUE,\n                  verbose = FALSE)\nsamples_jandec$density &lt;- densities_jandec\nlixels_jandec$density &lt;- densities_jandec\nsummary(samples_jandec$density)\n\n\nwrite_rds(lixels_jandec, \"data/sandbox/lixels_jandec.rds\")\nwrite_rds(samples_jandec, \"data/sandbox/samples_jandec.rds\")\n\n\nlixels_jandec &lt;- read_rds(\"data/sandbox/lixels_jandec.rds\")\nsamples_jandec &lt;- read_rds(\"data/sandbox/samples_jandec.rds\")\nsamples_jandec$density &lt;- samples_jandec$density*1000\nlixels_jandec$density &lt;- lixels_jandec$density*1000\nsummary(samples_jandec$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.002753 0.000000 0.658608 \n\nsummary(lixels_jandec$density)\n\n    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. \n0.000000 0.000000 0.000000 0.002753 0.000000 0.658608 \n\n\n\nlixels_jandec$display_name &lt;- ifelse(is.na(lixels_jandec$name_en), \n                                     paste(lixels_jandec$highway,\": Unnamed Road\"),\n                                     paste(lixels_jandec$highway,\": \",lixels_jandec$name_en))\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\ncustom_breaks &lt;- c(0, quantile(lixels_jandec$density, c(0.99,\n                                                     0.992,\n                                                     0.994,\n                                                     0.996,\n                                                     0.998,\n                                                     1)))\ntm_shape(lixels_jandec) +\n  tm_lines(col = \"density\",\n           id = \"display_name\",\n           breaks = custom_breaks,\n           palette = \"YlOrRd\",\n           lwd = 1.5)+\n  tm_shape(admin) +  \n  tm_borders(col = \"black\", lwd = 2, alpha = 0.5)\n\n\n\ntmap_mode('plot')\n\ntmap mode set to plotting\n\n\nSimilar patterns observed from the Jan+Dec data with the Apr data.\nWe should be able to merge Apr accidents with that of Jan, Oct and Dec and generalise more."
  }
]